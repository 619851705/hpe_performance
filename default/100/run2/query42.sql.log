15/04/07 08:16:09 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/07 08:16:09 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/07 08:16:09 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/07 08:16:09 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist

Logging initialized using configuration in file:/etc/hive/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive> use tpcds_bin_partitioned_orc_100; source query42.sql;
OK
Time taken: 2.683 seconds
Query ID = root_20150407081616_907209a1-9d13-4916-9414-8a2379d94e6e
Total jobs = 2
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/07 08:16:35 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/07 08:16:35 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/07 08:16:35 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/07 08:16:35 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150407081616_907209a1-9d13-4916-9414-8a2379d94e6e.log
2015-04-07 08:16:36	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-07 08:16:40	Dump the side-table for tag: 1 with group count: 3648 into file: file:/tmp/root/2f8cd7bd-d397-46c1-a3cb-e9767d05fd4c/hive_2015-04-07_08-16-16_560_7068822353044800106-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile01--.hashtable
2015-04-07 08:16:41	Uploaded 1 File to: file:/tmp/root/2f8cd7bd-d397-46c1-a3cb-e9767d05fd4c/hive_2015-04-07_08-16-16_560_7068822353044800106-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile01--.hashtable (108879 bytes)
2015-04-07 08:16:41	Dump the side-table for tag: 0 with group count: 31 into file: file:/tmp/root/2f8cd7bd-d397-46c1-a3cb-e9767d05fd4c/hive_2015-04-07_08-16-16_560_7068822353044800106-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile10--.hashtable
2015-04-07 08:16:41	Uploaded 1 File to: file:/tmp/root/2f8cd7bd-d397-46c1-a3cb-e9767d05fd4c/hive_2015-04-07_08-16-16_560_7068822353044800106-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile10--.hashtable (914 bytes)
2015-04-07 08:16:41	End of local task; Time Taken: 4.96 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 179
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0066, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0066/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0066
Hadoop job information for Stage-3: number of mappers: 46; number of reducers: 179
2015-04-07 08:17:00,496 Stage-3 map = 0%,  reduce = 0%
2015-04-07 08:17:08,339 Stage-3 map = 9%,  reduce = 0%, Cumulative CPU 20.47 sec
2015-04-07 08:17:09,410 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 224.13 sec
2015-04-07 08:17:10,491 Stage-3 map = 96%,  reduce = 0%, Cumulative CPU 264.47 sec
2015-04-07 08:17:11,570 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 282.34 sec
2015-04-07 08:17:13,734 Stage-3 map = 100%,  reduce = 1%, Cumulative CPU 282.34 sec
2015-04-07 08:17:14,823 Stage-3 map = 100%,  reduce = 6%, Cumulative CPU 301.07 sec
2015-04-07 08:17:15,906 Stage-3 map = 100%,  reduce = 12%, Cumulative CPU 318.15 sec
2015-04-07 08:17:16,967 Stage-3 map = 100%,  reduce = 20%, Cumulative CPU 338.5 sec
2015-04-07 08:17:18,035 Stage-3 map = 100%,  reduce = 28%, Cumulative CPU 368.34 sec
2015-04-07 08:17:19,099 Stage-3 map = 100%,  reduce = 35%, Cumulative CPU 389.23 sec
2015-04-07 08:17:20,168 Stage-3 map = 100%,  reduce = 46%, Cumulative CPU 426.65 sec
2015-04-07 08:17:21,234 Stage-3 map = 100%,  reduce = 56%, Cumulative CPU 455.36 sec
2015-04-07 08:17:22,309 Stage-3 map = 100%,  reduce = 65%, Cumulative CPU 487.33 sec
2015-04-07 08:17:23,385 Stage-3 map = 100%,  reduce = 77%, Cumulative CPU 525.36 sec
2015-04-07 08:17:24,435 Stage-3 map = 100%,  reduce = 88%, Cumulative CPU 560.73 sec
2015-04-07 08:17:25,480 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 597.38 sec
MapReduce Total cumulative CPU time: 9 minutes 57 seconds 380 msec
Ended Job = job_1428405026382_0066
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0067, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0067/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0067
Hadoop job information for Stage-4: number of mappers: 4; number of reducers: 1
2015-04-07 08:17:32,508 Stage-4 map = 0%,  reduce = 0%
2015-04-07 08:17:37,898 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 6.26 sec
2015-04-07 08:17:43,254 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 7.59 sec
MapReduce Total cumulative CPU time: 7 seconds 590 msec
Ended Job = job_1428405026382_0067
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 46  Reduce: 179   Cumulative CPU: 597.38 sec   HDFS Read: 1616559019 HDFS Write: 17572 SUCCESS
Stage-Stage-4: Map: 4  Reduce: 1   Cumulative CPU: 7.59 sec   HDFS Read: 64871 HDFS Write: 374 SUCCESS
Total MapReduce CPU Time Spent: 10 minutes 4 seconds 970 msec
OK
1998	10	Electronics	3.4732440435282096E7
1998	1	Women	3.357753024198407E7
1998	6	Jewelry	3.282079976696171E7
1998	2	Men	3.2783996395330675E7
1998	3	Children	3.1540970958351344E7
1998	7	Home	3.1119099255155593E7
1998	8	Sports	3.0985293120796144E7
1998	4	Shoes	3.0512255107863516E7
1998	9	Books	3.005956852558887E7
1998	5	Music	2.5020268013839766E7
1998	NULL		376068.6298184395
Time taken: 87.809 seconds, Fetched: 11 row(s)
hive> 