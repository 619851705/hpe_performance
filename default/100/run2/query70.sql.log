15/04/07 15:10:56 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/07 15:10:56 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/07 15:10:56 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/07 15:10:56 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist

Logging initialized using configuration in file:/etc/hive/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive> use tpcds_bin_partitioned_orc_100; source query70.sql;
OK
Time taken: 2.88 seconds
Query ID = root_20150407151111_e20653d1-7b3c-43f2-9dcd-968ed960cadc
Total jobs = 8
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/07 15:11:26 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/07 15:11:26 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/07 15:11:26 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/07 15:11:26 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150407151111_e20653d1-7b3c-43f2-9dcd-968ed960cadc.log
2015-04-07 03:11:28	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-07 03:11:32	Dump the side-table for tag: 1 with group count: 402 into file: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10015/HashTable-Stage-17/MapJoin-mapfile11--.hashtable
2015-04-07 03:11:32	Uploaded 1 File to: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10015/HashTable-Stage-17/MapJoin-mapfile11--.hashtable (15692 bytes)
2015-04-07 03:11:32	Dump the side-table for tag: 1 with group count: 366 into file: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10015/HashTable-Stage-17/MapJoin-mapfile21--.hashtable
2015-04-07 03:11:32	Uploaded 1 File to: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10015/HashTable-Stage-17/MapJoin-mapfile21--.hashtable (7984 bytes)
2015-04-07 03:11:32	End of local task; Time Taken: 4.364 sec.
Execution completed successfully
MapredLocal task succeeded
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/07 15:11:39 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/07 15:11:39 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/07 15:11:39 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/07 15:11:39 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150407151111_e20653d1-7b3c-43f2-9dcd-968ed960cadc.log
2015-04-07 03:11:40	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-07 03:11:44	Dump the side-table for tag: 1 with group count: 366 into file: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10017/HashTable-Stage-10/MapJoin-mapfile31--.hashtable
2015-04-07 03:11:44	Uploaded 1 File to: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10017/HashTable-Stage-10/MapJoin-mapfile31--.hashtable (9453 bytes)
2015-04-07 03:11:44	Dump the side-table for tag: 1 with group count: 402 into file: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10017/HashTable-Stage-10/MapJoin-mapfile41--.hashtable
2015-04-07 03:11:44	Uploaded 1 File to: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10017/HashTable-Stage-10/MapJoin-mapfile41--.hashtable (9567 bytes)
2015-04-07 03:11:44	End of local task; Time Taken: 4.15 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 8
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1428405026382_0134, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0134/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0134
Hadoop job information for Stage-17: number of mappers: 46; number of reducers: 0
2015-04-07 15:12:04,807 Stage-17 map = 0%,  reduce = 0%
2015-04-07 15:12:12,415 Stage-17 map = 15%,  reduce = 0%, Cumulative CPU 35.17 sec
2015-04-07 15:12:13,492 Stage-17 map = 63%,  reduce = 0%, Cumulative CPU 160.16 sec
2015-04-07 15:12:14,581 Stage-17 map = 77%,  reduce = 0%, Cumulative CPU 209.69 sec
2015-04-07 15:12:15,663 Stage-17 map = 86%,  reduce = 0%, Cumulative CPU 304.14 sec
2015-04-07 15:12:17,814 Stage-17 map = 89%,  reduce = 0%, Cumulative CPU 320.74 sec
2015-04-07 15:12:18,888 Stage-17 map = 92%,  reduce = 0%, Cumulative CPU 339.15 sec
2015-04-07 15:12:19,927 Stage-17 map = 93%,  reduce = 0%, Cumulative CPU 341.04 sec
2015-04-07 15:12:21,012 Stage-17 map = 96%,  reduce = 0%, Cumulative CPU 357.92 sec
2015-04-07 15:12:22,083 Stage-17 map = 98%,  reduce = 0%, Cumulative CPU 371.34 sec
2015-04-07 15:12:24,222 Stage-17 map = 100%,  reduce = 0%, Cumulative CPU 383.8 sec
MapReduce Total cumulative CPU time: 6 minutes 23 seconds 800 msec
Ended Job = job_1428405026382_0134
Launching Job 2 out of 8
Number of reduce tasks not specified. Estimated from input data size: 179
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0135, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0135/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0135
Hadoop job information for Stage-10: number of mappers: 46; number of reducers: 179
2015-04-07 15:12:39,583 Stage-10 map = 0%,  reduce = 0%
2015-04-07 15:12:49,174 Stage-10 map = 3%,  reduce = 0%, Cumulative CPU 24.34 sec
2015-04-07 15:12:50,247 Stage-10 map = 24%,  reduce = 0%, Cumulative CPU 290.39 sec
2015-04-07 15:12:51,332 Stage-10 map = 35%,  reduce = 0%, Cumulative CPU 379.48 sec
2015-04-07 15:12:52,404 Stage-10 map = 40%,  reduce = 0%, Cumulative CPU 391.41 sec
2015-04-07 15:12:53,472 Stage-10 map = 76%,  reduce = 0%, Cumulative CPU 507.18 sec
2015-04-07 15:12:54,530 Stage-10 map = 85%,  reduce = 0%, Cumulative CPU 528.53 sec
2015-04-07 15:12:55,581 Stage-10 map = 86%,  reduce = 0%, Cumulative CPU 530.23 sec
2015-04-07 15:12:56,650 Stage-10 map = 90%,  reduce = 0%, Cumulative CPU 558.29 sec
2015-04-07 15:12:57,705 Stage-10 map = 91%,  reduce = 0%, Cumulative CPU 566.15 sec
2015-04-07 15:12:59,847 Stage-10 map = 98%,  reduce = 0%, Cumulative CPU 592.61 sec
2015-04-07 15:13:00,917 Stage-10 map = 100%,  reduce = 0%, Cumulative CPU 594.72 sec
2015-04-07 15:13:01,962 Stage-10 map = 100%,  reduce = 39%, Cumulative CPU 737.0 sec
2015-04-07 15:13:03,034 Stage-10 map = 100%,  reduce = 44%, Cumulative CPU 756.32 sec
2015-04-07 15:13:04,107 Stage-10 map = 100%,  reduce = 49%, Cumulative CPU 773.81 sec
2015-04-07 15:13:05,185 Stage-10 map = 100%,  reduce = 55%, Cumulative CPU 795.33 sec
2015-04-07 15:13:06,232 Stage-10 map = 100%,  reduce = 82%, Cumulative CPU 889.09 sec
2015-04-07 15:13:07,276 Stage-10 map = 100%,  reduce = 88%, Cumulative CPU 909.67 sec
2015-04-07 15:13:08,348 Stage-10 map = 100%,  reduce = 98%, Cumulative CPU 940.37 sec
2015-04-07 15:13:09,413 Stage-10 map = 100%,  reduce = 100%, Cumulative CPU 947.64 sec
MapReduce Total cumulative CPU time: 15 minutes 47 seconds 640 msec
Ended Job = job_1428405026382_0135
Launching Job 3 out of 8
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0136, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0136/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0136
Hadoop job information for Stage-11: number of mappers: 4; number of reducers: 1
2015-04-07 15:13:16,236 Stage-11 map = 0%,  reduce = 0%
2015-04-07 15:13:21,541 Stage-11 map = 100%,  reduce = 0%, Cumulative CPU 7.34 sec
2015-04-07 15:13:26,906 Stage-11 map = 100%,  reduce = 100%, Cumulative CPU 9.09 sec
MapReduce Total cumulative CPU time: 9 seconds 90 msec
Ended Job = job_1428405026382_0136
Stage-21 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/07 15:13:33 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/07 15:13:33 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/07 15:13:33 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/07 15:13:33 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150407151111_e20653d1-7b3c-43f2-9dcd-968ed960cadc.log
2015-04-07 03:13:34	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-07 03:13:36	Dump the side-table for tag: 1 with group count: 10 into file: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10013/HashTable-Stage-15/MapJoin-mapfile01--.hashtable
2015-04-07 03:13:36	Uploaded 1 File to: file:/tmp/root/f5d596bc-6b80-4159-aa12-772770717c92/hive_2015-04-07_15-11-04_105_4696680433154605670-1/-local-10013/HashTable-Stage-15/MapJoin-mapfile01--.hashtable (458 bytes)
2015-04-07 03:13:36	End of local task; Time Taken: 2.2 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 5 out of 8
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1428405026382_0137, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0137/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0137
Hadoop job information for Stage-15: number of mappers: 7; number of reducers: 0
2015-04-07 15:13:42,820 Stage-15 map = 0%,  reduce = 0%
2015-04-07 15:13:48,149 Stage-15 map = 14%,  reduce = 0%, Cumulative CPU 1.44 sec
2015-04-07 15:14:03,118 Stage-15 map = 18%,  reduce = 0%, Cumulative CPU 108.01 sec
2015-04-07 15:14:10,815 Stage-15 map = 33%,  reduce = 0%, Cumulative CPU 148.41 sec
2015-04-07 15:14:11,884 Stage-15 map = 42%,  reduce = 0%, Cumulative CPU 164.27 sec
2015-04-07 15:14:18,280 Stage-15 map = 55%,  reduce = 0%, Cumulative CPU 195.89 sec
2015-04-07 15:14:21,477 Stage-15 map = 78%,  reduce = 0%, Cumulative CPU 211.94 sec
2015-04-07 15:14:23,608 Stage-15 map = 80%,  reduce = 0%, Cumulative CPU 214.57 sec
2015-04-07 15:14:24,677 Stage-15 map = 86%,  reduce = 0%, Cumulative CPU 224.39 sec
2015-04-07 15:14:34,304 Stage-15 map = 93%,  reduce = 0%, Cumulative CPU 244.86 sec
2015-04-07 15:14:37,494 Stage-15 map = 100%,  reduce = 0%, Cumulative CPU 248.75 sec
MapReduce Total cumulative CPU time: 4 minutes 8 seconds 750 msec
Ended Job = job_1428405026382_0137
Launching Job 6 out of 8
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0138, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0138/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0138
Hadoop job information for Stage-4: number of mappers: 3; number of reducers: 1
2015-04-07 15:14:44,233 Stage-4 map = 0%,  reduce = 0%
2015-04-07 15:14:49,547 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 4.71 sec
2015-04-07 15:14:54,838 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1428405026382_0138
Launching Job 7 out of 8
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0139, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0139/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0139
Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1
2015-04-07 15:15:01,464 Stage-5 map = 0%,  reduce = 0%
2015-04-07 15:15:06,752 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 1.71 sec
2015-04-07 15:15:12,081 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 3.4 sec
MapReduce Total cumulative CPU time: 3 seconds 400 msec
Ended Job = job_1428405026382_0139
Launching Job 8 out of 8
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428405026382_0140, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428405026382_0140/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428405026382_0140
Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1
2015-04-07 15:15:18,748 Stage-6 map = 0%,  reduce = 0%
2015-04-07 15:15:25,095 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2015-04-07 15:15:30,391 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 3.13 sec
MapReduce Total cumulative CPU time: 3 seconds 130 msec
Ended Job = job_1428405026382_0140
MapReduce Jobs Launched: 
Stage-Stage-17: Map: 46   Cumulative CPU: 383.97 sec   HDFS Read: 1118552335 HDFS Write: 2129846636 SUCCESS
Stage-Stage-10: Map: 46  Reduce: 179   Cumulative CPU: 947.64 sec   HDFS Read: 1118552335 HDFS Write: 17462 SUCCESS
Stage-Stage-11: Map: 4  Reduce: 1   Cumulative CPU: 9.09 sec   HDFS Read: 64761 HDFS Write: 294 SUCCESS
Stage-Stage-15: Map: 7   Cumulative CPU: 248.75 sec   HDFS Read: 2129859657 HDFS Write: 5424 SUCCESS
Stage-Stage-4: Map: 3  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 7686 HDFS Write: 888 SUCCESS
Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 3.4 sec   HDFS Read: 1294 HDFS Write: 910 SUCCESS
Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 3.13 sec   HDFS Read: 1316 HDFS Write: 789 SUCCESS
Total MapReduce CPU Time Spent: 26 minutes 42 seconds 80 msec
OK
-6.365080051001578E9	SD	Ziebach County	3	1
-5.723514322407739E9	SC	Fairfield County	3	2
-5.491662288054659E9	TN	Williamson County	3	3
-5.476652643725031E9	LA	Franklin Parish	3	4
-4.846576835536714E9	MI	Luce County	3	5
-4.817315300917294E9	OH	Richland County	3	6
-4.386919429482996E9	AL	Walker County	3	7
-3.510681481448732E9	GA	Barrow County	3	8
-3.073433747904151E9	MO	Daviess County	3	9
-2.232598000239135E8			3	10
-2.1699370540772194E8	SC		3	11
-6.365080051001579E9	SD	NULL	1	1
-5.940508027815457E9	SC	NULL	1	2
-5.491662288054659E9	TN	NULL	1	3
-5.47665264372503E9	LA	NULL	1	4
-4.846576835536715E9	MI	NULL	1	5
-4.817315300917293E9	OH	NULL	1	6
-4.386919429482996E9	AL	NULL	1	7
-3.5106814814487314E9	GA	NULL	1	8
-3.073433747904151E9	MO	NULL	1	9
-2.2325980002391353E8		NULL	1	10
-4.41320896059106E10	NULL	NULL	0	1
Time taken: 267.538 seconds, Fetched: 22 row(s)
hive> 