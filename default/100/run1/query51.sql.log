15/04/06 20:24:57 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/06 20:24:57 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/06 20:24:57 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/06 20:24:57 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist

Logging initialized using configuration in file:/etc/hive/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive> use tpcds_bin_partitioned_orc_100; source query51.sql;
OK
Time taken: 2.809 seconds
Query ID = root_20150406202525_a18fdd5a-7250-4999-82f2-995707e42313
Total jobs = 7
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/06 20:25:31 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/06 20:25:31 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/06 20:25:31 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/06 20:25:31 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150406202525_a18fdd5a-7250-4999-82f2-995707e42313.log
2015-04-06 08:25:32	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-06 08:25:35	Dump the side-table for tag: 1 with group count: 366 into file: file:/tmp/root/77f1a7d0-f0fb-4368-b314-353fd2dc32d6/hive_2015-04-06_20-25-05_470_1400289377633213364-1/-local-10012/HashTable-Stage-2/MapJoin-mapfile01--.hashtable
2015-04-06 08:25:36	Uploaded 1 File to: file:/tmp/root/77f1a7d0-f0fb-4368-b314-353fd2dc32d6/hive_2015-04-06_20-25-05_470_1400289377633213364-1/-local-10012/HashTable-Stage-2/MapJoin-mapfile01--.hashtable (13499 bytes)
2015-04-06 08:25:36	End of local task; Time Taken: 3.767 sec.
Execution completed successfully
MapredLocal task succeeded
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/06 20:25:43 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/06 20:25:43 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/06 20:25:43 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/06 20:25:43 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150406202525_a18fdd5a-7250-4999-82f2-995707e42313.log
2015-04-06 08:25:44	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-06 08:25:47	Dump the side-table for tag: 1 with group count: 366 into file: file:/tmp/root/77f1a7d0-f0fb-4368-b314-353fd2dc32d6/hive_2015-04-06_20-25-05_470_1400289377633213364-1/-local-10014/HashTable-Stage-8/MapJoin-mapfile11--.hashtable
2015-04-06 08:25:48	Uploaded 1 File to: file:/tmp/root/77f1a7d0-f0fb-4368-b314-353fd2dc32d6/hive_2015-04-06_20-25-05_470_1400289377633213364-1/-local-10014/HashTable-Stage-8/MapJoin-mapfile11--.hashtable (13499 bytes)
2015-04-06 08:25:48	End of local task; Time Taken: 3.816 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 7
Number of reduce tasks not specified. Estimated from input data size: 179
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0074, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0074/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0074
Hadoop job information for Stage-2: number of mappers: 46; number of reducers: 179
2015-04-06 20:26:05,686 Stage-2 map = 0%,  reduce = 0%
2015-04-06 20:26:21,808 Stage-2 map = 4%,  reduce = 0%, Cumulative CPU 185.0 sec
2015-04-06 20:26:25,027 Stage-2 map = 28%,  reduce = 0%, Cumulative CPU 311.83 sec
2015-04-06 20:26:26,104 Stage-2 map = 60%,  reduce = 0%, Cumulative CPU 382.49 sec
2015-04-06 20:26:27,174 Stage-2 map = 76%,  reduce = 0%, Cumulative CPU 399.71 sec
2015-04-06 20:26:28,241 Stage-2 map = 80%,  reduce = 0%, Cumulative CPU 443.18 sec
2015-04-06 20:26:29,307 Stage-2 map = 81%,  reduce = 0%, Cumulative CPU 450.5 sec
2015-04-06 20:26:31,448 Stage-2 map = 85%,  reduce = 0%, Cumulative CPU 494.47 sec
2015-04-06 20:26:32,523 Stage-2 map = 86%,  reduce = 0%, Cumulative CPU 495.73 sec
2015-04-06 20:26:34,662 Stage-2 map = 90%,  reduce = 0%, Cumulative CPU 533.43 sec
2015-04-06 20:26:36,817 Stage-2 map = 90%,  reduce = 4%, Cumulative CPU 543.06 sec
2015-04-06 20:26:38,174 Stage-2 map = 92%,  reduce = 5%, Cumulative CPU 584.51 sec
2015-04-06 20:26:39,247 Stage-2 map = 93%,  reduce = 7%, Cumulative CPU 590.17 sec
2015-04-06 20:26:40,320 Stage-2 map = 93%,  reduce = 8%, Cumulative CPU 602.61 sec
2015-04-06 20:26:41,389 Stage-2 map = 93%,  reduce = 10%, Cumulative CPU 630.53 sec
2015-04-06 20:26:42,459 Stage-2 map = 93%,  reduce = 11%, Cumulative CPU 636.72 sec
2015-04-06 20:26:43,528 Stage-2 map = 94%,  reduce = 13%, Cumulative CPU 659.05 sec
2015-04-06 20:26:44,597 Stage-2 map = 94%,  reduce = 14%, Cumulative CPU 677.95 sec
2015-04-06 20:26:45,666 Stage-2 map = 94%,  reduce = 16%, Cumulative CPU 687.98 sec
2015-04-06 20:26:46,734 Stage-2 map = 94%,  reduce = 19%, Cumulative CPU 725.46 sec
2015-04-06 20:26:47,771 Stage-2 map = 94%,  reduce = 21%, Cumulative CPU 736.37 sec
2015-04-06 20:26:48,838 Stage-2 map = 94%,  reduce = 22%, Cumulative CPU 748.31 sec
2015-04-06 20:26:49,907 Stage-2 map = 96%,  reduce = 24%, Cumulative CPU 784.91 sec
2015-04-06 20:26:50,975 Stage-2 map = 96%,  reduce = 26%, Cumulative CPU 798.26 sec
2015-04-06 20:26:52,045 Stage-2 map = 97%,  reduce = 28%, Cumulative CPU 816.89 sec
2015-04-06 20:26:53,126 Stage-2 map = 99%,  reduce = 30%, Cumulative CPU 840.32 sec
2015-04-06 20:26:54,197 Stage-2 map = 100%,  reduce = 31%, Cumulative CPU 852.34 sec
2015-04-06 20:26:55,267 Stage-2 map = 100%,  reduce = 44%, Cumulative CPU 949.13 sec
2015-04-06 20:26:56,336 Stage-2 map = 100%,  reduce = 56%, Cumulative CPU 1134.2 sec
2015-04-06 20:26:57,404 Stage-2 map = 100%,  reduce = 80%, Cumulative CPU 1582.22 sec
2015-04-06 20:26:58,469 Stage-2 map = 100%,  reduce = 99%, Cumulative CPU 1951.77 sec
2015-04-06 20:26:59,533 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 1955.44 sec
MapReduce Total cumulative CPU time: 32 minutes 35 seconds 440 msec
Ended Job = job_1428164231378_0074
Launching Job 2 out of 7
Number of reduce tasks not specified. Estimated from input data size: 68
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0075, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0075/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0075
Hadoop job information for Stage-8: number of mappers: 18; number of reducers: 68
2015-04-06 20:27:13,206 Stage-8 map = 0%,  reduce = 0%
2015-04-06 20:27:23,811 Stage-8 map = 6%,  reduce = 0%, Cumulative CPU 6.22 sec
2015-04-06 20:27:24,880 Stage-8 map = 62%,  reduce = 0%, Cumulative CPU 129.0 sec
2015-04-06 20:27:25,939 Stage-8 map = 73%,  reduce = 0%, Cumulative CPU 149.35 sec
2015-04-06 20:27:27,010 Stage-8 map = 75%,  reduce = 0%, Cumulative CPU 151.24 sec
2015-04-06 20:27:28,077 Stage-8 map = 84%,  reduce = 0%, Cumulative CPU 171.42 sec
2015-04-06 20:27:29,148 Stage-8 map = 85%,  reduce = 0%, Cumulative CPU 175.52 sec
2015-04-06 20:27:31,288 Stage-8 map = 92%,  reduce = 0%, Cumulative CPU 192.56 sec
2015-04-06 20:27:34,490 Stage-8 map = 93%,  reduce = 9%, Cumulative CPU 213.25 sec
2015-04-06 20:27:35,561 Stage-8 map = 94%,  reduce = 13%, Cumulative CPU 219.57 sec
2015-04-06 20:27:36,633 Stage-8 map = 96%,  reduce = 18%, Cumulative CPU 225.78 sec
2015-04-06 20:27:37,705 Stage-8 map = 98%,  reduce = 24%, Cumulative CPU 239.22 sec
2015-04-06 20:27:38,776 Stage-8 map = 98%,  reduce = 30%, Cumulative CPU 244.17 sec
2015-04-06 20:27:40,917 Stage-8 map = 100%,  reduce = 32%, Cumulative CPU 255.78 sec
2015-04-06 20:27:42,259 Stage-8 map = 100%,  reduce = 43%, Cumulative CPU 293.93 sec
2015-04-06 20:27:43,328 Stage-8 map = 100%,  reduce = 91%, Cumulative CPU 513.59 sec
2015-04-06 20:27:44,394 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 554.91 sec
MapReduce Total cumulative CPU time: 9 minutes 14 seconds 910 msec
Ended Job = job_1428164231378_0075
Launching Job 3 out of 7
Number of reduce tasks not specified. Estimated from input data size: 16
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0076, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0076/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0076
Hadoop job information for Stage-3: number of mappers: 6; number of reducers: 16
2015-04-06 20:27:51,065 Stage-3 map = 0%,  reduce = 0%
2015-04-06 20:28:01,768 Stage-3 map = 34%,  reduce = 0%, Cumulative CPU 48.87 sec
2015-04-06 20:28:04,967 Stage-3 map = 47%,  reduce = 0%, Cumulative CPU 66.92 sec
2015-04-06 20:28:08,164 Stage-3 map = 58%,  reduce = 0%, Cumulative CPU 85.5 sec
2015-04-06 20:28:11,357 Stage-3 map = 63%,  reduce = 0%, Cumulative CPU 102.89 sec
2015-04-06 20:28:12,420 Stage-3 map = 74%,  reduce = 1%, Cumulative CPU 107.77 sec
2015-04-06 20:28:13,488 Stage-3 map = 80%,  reduce = 7%, Cumulative CPU 123.4 sec
2015-04-06 20:28:15,619 Stage-3 map = 80%,  reduce = 12%, Cumulative CPU 124.04 sec
2015-04-06 20:28:16,689 Stage-3 map = 83%,  reduce = 17%, Cumulative CPU 135.8 sec
2015-04-06 20:28:27,339 Stage-3 map = 89%,  reduce = 17%, Cumulative CPU 174.99 sec
2015-04-06 20:28:28,405 Stage-3 map = 94%,  reduce = 20%, Cumulative CPU 178.95 sec
2015-04-06 20:28:29,470 Stage-3 map = 100%,  reduce = 24%, Cumulative CPU 184.06 sec
2015-04-06 20:28:31,601 Stage-3 map = 100%,  reduce = 53%, Cumulative CPU 204.53 sec
2015-04-06 20:28:32,665 Stage-3 map = 100%,  reduce = 65%, Cumulative CPU 215.55 sec
2015-04-06 20:28:34,793 Stage-3 map = 100%,  reduce = 77%, Cumulative CPU 293.81 sec
2015-04-06 20:28:35,864 Stage-3 map = 100%,  reduce = 78%, Cumulative CPU 298.29 sec
2015-04-06 20:28:36,929 Stage-3 map = 100%,  reduce = 83%, Cumulative CPU 312.37 sec
2015-04-06 20:28:37,996 Stage-3 map = 100%,  reduce = 96%, Cumulative CPU 356.22 sec
2015-04-06 20:28:39,065 Stage-3 map = 100%,  reduce = 98%, Cumulative CPU 362.41 sec
2015-04-06 20:28:40,127 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 370.55 sec
MapReduce Total cumulative CPU time: 6 minutes 10 seconds 550 msec
Ended Job = job_1428164231378_0076
Launching Job 4 out of 7
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0077, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0077/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0077
Hadoop job information for Stage-9: number of mappers: 4; number of reducers: 7
2015-04-06 20:28:46,517 Stage-9 map = 0%,  reduce = 0%
2015-04-06 20:28:53,940 Stage-9 map = 25%,  reduce = 0%, Cumulative CPU 4.92 sec
2015-04-06 20:28:57,138 Stage-9 map = 52%,  reduce = 0%, Cumulative CPU 29.34 sec
2015-04-06 20:28:59,529 Stage-9 map = 58%,  reduce = 0%, Cumulative CPU 36.3 sec
2015-04-06 20:29:00,594 Stage-9 map = 74%,  reduce = 0%, Cumulative CPU 41.49 sec
2015-04-06 20:29:02,722 Stage-9 map = 77%,  reduce = 0%, Cumulative CPU 48.44 sec
2015-04-06 20:29:04,852 Stage-9 map = 86%,  reduce = 5%, Cumulative CPU 50.8 sec
2015-04-06 20:29:05,921 Stage-9 map = 89%,  reduce = 17%, Cumulative CPU 56.08 sec
2015-04-06 20:29:08,053 Stage-9 map = 89%,  reduce = 20%, Cumulative CPU 56.34 sec
2015-04-06 20:29:09,120 Stage-9 map = 92%,  reduce = 25%, Cumulative CPU 60.68 sec
2015-04-06 20:29:19,757 Stage-9 map = 100%,  reduce = 25%, Cumulative CPU 77.52 sec
2015-04-06 20:29:20,830 Stage-9 map = 100%,  reduce = 35%, Cumulative CPU 80.74 sec
2015-04-06 20:29:24,027 Stage-9 map = 100%,  reduce = 72%, Cumulative CPU 116.38 sec
2015-04-06 20:29:27,216 Stage-9 map = 100%,  reduce = 90%, Cumulative CPU 143.94 sec
2015-04-06 20:29:28,280 Stage-9 map = 100%,  reduce = 97%, Cumulative CPU 151.57 sec
2015-04-06 20:29:29,365 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 158.1 sec
MapReduce Total cumulative CPU time: 2 minutes 38 seconds 100 msec
Ended Job = job_1428164231378_0077
Launching Job 5 out of 7
Number of reduce tasks not specified. Estimated from input data size: 23
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0078, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0078/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0078
Hadoop job information for Stage-4: number of mappers: 8; number of reducers: 23
2015-04-06 20:29:35,830 Stage-4 map = 0%,  reduce = 0%
2015-04-06 20:29:46,513 Stage-4 map = 2%,  reduce = 0%, Cumulative CPU 62.54 sec
2015-04-06 20:29:49,704 Stage-4 map = 35%,  reduce = 0%, Cumulative CPU 93.22 sec
2015-04-06 20:29:51,831 Stage-4 map = 42%,  reduce = 0%, Cumulative CPU 99.43 sec
2015-04-06 20:29:52,895 Stage-4 map = 52%,  reduce = 0%, Cumulative CPU 118.48 sec
2015-04-06 20:29:55,027 Stage-4 map = 61%,  reduce = 0%, Cumulative CPU 129.5 sec
2015-04-06 20:29:56,089 Stage-4 map = 63%,  reduce = 0%, Cumulative CPU 140.81 sec
2015-04-06 20:29:58,216 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 157.89 sec
2015-04-06 20:29:59,281 Stage-4 map = 69%,  reduce = 0%, Cumulative CPU 161.69 sec
2015-04-06 20:30:00,350 Stage-4 map = 69%,  reduce = 4%, Cumulative CPU 164.94 sec
2015-04-06 20:30:01,418 Stage-4 map = 75%,  reduce = 7%, Cumulative CPU 189.63 sec
2015-04-06 20:30:02,485 Stage-4 map = 75%,  reduce = 8%, Cumulative CPU 190.57 sec
2015-04-06 20:30:04,589 Stage-4 map = 83%,  reduce = 8%, Cumulative CPU 211.69 sec
2015-04-06 20:30:05,654 Stage-4 map = 88%,  reduce = 8%, Cumulative CPU 213.5 sec
2015-04-06 20:30:06,719 Stage-4 map = 88%,  reduce = 14%, Cumulative CPU 216.39 sec
2015-04-06 20:30:07,785 Stage-4 map = 88%,  reduce = 19%, Cumulative CPU 229.16 sec
2015-04-06 20:30:08,849 Stage-4 map = 88%,  reduce = 21%, Cumulative CPU 230.22 sec
2015-04-06 20:30:14,165 Stage-4 map = 92%,  reduce = 21%, Cumulative CPU 255.23 sec
2015-04-06 20:30:15,231 Stage-4 map = 96%,  reduce = 21%, Cumulative CPU 256.31 sec
2015-04-06 20:30:16,297 Stage-4 map = 100%,  reduce = 26%, Cumulative CPU 261.15 sec
2015-04-06 20:30:17,358 Stage-4 map = 100%,  reduce = 34%, Cumulative CPU 267.51 sec
2015-04-06 20:30:18,394 Stage-4 map = 100%,  reduce = 37%, Cumulative CPU 270.81 sec
2015-04-06 20:30:19,456 Stage-4 map = 100%,  reduce = 68%, Cumulative CPU 343.88 sec
2015-04-06 20:30:20,520 Stage-4 map = 100%,  reduce = 71%, Cumulative CPU 373.66 sec
2015-04-06 20:30:21,880 Stage-4 map = 100%,  reduce = 78%, Cumulative CPU 413.55 sec
2015-04-06 20:30:22,942 Stage-4 map = 100%,  reduce = 86%, Cumulative CPU 450.5 sec
2015-04-06 20:30:24,005 Stage-4 map = 100%,  reduce = 90%, Cumulative CPU 468.0 sec
2015-04-06 20:30:25,067 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 513.23 sec
MapReduce Total cumulative CPU time: 8 minutes 33 seconds 230 msec
Ended Job = job_1428164231378_0078
Launching Job 6 out of 7
Number of reduce tasks not specified. Estimated from input data size: 19
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0079, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0079/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0079
Hadoop job information for Stage-5: number of mappers: 6; number of reducers: 19
2015-04-06 20:30:31,211 Stage-5 map = 0%,  reduce = 0%
2015-04-06 20:30:41,054 Stage-5 map = 26%,  reduce = 0%, Cumulative CPU 47.96 sec
2015-04-06 20:30:43,185 Stage-5 map = 31%,  reduce = 0%, Cumulative CPU 49.99 sec
2015-04-06 20:30:47,440 Stage-5 map = 46%,  reduce = 0%, Cumulative CPU 86.66 sec
2015-04-06 20:30:50,609 Stage-5 map = 60%,  reduce = 0%, Cumulative CPU 104.64 sec
2015-04-06 20:30:52,734 Stage-5 map = 64%,  reduce = 0%, Cumulative CPU 115.85 sec
2015-04-06 20:30:53,800 Stage-5 map = 67%,  reduce = 6%, Cumulative CPU 123.1 sec
2015-04-06 20:30:54,866 Stage-5 map = 67%,  reduce = 11%, Cumulative CPU 125.94 sec
2015-04-06 20:30:55,931 Stage-5 map = 76%,  reduce = 11%, Cumulative CPU 140.9 sec
2015-04-06 20:30:59,130 Stage-5 map = 78%,  reduce = 11%, Cumulative CPU 155.48 sec
2015-04-06 20:31:06,578 Stage-5 map = 89%,  reduce = 11%, Cumulative CPU 191.99 sec
2015-04-06 20:31:07,640 Stage-5 map = 89%,  reduce = 14%, Cumulative CPU 193.15 sec
2015-04-06 20:31:08,705 Stage-5 map = 100%,  reduce = 15%, Cumulative CPU 199.92 sec
2015-04-06 20:31:09,769 Stage-5 map = 100%,  reduce = 45%, Cumulative CPU 214.71 sec
2015-04-06 20:31:11,893 Stage-5 map = 100%,  reduce = 47%, Cumulative CPU 219.44 sec
2015-04-06 20:31:12,955 Stage-5 map = 100%,  reduce = 77%, Cumulative CPU 305.09 sec
2015-04-06 20:31:15,077 Stage-5 map = 100%,  reduce = 92%, Cumulative CPU 350.03 sec
2015-04-06 20:31:16,141 Stage-5 map = 100%,  reduce = 99%, Cumulative CPU 369.8 sec
2015-04-06 20:31:17,200 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 372.81 sec
MapReduce Total cumulative CPU time: 6 minutes 12 seconds 810 msec
Ended Job = job_1428164231378_0079
Launching Job 7 out of 7
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0080, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0080/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0080
Hadoop job information for Stage-6: number of mappers: 4; number of reducers: 1
2015-04-06 20:31:23,455 Stage-6 map = 0%,  reduce = 0%
2015-04-06 20:31:29,815 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 13.44 sec
2015-04-06 20:31:35,417 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 14.86 sec
MapReduce Total cumulative CPU time: 14 seconds 860 msec
Ended Job = job_1428164231378_0080
MapReduce Jobs Launched: 
Stage-Stage-2: Map: 46  Reduce: 179   Cumulative CPU: 1955.44 sec   HDFS Read: 1463615734 HDFS Write: 1055571029 SUCCESS
Stage-Stage-8: Map: 18  Reduce: 68   Cumulative CPU: 554.91 sec   HDFS Read: 412554287 HDFS Write: 457811374 SUCCESS
Stage-Stage-3: Map: 6  Reduce: 16   Cumulative CPU: 370.55 sec   HDFS Read: 1055618618 HDFS Write: 1057797693 SUCCESS
Stage-Stage-9: Map: 4  Reduce: 7   Cumulative CPU: 158.1 sec   HDFS Read: 457829702 HDFS Write: 457814754 SUCCESS
Stage-Stage-4: Map: 8  Reduce: 23   Cumulative CPU: 513.23 sec   HDFS Read: 1515619610 HDFS Write: 1231897171 SUCCESS
Stage-Stage-5: Map: 6  Reduce: 19   Cumulative CPU: 372.81 sec   HDFS Read: 1231904044 HDFS Write: 14331421 SUCCESS
Stage-Stage-6: Map: 4  Reduce: 1   Cumulative CPU: 14.86 sec   HDFS Read: 14336960 HDFS Write: 7693 SUCCESS
Total MapReduce CPU Time Spent: 0 days 1 hours 5 minutes 39 seconds 900 msec
OK
1	1999-06-03	56.939998626708984	39.310001373291016	56.939998626708984	39.310001373291016
4	1999-06-04	96.8700008392334	41.66999816894531	96.8700008392334	41.66999816894531
4	1999-06-05	NULL	43.04999816417694	96.8700008392334	43.04999816417694
4	1999-06-09	163.94000053405762	NULL	163.94000053405762	155.3499974012375
4	1999-06-14	261.7700023651123	NULL	261.7700023651123	239.38999927043915
7	1999-06-02	29.899999618530273	18.020000338554382	29.899999618530273	18.020000338554382
10	1999-06-02	64.83999633789062	NULL	64.83999633789062	19.920000076293945
17	2000-01-02	139.89999771118164	56.24000144004822	139.89999771118164	56.24000144004822
17	2000-01-03	NULL	77.22000098228455	139.89999771118164	77.22000098228455
23	2000-01-03	NULL	8.130000114440918	8.550000190734863	8.130000114440918
23	2000-01-04	172.24999332427979	26.21999979019165	172.24999332427979	26.21999979019165
23	2000-01-07	245.85999393463135	109.87999963760376	245.85999393463135	109.87999963760376
23	2000-01-08	248.31999397277832	116.21999979019165	248.31999397277832	116.21999979019165
23	2000-01-09	NULL	178.97000169754028	248.31999397277832	178.97000169754028
23	2000-01-12	NULL	181.46000170707703	248.31999397277832	181.46000170707703
23	2000-01-13	372.13999366760254	248.7100007534027	372.13999366760254	248.7100007534027
23	2000-01-15	NULL	329.93000197410583	372.13999366760254	329.93000197410583
23	2000-01-17	395.1299934387207	NULL	395.1299934387207	329.93000197410583
23	2000-01-19	442.1399917602539	358.71000266075134	442.1399917602539	358.71000266075134
23	2000-01-23	NULL	439.8500020503998	442.1399917602539	439.8500020503998
23	2000-01-25	456.74999141693115	NULL	456.74999141693115	439.8500020503998
28	1999-06-02	NULL	11.720000267028809	78.18000030517578	11.720000267028809
28	1999-06-03	139.18999862670898	NULL	139.18999862670898	11.720000267028809
28	1999-06-04	NULL	30.390000343322754	139.18999862670898	30.390000343322754
28	1999-06-05	NULL	64.27999973297119	139.18999862670898	64.27999973297119
28	1999-06-07	NULL	106.40999984741211	139.18999862670898	106.40999984741211
28	1999-06-08	195.04999923706055	NULL	195.04999923706055	106.40999984741211
28	1999-06-09	NULL	108.049999833107	195.04999923706055	108.049999833107
28	1999-06-10	250.29999923706055	NULL	250.29999923706055	108.049999833107
28	1999-06-12	409.27999687194824	138.38999998569489	409.27999687194824	138.38999998569489
28	1999-06-15	NULL	178.66999876499176	409.27999687194824	178.66999876499176
28	1999-06-16	NULL	248.59999907016754	409.27999687194824	248.59999907016754
28	1999-06-17	467.93999671936035	NULL	467.93999671936035	248.59999907016754
28	1999-06-18	NULL	254.29999899864197	467.93999671936035	254.29999899864197
28	1999-06-19	NULL	349.9399983882904	467.93999671936035	349.9399983882904
34	1999-06-07	NULL	37.31999969482422	56.15000104904175	37.31999969482422
35	2000-01-02	215.65000200271606	69.1200008392334	215.65000200271606	69.1200008392334
35	2000-01-03	268.15000200271606	NULL	268.15000200271606	69.1200008392334
35	2000-01-04	NULL	167.59000205993652	268.15000200271606	167.59000205993652
35	2000-01-07	NULL	177.22000217437744	268.15000200271606	177.22000217437744
35	2000-01-08	NULL	192.00000220537186	268.15000200271606	192.00000220537186
35	2000-01-17	NULL	217.07000190019608	268.15000200271606	217.07000190019608
35	2000-01-18	271.2600018978119	NULL	271.2600018978119	217.07000190019608
35	2000-01-19	439.6400067806244	NULL	439.6400067806244	217.07000190019608
35	2000-01-20	482.91000723838806	442.68999511003494	482.91000723838806	442.68999511003494
40	1999-06-07	31.010000228881836	NULL	31.010000228881836	26.399999618530273
40	1999-06-08	31.010000228881836	NULL	31.010000228881836	26.399999618530273
43	1999-06-02	21.719999313354492	14.219999611377716	21.719999313354492	14.219999611377716
44	1999-06-03	130.9999988079071	53.34000039100647	130.9999988079071	53.34000039100647
44	1999-06-06	190.650000333786	NULL	190.650000333786	158.01000428199768
44	1999-06-07	NULL	180.15000367164612	190.650000333786	180.15000367164612
44	1999-06-08	211.0800006389618	NULL	211.0800006389618	180.15000367164612
47	2000-01-02	80.58000183105469	13.81000018119812	80.58000183105469	13.81000018119812
49	1999-06-04	106.8700008392334	16.510000228881836	106.8700008392334	16.510000228881836
49	1999-06-05	185.74000358581543	NULL	185.74000358581543	16.510000228881836
49	1999-06-06	NULL	81.85999870300293	185.74000358581543	81.85999870300293
49	1999-06-09	NULL	134.33999824523926	185.74000358581543	134.33999824523926
49	1999-06-12	NULL	165.0499973297119	185.74000358581543	165.0499973297119
50	1999-06-06	124.71999740600586	69.19000196456909	124.71999740600586	69.19000196456909
50	1999-06-07	132.9799976348877	90.59000158309937	132.9799976348877	90.59000158309937
50	1999-06-08	295.4799976348877	116.77000188827515	295.4799976348877	116.77000188827515
50	1999-06-10	NULL	116.77000188827515	295.4799976348877	116.77000188827515
50	1999-06-11	300.9099974632263	211.4700002670288	300.9099974632263	211.4700002670288
50	1999-06-12	310.76999711990356	284.10999965667725	310.76999711990356	284.10999965667725
50	1999-06-14	NULL	305.539999961853	310.76999711990356	305.539999961853
58	1999-06-05	129.30999755859375	NULL	129.30999755859375	24.059999465942383
58	1999-06-06	NULL	69.39999961853027	129.30999755859375	69.39999961853027
58	1999-06-07	174.38999938964844	NULL	174.38999938964844	69.39999961853027
58	1999-06-08	NULL	150.73000144958496	174.38999938964844	150.73000144958496
65	2000-01-02	126.56999969482422	19.610000252723694	126.56999969482422	19.610000252723694
65	2000-01-03	NULL	106.55999720096588	126.56999969482422	106.55999720096588
65	2000-01-04	NULL	117.6899973154068	126.56999969482422	117.6899973154068
65	2000-01-05	NULL	119.6899973154068	126.56999969482422	119.6899973154068
68	1999-06-20	174.24999809265137	155.65999817848206	174.24999809265137	155.65999817848206
68	1999-06-21	NULL	170.22999787330627	174.24999809265137	170.22999787330627
70	1999-06-03	99.85000085830688	57.33999824523926	99.85000085830688	57.33999824523926
70	1999-06-05	NULL	85.27999877929688	99.85000085830688	85.27999877929688
73	1999-06-03	52.36000061035156	NULL	52.36000061035156	25.5
73	1999-06-04	273.3000030517578	NULL	273.3000030517578	25.5
73	1999-06-05	NULL	33.63000011444092	273.3000030517578	33.63000011444092
73	1999-06-06	NULL	161.9099988937378	273.3000030517578	161.9099988937378
73	1999-06-07	347.69000244140625	315.8000020980835	347.69000244140625	315.8000020980835
82	1999-06-03	NULL	8.539999961853027	103.19999694824219	8.539999961853027
82	1999-06-04	106.5799970626831	75.66000270843506	106.5799970626831	75.66000270843506
82	1999-06-05	NULL	76.9900027513504	106.5799970626831	76.9900027513504
82	1999-06-07	NULL	84.71000254154205	106.5799970626831	84.71000254154205
83	2000-01-04	261.71999740600586	241.78000259399414	261.71999740600586	241.78000259399414
83	2000-01-05	293.24999809265137	282.44000244140625	293.24999809265137	282.44000244140625
89	2000-01-03	166.8800048828125	32.69000035524368	166.8800048828125	32.69000035524368
89	2000-01-05	172.19000482559204	NULL	172.19000482559204	32.69000035524368
89	2000-01-08	NULL	80.80000132322311	172.19000482559204	80.80000132322311
89	2000-01-09	NULL	120.81000059843063	172.19000482559204	120.81000059843063
89	2000-01-14	NULL	121.23000058531761	172.19000482559204	121.23000058531761
89	2000-01-15	NULL	131.80000028014183	172.19000482559204	131.80000028014183
100	1999-06-02	86.86000061035156	84.64000034332275	86.86000061035156	84.64000034332275
100	1999-06-11	287.4300060272217	NULL	287.4300060272217	208.92000114917755
100	1999-06-12	312.8500061035156	NULL	312.8500061035156	208.92000114917755
100	1999-06-13	NULL	218.01000106334686	312.8500061035156	218.01000106334686
100	1999-06-14	NULL	235.6500004529953	312.8500061035156	235.6500004529953
100	1999-06-15	NULL	255.8100003004074	312.8500061035156	255.8100003004074
Time taken: 391.043 seconds, Fetched: 100 row(s)
hive> 