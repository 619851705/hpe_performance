15/04/06 20:09:42 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/06 20:09:42 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/06 20:09:42 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/06 20:09:42 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist

Logging initialized using configuration in file:/etc/hive/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
hive> use tpcds_bin_partitioned_orc_100; source query42.sql;
OK
Time taken: 2.56 seconds
Query ID = root_20150406200909_12be672a-7bda-4603-85a1-831ed4bb2c6e
Total jobs = 2
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/2.2.0.0-2041/hive/lib/hive-jdbc-0.14.0.2.2.0.0-2041-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/04/06 20:10:08 WARN conf.HiveConf: HiveConf of name hive.optimize.mapjoin.mapreduce does not exist
15/04/06 20:10:08 WARN conf.HiveConf: HiveConf of name hive.heapsize does not exist
15/04/06 20:10:08 WARN conf.HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
15/04/06 20:10:08 WARN conf.HiveConf: HiveConf of name hive.auto.convert.sortmerge.join.noconditionaltask does not exist
Execution log at: /tmp/root/root_20150406200909_12be672a-7bda-4603-85a1-831ed4bb2c6e.log
2015-04-06 08:10:09	Starting to launch local task to process map join;	maximum memory = 1065484288
2015-04-06 08:10:14	Dump the side-table for tag: 1 with group count: 3648 into file: file:/tmp/root/cf88dcd2-8d44-4e19-84bc-fd7f69ad0d5e/hive_2015-04-06_20-09-48_814_7226656115044682577-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile01--.hashtable
2015-04-06 08:10:14	Uploaded 1 File to: file:/tmp/root/cf88dcd2-8d44-4e19-84bc-fd7f69ad0d5e/hive_2015-04-06_20-09-48_814_7226656115044682577-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile01--.hashtable (108879 bytes)
2015-04-06 08:10:14	Dump the side-table for tag: 0 with group count: 31 into file: file:/tmp/root/cf88dcd2-8d44-4e19-84bc-fd7f69ad0d5e/hive_2015-04-06_20-09-48_814_7226656115044682577-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile10--.hashtable
2015-04-06 08:10:14	Uploaded 1 File to: file:/tmp/root/cf88dcd2-8d44-4e19-84bc-fd7f69ad0d5e/hive_2015-04-06_20-09-48_814_7226656115044682577-1/-local-10007/HashTable-Stage-3/MapJoin-mapfile10--.hashtable (914 bytes)
2015-04-06 08:10:14	End of local task; Time Taken: 5.004 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 179
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0064, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0064/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0064
Hadoop job information for Stage-3: number of mappers: 46; number of reducers: 179
2015-04-06 20:10:34,377 Stage-3 map = 0%,  reduce = 0%
2015-04-06 20:10:50,818 Stage-3 map = 5%,  reduce = 0%, Cumulative CPU 193.91 sec
2015-04-06 20:10:52,970 Stage-3 map = 12%,  reduce = 0%, Cumulative CPU 244.37 sec
2015-04-06 20:10:54,048 Stage-3 map = 53%,  reduce = 0%, Cumulative CPU 348.4 sec
2015-04-06 20:10:55,148 Stage-3 map = 91%,  reduce = 0%, Cumulative CPU 394.78 sec
2015-04-06 20:10:56,224 Stage-3 map = 95%,  reduce = 0%, Cumulative CPU 399.25 sec
2015-04-06 20:10:57,296 Stage-3 map = 99%,  reduce = 0%, Cumulative CPU 409.29 sec
2015-04-06 20:10:58,366 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 410.13 sec
2015-04-06 20:10:59,446 Stage-3 map = 100%,  reduce = 1%, Cumulative CPU 410.13 sec
2015-04-06 20:11:00,531 Stage-3 map = 100%,  reduce = 12%, Cumulative CPU 446.47 sec
2015-04-06 20:11:01,608 Stage-3 map = 100%,  reduce = 20%, Cumulative CPU 474.21 sec
2015-04-06 20:11:02,679 Stage-3 map = 100%,  reduce = 35%, Cumulative CPU 537.94 sec
2015-04-06 20:11:03,752 Stage-3 map = 100%,  reduce = 42%, Cumulative CPU 558.44 sec
2015-04-06 20:11:04,829 Stage-3 map = 100%,  reduce = 54%, Cumulative CPU 596.18 sec
2015-04-06 20:11:05,901 Stage-3 map = 100%,  reduce = 63%, Cumulative CPU 624.35 sec
2015-04-06 20:11:06,974 Stage-3 map = 100%,  reduce = 80%, Cumulative CPU 683.06 sec
2015-04-06 20:11:08,018 Stage-3 map = 100%,  reduce = 87%, Cumulative CPU 705.49 sec
2015-04-06 20:11:09,060 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 744.78 sec
MapReduce Total cumulative CPU time: 12 minutes 24 seconds 780 msec
Ended Job = job_1428164231378_0064
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1428164231378_0065, Tracking URL = http://f01hn02.hadoop:8088/proxy/application_1428164231378_0065/
Kill Command = /usr/hdp/2.2.0.0-2041/hadoop/bin/hadoop job  -kill job_1428164231378_0065
Hadoop job information for Stage-4: number of mappers: 4; number of reducers: 1
2015-04-06 20:11:16,080 Stage-4 map = 0%,  reduce = 0%
2015-04-06 20:11:21,398 Stage-4 map = 75%,  reduce = 0%, Cumulative CPU 4.45 sec
2015-04-06 20:11:22,469 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 6.33 sec
2015-04-06 20:11:26,743 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 7.69 sec
MapReduce Total cumulative CPU time: 7 seconds 690 msec
Ended Job = job_1428164231378_0065
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 46  Reduce: 179   Cumulative CPU: 744.78 sec   HDFS Read: 1616559019 HDFS Write: 17572 SUCCESS
Stage-Stage-4: Map: 4  Reduce: 1   Cumulative CPU: 7.69 sec   HDFS Read: 64871 HDFS Write: 374 SUCCESS
Total MapReduce CPU Time Spent: 12 minutes 32 seconds 470 msec
OK
1998	10	Electronics	3.4732440435282096E7
1998	1	Women	3.357753024198407E7
1998	6	Jewelry	3.282079976696171E7
1998	2	Men	3.2783996395330675E7
1998	3	Children	3.1540970958351344E7
1998	7	Home	3.1119099255155593E7
1998	8	Sports	3.0985293120796144E7
1998	4	Shoes	3.0512255107863516E7
1998	9	Books	3.005956852558887E7
1998	5	Music	2.5020268013839766E7
1998	NULL		376068.6298184395
Time taken: 99.037 seconds, Fetched: 11 row(s)
hive> 