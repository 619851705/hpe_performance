START hdp2.6_spark21_run_1_100_query34_sql_2017-04-07-09-22:  Fri Apr 7 09:22:34 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 09:22:34 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/07 09:22:34 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/07 09:22:34 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,c_first_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,c_salutation
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,c_preferred_cust_flag
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,cnt from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>    (select ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,ss_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,count(*) cnt
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     from store_sales,date_dim,store,household_demographics
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     where store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store_sales.ss_store_sk = store.s_store_sk  
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and (date_dim.d_dom between 1 and 3 or date_dim.d_dom between 25 and 28)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and (household_demographics.hd_buy_potential = '1001-5000' or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          household_demographics.hd_buy_potential = '5001-10000')
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and household_demographics.hd_vehicle_count > 0
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and (case when household_demographics.hd_vehicle_count > 0 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> then household_demographics.hd_dep_count/ household_demographics.hd_vehicle_count 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> else null 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> end)  > 1.2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and date_dim.d_year in (1998,1998+1,1998+2)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store.s_county in ('Kittitas County','Adams County','Richland County','Furnas County',
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                            'Orange County','Appanoose County','Franklin Parish','Tehama County')
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     group by ss_ticket_number,ss_customer_sk) dn,customer
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     where dn.ss_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       and cnt between 15 and 20
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     order by c_last_name,c_first_name,c_salutation,c_preferred_cust_flag desc;
STOP hdp2.6_spark21_run_1_100_query34_sql_2017-04-07-09-22:  Fri Apr 7 09:43:17 CDT 2017
