START hdp2.6_spark21_run_1_100_query31_sql_2017-04-06-19-06:  Thu Apr 6 19:06:35 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> with ss as
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales,date_dim,customer_address
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where ss_sold_date_sk = d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and ss_addr_sk=ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  group by ca_county,d_qoy, d_year),
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  ws as
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from web_sales,date_dim,customer_address
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where ws_sold_date_sk = d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and ws_bill_addr_sk=ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  group by ca_county,d_qoy, d_year)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  select
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss1.ca_county
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss1.d_year
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ws2.web_sales/ws1.web_sales web_q1_q2_increase
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss2.store_sales/ss1.store_sales store_q1_q2_increase
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ws3.web_sales/ws2.web_sales web_q2_q3_increase
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss3.store_sales/ss2.store_sales store_q2_q3_increase
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss ss1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss ss2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss ss3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ws ws1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ws ws2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ws ws3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ss1.d_qoy = 1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss1.d_year = 1998
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss1.ca_county = ss2.ca_county
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss2.d_qoy = 2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss2.d_year = 1998
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and ss2.ca_county = ss3.ca_county
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss3.d_qoy = 3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss3.d_year = 1998
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ss1.ca_county = ws1.ca_county
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws1.d_qoy = 1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws1.d_year = 1998
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws1.ca_county = ws2.ca_county
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws2.d_qoy = 2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws2.d_year = 1998
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws1.ca_county = ws3.ca_county
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws3.d_qoy = 3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and ws3.d_year =1998
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  order by web_q1_q2_increase;
17/04/06 19:06:36 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:36 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:36 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:36 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:36 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/06 19:06:36 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:36 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:36 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:36 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:36 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_1_100_query31_sql_2017-04-06-19-06:  Thu Apr 6 19:06:36 CDT 2017
