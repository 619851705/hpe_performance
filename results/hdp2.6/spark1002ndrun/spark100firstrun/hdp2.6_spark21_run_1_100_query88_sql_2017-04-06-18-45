START hdp2.6_spark21_run_1_100_query88_sql_2017-04-06-18-45:  Thu Apr 6 18:45:16 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:45:17 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 18:45:17 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 18:45:17 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h8_30_to_9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2)) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s1,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_to_9_30 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s2,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_30_to_10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s3,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_to_10_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s4,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_30_to_11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s5,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_to_11_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s6,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_30_to_12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s7,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h12_to_12_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ;
Error: org.apache.spark.sql.AnalysisException: Detected cartesian product for INNER join between logical plans
Join Inner
:- Join Inner
:  :- Join Inner
:  :  :- Join Inner
:  :  :  :- Join Inner
:  :  :  :  :- Join Inner
:  :  :  :  :  :- Aggregate [count(1) AS h8_30_to_9#18865L]
:  :  :  :  :  :  +- Project
:  :  :  :  :  :     +- Join Inner, (ss_store_sk#18880 = s_store_sk#18911)
:  :  :  :  :  :        :- Project [ss_store_sk#18880]
:  :  :  :  :  :        :  +- Join Inner, (ss_sold_time_sk#18874 = t_time_sk#18901)
:  :  :  :  :  :        :     :- Project [ss_sold_time_sk#18874, ss_store_sk#18880]
:  :  :  :  :  :        :     :  +- Join Inner, (ss_hdemo_sk#18878 = hd_demo_sk#18896)
:  :  :  :  :  :        :     :     :- Project [ss_sold_time_sk#18874, ss_hdemo_sk#18878, ss_store_sk#18880]
:  :  :  :  :  :        :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#18878) && isnotnull(ss_sold_time_sk#18874)) && isnotnull(ss_store_sk#18880))
:  :  :  :  :  :        :     :     :     +- Relation[ss_sold_time_sk#18874,ss_item_sk#18875,ss_customer_sk#18876,ss_cdemo_sk#18877,ss_hdemo_sk#18878,ss_addr_sk#18879,ss_store_sk#18880,ss_promo_sk#18881,ss_ticket_number#18882,ss_quantity#18883,ss_wholesale_cost#18884,ss_list_price#18885,ss_sales_price#18886,ss_ext_discount_amt#18887,ss_ext_sales_price#18888,ss_ext_wholesale_cost#18889,ss_ext_list_price#18890,ss_ext_tax#18891,ss_coupon_amt#18892,ss_net_paid#18893,ss_net_paid_inc_tax#18894,ss_net_profit#18895,ss_sold_date_sk#18873] parquet
:  :  :  :  :  :        :     :     +- Project [hd_demo_sk#18896]
:  :  :  :  :  :        :     :        +- Filter (((((hd_dep_count#18899 = 3) && (hd_vehicle_count#18900 <= 5)) || ((hd_dep_count#18899 = 0) && (hd_vehicle_count#18900 <= 2))) || ((hd_dep_count#18899 = 1) && (hd_vehicle_count#18900 <= 3))) && isnotnull(hd_demo_sk#18896))
:  :  :  :  :  :        :     :           +- InMemoryRelation [hd_demo_sk#18896, hd_income_band_sk#18897, hd_buy_potential#18898, hd_dep_count#18899, hd_vehicle_count#18900], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :  :        :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :  :        :     +- Project [t_time_sk#18901]
:  :  :  :  :  :        :        +- Filter (((isnotnull(t_hour#18904) && isnotnull(t_minute#18905)) && ((t_hour#18904 = 8) && (t_minute#18905 >= 30))) && isnotnull(t_time_sk#18901))
:  :  :  :  :  :        :           +- InMemoryRelation [t_time_sk#18901, t_time_id#18902, t_time#18903, t_hour#18904, t_minute#18905, t_second#18906, t_am_pm#18907, t_shift#18908, t_sub_shift#18909, t_meal_time#18910], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :  :        :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :  :        +- Project [s_store_sk#18911]
:  :  :  :  :  :           +- Filter ((isnotnull(s_store_name#18916) && (s_store_name#18916 = ese)) && isnotnull(s_store_sk#18911))
:  :  :  :  :  :              +- InMemoryRelation [s_store_sk#18911, s_store_id#18912, s_rec_start_date#18913, s_rec_end_date#18914, s_closed_date_sk#18915, s_store_name#18916, s_number_employees#18917, s_floor_space#18918, s_hours#18919, s_manager#18920, s_market_id#18921, s_geography_class#18922, s_market_desc#18923, s_market_manager#18924, s_division_id#18925, s_division_name#18926, s_company_id#18927, s_company_name#18928, s_street_number#18929, s_street_name#18930, s_street_type#18931, s_suite_number#18932, s_city#18933, s_county#18934, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :  :                    +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  :  +- Aggregate [count(1) AS h9_to_9_30#18866L]
:  :  :  :  :     +- Project
:  :  :  :  :        +- Join Inner, (ss_store_sk#18947 = s_store_sk#18978)
:  :  :  :  :           :- Project [ss_store_sk#18947]
:  :  :  :  :           :  +- Join Inner, (ss_sold_time_sk#18941 = t_time_sk#18968)
:  :  :  :  :           :     :- Project [ss_sold_time_sk#18941, ss_store_sk#18947]
:  :  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#18945 = hd_demo_sk#18963)
:  :  :  :  :           :     :     :- Project [ss_sold_time_sk#18941, ss_hdemo_sk#18945, ss_store_sk#18947]
:  :  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#18945) && isnotnull(ss_sold_time_sk#18941)) && isnotnull(ss_store_sk#18947))
:  :  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#18941,ss_item_sk#18942,ss_customer_sk#18943,ss_cdemo_sk#18944,ss_hdemo_sk#18945,ss_addr_sk#18946,ss_store_sk#18947,ss_promo_sk#18948,ss_ticket_number#18949,ss_quantity#18950,ss_wholesale_cost#18951,ss_list_price#18952,ss_sales_price#18953,ss_ext_discount_amt#18954,ss_ext_sales_price#18955,ss_ext_wholesale_cost#18956,ss_ext_list_price#18957,ss_ext_tax#18958,ss_coupon_amt#18959,ss_net_paid#18960,ss_net_paid_inc_tax#18961,ss_net_profit#18962,ss_sold_date_sk#18940] parquet
:  :  :  :  :           :     :     +- Project [hd_demo_sk#18963]
:  :  :  :  :           :     :        +- Filter (((((hd_dep_count#18966 = 3) && (hd_vehicle_count#18967 <= 5)) || ((hd_dep_count#18966 = 0) && (hd_vehicle_count#18967 <= 2))) || ((hd_dep_count#18966 = 1) && (hd_vehicle_count#18967 <= 3))) && isnotnull(hd_demo_sk#18963))
:  :  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#18963, hd_income_band_sk#18964, hd_buy_potential#18965, hd_dep_count#18966, hd_vehicle_count#18967], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :           :     +- Project [t_time_sk#18968]
:  :  :  :  :           :        +- Filter (((isnotnull(t_hour#18971) && isnotnull(t_minute#18972)) && ((t_hour#18971 = 9) && (t_minute#18972 < 30))) && isnotnull(t_time_sk#18968))
:  :  :  :  :           :           +- InMemoryRelation [t_time_sk#18968, t_time_id#18969, t_time#18970, t_hour#18971, t_minute#18972, t_second#18973, t_am_pm#18974, t_shift#18975, t_sub_shift#18976, t_meal_time#18977], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :           +- Project [s_store_sk#18978]
:  :  :  :  :              +- Filter ((isnotnull(s_store_name#18983) && (s_store_name#18983 = ese)) && isnotnull(s_store_sk#18978))
:  :  :  :  :                 +- InMemoryRelation [s_store_sk#18978, s_store_id#18979, s_rec_start_date#18980, s_rec_end_date#18981, s_closed_date_sk#18982, s_store_name#18983, s_number_employees#18984, s_floor_space#18985, s_hours#18986, s_manager#18987, s_market_id#18988, s_geography_class#18989, s_market_desc#18990, s_market_manager#18991, s_division_id#18992, s_division_name#18993, s_company_id#18994, s_company_name#18995, s_street_number#18996, s_street_name#18997, s_street_type#18998, s_suite_number#18999, s_city#19000, s_county#19001, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  +- Aggregate [count(1) AS h9_30_to_10#18867L]
:  :  :  :     +- Project
:  :  :  :        +- Join Inner, (ss_store_sk#19014 = s_store_sk#19045)
:  :  :  :           :- Project [ss_store_sk#19014]
:  :  :  :           :  +- Join Inner, (ss_sold_time_sk#19008 = t_time_sk#19035)
:  :  :  :           :     :- Project [ss_sold_time_sk#19008, ss_store_sk#19014]
:  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#19012 = hd_demo_sk#19030)
:  :  :  :           :     :     :- Project [ss_sold_time_sk#19008, ss_hdemo_sk#19012, ss_store_sk#19014]
:  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#19012) && isnotnull(ss_sold_time_sk#19008)) && isnotnull(ss_store_sk#19014))
:  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#19008,ss_item_sk#19009,ss_customer_sk#19010,ss_cdemo_sk#19011,ss_hdemo_sk#19012,ss_addr_sk#19013,ss_store_sk#19014,ss_promo_sk#19015,ss_ticket_number#19016,ss_quantity#19017,ss_wholesale_cost#19018,ss_list_price#19019,ss_sales_price#19020,ss_ext_discount_amt#19021,ss_ext_sales_price#19022,ss_ext_wholesale_cost#19023,ss_ext_list_price#19024,ss_ext_tax#19025,ss_coupon_amt#19026,ss_net_paid#19027,ss_net_paid_inc_tax#19028,ss_net_profit#19029,ss_sold_date_sk#19007] parquet
:  :  :  :           :     :     +- Project [hd_demo_sk#19030]
:  :  :  :           :     :        +- Filter (((((hd_dep_count#19033 = 3) && (hd_vehicle_count#19034 <= 5)) || ((hd_dep_count#19033 = 0) && (hd_vehicle_count#19034 <= 2))) || ((hd_dep_count#19033 = 1) && (hd_vehicle_count#19034 <= 3))) && isnotnull(hd_demo_sk#19030))
:  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#19030, hd_income_band_sk#19031, hd_buy_potential#19032, hd_dep_count#19033, hd_vehicle_count#19034], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :           :     +- Project [t_time_sk#19035]
:  :  :  :           :        +- Filter (((isnotnull(t_hour#19038) && isnotnull(t_minute#19039)) && ((t_hour#19038 = 9) && (t_minute#19039 >= 30))) && isnotnull(t_time_sk#19035))
:  :  :  :           :           +- InMemoryRelation [t_time_sk#19035, t_time_id#19036, t_time#19037, t_hour#19038, t_minute#19039, t_second#19040, t_am_pm#19041, t_shift#19042, t_sub_shift#19043, t_meal_time#19044], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :           +- Project [s_store_sk#19045]
:  :  :  :              +- Filter ((isnotnull(s_store_name#19050) && (s_store_name#19050 = ese)) && isnotnull(s_store_sk#19045))
:  :  :  :                 +- InMemoryRelation [s_store_sk#19045, s_store_id#19046, s_rec_start_date#19047, s_rec_end_date#19048, s_closed_date_sk#19049, s_store_name#19050, s_number_employees#19051, s_floor_space#19052, s_hours#19053, s_manager#19054, s_market_id#19055, s_geography_class#19056, s_market_desc#19057, s_market_manager#19058, s_division_id#19059, s_division_name#19060, s_company_id#19061, s_company_name#19062, s_street_number#19063, s_street_name#19064, s_street_type#19065, s_suite_number#19066, s_city#19067, s_county#19068, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  +- Aggregate [count(1) AS h10_to_10_30#18868L]
:  :  :     +- Project
:  :  :        +- Join Inner, (ss_store_sk#19081 = s_store_sk#19112)
:  :  :           :- Project [ss_store_sk#19081]
:  :  :           :  +- Join Inner, (ss_sold_time_sk#19075 = t_time_sk#19102)
:  :  :           :     :- Project [ss_sold_time_sk#19075, ss_store_sk#19081]
:  :  :           :     :  +- Join Inner, (ss_hdemo_sk#19079 = hd_demo_sk#19097)
:  :  :           :     :     :- Project [ss_sold_time_sk#19075, ss_hdemo_sk#19079, ss_store_sk#19081]
:  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#19079) && isnotnull(ss_sold_time_sk#19075)) && isnotnull(ss_store_sk#19081))
:  :  :           :     :     :     +- Relation[ss_sold_time_sk#19075,ss_item_sk#19076,ss_customer_sk#19077,ss_cdemo_sk#19078,ss_hdemo_sk#19079,ss_addr_sk#19080,ss_store_sk#19081,ss_promo_sk#19082,ss_ticket_number#19083,ss_quantity#19084,ss_wholesale_cost#19085,ss_list_price#19086,ss_sales_price#19087,ss_ext_discount_amt#19088,ss_ext_sales_price#19089,ss_ext_wholesale_cost#19090,ss_ext_list_price#19091,ss_ext_tax#19092,ss_coupon_amt#19093,ss_net_paid#19094,ss_net_paid_inc_tax#19095,ss_net_profit#19096,ss_sold_date_sk#19074] parquet
:  :  :           :     :     +- Project [hd_demo_sk#19097]
:  :  :           :     :        +- Filter (((((hd_dep_count#19100 = 3) && (hd_vehicle_count#19101 <= 5)) || ((hd_dep_count#19100 = 0) && (hd_vehicle_count#19101 <= 2))) || ((hd_dep_count#19100 = 1) && (hd_vehicle_count#19101 <= 3))) && isnotnull(hd_demo_sk#19097))
:  :  :           :     :           +- InMemoryRelation [hd_demo_sk#19097, hd_income_band_sk#19098, hd_buy_potential#19099, hd_dep_count#19100, hd_vehicle_count#19101], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :           :     +- Project [t_time_sk#19102]
:  :  :           :        +- Filter (((isnotnull(t_hour#19105) && isnotnull(t_minute#19106)) && ((t_hour#19105 = 10) && (t_minute#19106 < 30))) && isnotnull(t_time_sk#19102))
:  :  :           :           +- InMemoryRelation [t_time_sk#19102, t_time_id#19103, t_time#19104, t_hour#19105, t_minute#19106, t_second#19107, t_am_pm#19108, t_shift#19109, t_sub_shift#19110, t_meal_time#19111], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :           +- Project [s_store_sk#19112]
:  :  :              +- Filter ((isnotnull(s_store_name#19117) && (s_store_name#19117 = ese)) && isnotnull(s_store_sk#19112))
:  :  :                 +- InMemoryRelation [s_store_sk#19112, s_store_id#19113, s_rec_start_date#19114, s_rec_end_date#19115, s_closed_date_sk#19116, s_store_name#19117, s_number_employees#19118, s_floor_space#19119, s_hours#19120, s_manager#19121, s_market_id#19122, s_geography_class#19123, s_market_desc#19124, s_market_manager#19125, s_division_id#19126, s_division_name#19127, s_company_id#19128, s_company_name#19129, s_street_number#19130, s_street_name#19131, s_street_type#19132, s_suite_number#19133, s_city#19134, s_county#19135, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  +- Aggregate [count(1) AS h10_30_to_11#18869L]
:  :     +- Project
:  :        +- Join Inner, (ss_store_sk#19148 = s_store_sk#19179)
:  :           :- Project [ss_store_sk#19148]
:  :           :  +- Join Inner, (ss_sold_time_sk#19142 = t_time_sk#19169)
:  :           :     :- Project [ss_sold_time_sk#19142, ss_store_sk#19148]
:  :           :     :  +- Join Inner, (ss_hdemo_sk#19146 = hd_demo_sk#19164)
:  :           :     :     :- Project [ss_sold_time_sk#19142, ss_hdemo_sk#19146, ss_store_sk#19148]
:  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#19146) && isnotnull(ss_sold_time_sk#19142)) && isnotnull(ss_store_sk#19148))
:  :           :     :     :     +- Relation[ss_sold_time_sk#19142,ss_item_sk#19143,ss_customer_sk#19144,ss_cdemo_sk#19145,ss_hdemo_sk#19146,ss_addr_sk#19147,ss_store_sk#19148,ss_promo_sk#19149,ss_ticket_number#19150,ss_quantity#19151,ss_wholesale_cost#19152,ss_list_price#19153,ss_sales_price#19154,ss_ext_discount_amt#19155,ss_ext_sales_price#19156,ss_ext_wholesale_cost#19157,ss_ext_list_price#19158,ss_ext_tax#19159,ss_coupon_amt#19160,ss_net_paid#19161,ss_net_paid_inc_tax#19162,ss_net_profit#19163,ss_sold_date_sk#19141] parquet
:  :           :     :     +- Project [hd_demo_sk#19164]
:  :           :     :        +- Filter (((((hd_dep_count#19167 = 3) && (hd_vehicle_count#19168 <= 5)) || ((hd_dep_count#19167 = 0) && (hd_vehicle_count#19168 <= 2))) || ((hd_dep_count#19167 = 1) && (hd_vehicle_count#19168 <= 3))) && isnotnull(hd_demo_sk#19164))
:  :           :     :           +- InMemoryRelation [hd_demo_sk#19164, hd_income_band_sk#19165, hd_buy_potential#19166, hd_dep_count#19167, hd_vehicle_count#19168], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :           :     +- Project [t_time_sk#19169]
:  :           :        +- Filter (((isnotnull(t_hour#19172) && isnotnull(t_minute#19173)) && ((t_hour#19172 = 10) && (t_minute#19173 >= 30))) && isnotnull(t_time_sk#19169))
:  :           :           +- InMemoryRelation [t_time_sk#19169, t_time_id#19170, t_time#19171, t_hour#19172, t_minute#19173, t_second#19174, t_am_pm#19175, t_shift#19176, t_sub_shift#19177, t_meal_time#19178], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :           +- Project [s_store_sk#19179]
:  :              +- Filter ((isnotnull(s_store_name#19184) && (s_store_name#19184 = ese)) && isnotnull(s_store_sk#19179))
:  :                 +- InMemoryRelation [s_store_sk#19179, s_store_id#19180, s_rec_start_date#19181, s_rec_end_date#19182, s_closed_date_sk#19183, s_store_name#19184, s_number_employees#19185, s_floor_space#19186, s_hours#19187, s_manager#19188, s_market_id#19189, s_geography_class#19190, s_market_desc#19191, s_market_manager#19192, s_division_id#19193, s_division_name#19194, s_company_id#19195, s_company_name#19196, s_street_number#19197, s_street_name#19198, s_street_type#19199, s_suite_number#19200, s_city#19201, s_county#19202, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  +- Aggregate [count(1) AS h11_to_11_30#18870L]
:     +- Project
:        +- Join Inner, (ss_store_sk#19215 = s_store_sk#19246)
:           :- Project [ss_store_sk#19215]
:           :  +- Join Inner, (ss_sold_time_sk#19209 = t_time_sk#19236)
:           :     :- Project [ss_sold_time_sk#19209, ss_store_sk#19215]
:           :     :  +- Join Inner, (ss_hdemo_sk#19213 = hd_demo_sk#19231)
:           :     :     :- Project [ss_sold_time_sk#19209, ss_hdemo_sk#19213, ss_store_sk#19215]
:           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#19213) && isnotnull(ss_sold_time_sk#19209)) && isnotnull(ss_store_sk#19215))
:           :     :     :     +- Relation[ss_sold_time_sk#19209,ss_item_sk#19210,ss_customer_sk#19211,ss_cdemo_sk#19212,ss_hdemo_sk#19213,ss_addr_sk#19214,ss_store_sk#19215,ss_promo_sk#19216,ss_ticket_number#19217,ss_quantity#19218,ss_wholesale_cost#19219,ss_list_price#19220,ss_sales_price#19221,ss_ext_discount_amt#19222,ss_ext_sales_price#19223,ss_ext_wholesale_cost#19224,ss_ext_list_price#19225,ss_ext_tax#19226,ss_coupon_amt#19227,ss_net_paid#19228,ss_net_paid_inc_tax#19229,ss_net_profit#19230,ss_sold_date_sk#19208] parquet
:           :     :     +- Project [hd_demo_sk#19231]
:           :     :        +- Filter (((((hd_dep_count#19234 = 3) && (hd_vehicle_count#19235 <= 5)) || ((hd_dep_count#19234 = 0) && (hd_vehicle_count#19235 <= 2))) || ((hd_dep_count#19234 = 1) && (hd_vehicle_count#19235 <= 3))) && isnotnull(hd_demo_sk#19231))
:           :     :           +- InMemoryRelation [hd_demo_sk#19231, hd_income_band_sk#19232, hd_buy_potential#19233, hd_dep_count#19234, hd_vehicle_count#19235], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:           :     +- Project [t_time_sk#19236]
:           :        +- Filter (((isnotnull(t_hour#19239) && isnotnull(t_minute#19240)) && ((t_hour#19239 = 11) && (t_minute#19240 < 30))) && isnotnull(t_time_sk#19236))
:           :           +- InMemoryRelation [t_time_sk#19236, t_time_id#19237, t_time#19238, t_hour#19239, t_minute#19240, t_second#19241, t_am_pm#19242, t_shift#19243, t_sub_shift#19244, t_meal_time#19245], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:           +- Project [s_store_sk#19246]
:              +- Filter ((isnotnull(s_store_name#19251) && (s_store_name#19251 = ese)) && isnotnull(s_store_sk#19246))
:                 +- InMemoryRelation [s_store_sk#19246, s_store_id#19247, s_rec_start_date#19248, s_rec_end_date#19249, s_closed_date_sk#19250, s_store_name#19251, s_number_employees#19252, s_floor_space#19253, s_hours#19254, s_manager#19255, s_market_id#19256, s_geography_class#19257, s_market_desc#19258, s_market_manager#19259, s_division_id#19260, s_division_name#19261, s_company_id#19262, s_company_name#19263, s_street_number#19264, s_street_name#19265, s_street_type#19266, s_suite_number#19267, s_city#19268, s_county#19269, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
+- Aggregate [count(1) AS h11_30_to_12#18871L]
   +- Project
      +- Join Inner, (ss_store_sk#19282 = s_store_sk#19313)
         :- Project [ss_store_sk#19282]
         :  +- Join Inner, (ss_sold_time_sk#19276 = t_time_sk#19303)
         :     :- Project [ss_sold_time_sk#19276, ss_store_sk#19282]
         :     :  +- Join Inner, (ss_hdemo_sk#19280 = hd_demo_sk#19298)
         :     :     :- Project [ss_sold_time_sk#19276, ss_hdemo_sk#19280, ss_store_sk#19282]
         :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#19280) && isnotnull(ss_sold_time_sk#19276)) && isnotnull(ss_store_sk#19282))
         :     :     :     +- Relation[ss_sold_time_sk#19276,ss_item_sk#19277,ss_customer_sk#19278,ss_cdemo_sk#19279,ss_hdemo_sk#19280,ss_addr_sk#19281,ss_store_sk#19282,ss_promo_sk#19283,ss_ticket_number#19284,ss_quantity#19285,ss_wholesale_cost#19286,ss_list_price#19287,ss_sales_price#19288,ss_ext_discount_amt#19289,ss_ext_sales_price#19290,ss_ext_wholesale_cost#19291,ss_ext_list_price#19292,ss_ext_tax#19293,ss_coupon_amt#19294,ss_net_paid#19295,ss_net_paid_inc_tax#19296,ss_net_profit#19297,ss_sold_date_sk#19275] parquet
         :     :     +- Project [hd_demo_sk#19298]
         :     :        +- Filter (((((hd_dep_count#19301 = 3) && (hd_vehicle_count#19302 <= 5)) || ((hd_dep_count#19301 = 0) && (hd_vehicle_count#19302 <= 2))) || ((hd_dep_count#19301 = 1) && (hd_vehicle_count#19302 <= 3))) && isnotnull(hd_demo_sk#19298))
         :     :           +- InMemoryRelation [hd_demo_sk#19298, hd_income_band_sk#19299, hd_buy_potential#19300, hd_dep_count#19301, hd_vehicle_count#19302], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
         :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
         :     +- Project [t_time_sk#19303]
         :        +- Filter (((isnotnull(t_hour#19306) && isnotnull(t_minute#19307)) && ((t_hour#19306 = 11) && (t_minute#19307 >= 30))) && isnotnull(t_time_sk#19303))
         :           +- InMemoryRelation [t_time_sk#19303, t_time_id#19304, t_time#19305, t_hour#19306, t_minute#19307, t_second#19308, t_am_pm#19309, t_shift#19310, t_sub_shift#19311, t_meal_time#19312], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
         :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
         +- Project [s_store_sk#19313]
            +- Filter ((isnotnull(s_store_name#19318) && (s_store_name#19318 = ese)) && isnotnull(s_store_sk#19313))
               +- InMemoryRelation [s_store_sk#19313, s_store_id#19314, s_rec_start_date#19315, s_rec_end_date#19316, s_closed_date_sk#19317, s_store_name#19318, s_number_employees#19319, s_floor_space#19320, s_hours#19321, s_manager#19322, s_market_id#19323, s_geography_class#19324, s_market_desc#19325, s_market_manager#19326, s_division_id#19327, s_division_name#19328, s_company_id#19329, s_company_name#19330, s_street_number#19331, s_street_name#19332, s_street_type#19333, s_suite_number#19334, s_city#19335, s_county#19336, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                     +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
and
Aggregate [count(1) AS h12_to_12_30#18872L]
+- Project
   +- Join Inner, (ss_store_sk#19349 = s_store_sk#19380)
      :- Project [ss_store_sk#19349]
      :  +- Join Inner, (ss_sold_time_sk#19343 = t_time_sk#19370)
      :     :- Project [ss_sold_time_sk#19343, ss_store_sk#19349]
      :     :  +- Join Inner, (ss_hdemo_sk#19347 = hd_demo_sk#19365)
      :     :     :- Project [ss_sold_time_sk#19343, ss_hdemo_sk#19347, ss_store_sk#19349]
      :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#19347) && isnotnull(ss_sold_time_sk#19343)) && isnotnull(ss_store_sk#19349))
      :     :     :     +- Relation[ss_sold_time_sk#19343,ss_item_sk#19344,ss_customer_sk#19345,ss_cdemo_sk#19346,ss_hdemo_sk#19347,ss_addr_sk#19348,ss_store_sk#19349,ss_promo_sk#19350,ss_ticket_number#19351,ss_quantity#19352,ss_wholesale_cost#19353,ss_list_price#19354,ss_sales_price#19355,ss_ext_discount_amt#19356,ss_ext_sales_price#19357,ss_ext_wholesale_cost#19358,ss_ext_list_price#19359,ss_ext_tax#19360,ss_coupon_amt#19361,ss_net_paid#19362,ss_net_paid_inc_tax#19363,ss_net_profit#19364,ss_sold_date_sk#19342] parquet
      :     :     +- Project [hd_demo_sk#19365]
      :     :        +- Filter (((((hd_dep_count#19368 = 3) && (hd_vehicle_count#19369 <= 5)) || ((hd_dep_count#19368 = 0) && (hd_vehicle_count#19369 <= 2))) || ((hd_dep_count#19368 = 1) && (hd_vehicle_count#19369 <= 3))) && isnotnull(hd_demo_sk#19365))
      :     :           +- InMemoryRelation [hd_demo_sk#19365, hd_income_band_sk#19366, hd_buy_potential#19367, hd_dep_count#19368, hd_vehicle_count#19369], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#19370]
      :        +- Filter (((isnotnull(t_hour#19373) && isnotnull(t_minute#19374)) && ((t_hour#19373 = 12) && (t_minute#19374 < 30))) && isnotnull(t_time_sk#19370))
      :           +- InMemoryRelation [t_time_sk#19370, t_time_id#19371, t_time#19372, t_hour#19373, t_minute#19374, t_second#19375, t_am_pm#19376, t_shift#19377, t_sub_shift#19378, t_meal_time#19379], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [s_store_sk#19380]
         +- Filter ((isnotnull(s_store_name#19385) && (s_store_name#19385 = ese)) && isnotnull(s_store_sk#19380))
            +- InMemoryRelation [s_store_sk#19380, s_store_id#19381, s_rec_start_date#19382, s_rec_end_date#19383, s_closed_date_sk#19384, s_store_name#19385, s_number_employees#19386, s_floor_space#19387, s_hours#19388, s_manager#19389, s_market_id#19390, s_geography_class#19391, s_market_desc#19392, s_market_manager#19393, s_division_id#19394, s_division_name#19395, s_company_id#19396, s_company_name#19397, s_street_number#19398, s_street_name#19399, s_street_type#19400, s_suite_number#19401, s_city#19402, s_county#19403, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
Join condition is missing or trivial.
Use the CROSS JOIN syntax to allow cartesian products between these relations.; (state=,code=0)

Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
STOP hdp2.6_spark21_run_1_100_query88_sql_2017-04-06-18-45:  Thu Apr 6 18:45:21 CDT 2017
