START hdp2.6_spark21_run_1_100_query46_sql_2017-04-06-19-06:  Thu Apr 6 19:06:41 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:42 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:42 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,c_first_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ca_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,amt,profit 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    (select ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,ss_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,ca_city bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,sum(ss_coupon_amt) amt
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,sum(ss_net_profit) profit
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     from store_sales,date_dim,store,household_demographics,customer_address 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     where store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store_sales.ss_store_sk = store.s_store_sk  
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store_sales.ss_addr_sk = customer_address.ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and (household_demographics.hd_dep_count = 4 or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          household_demographics.hd_vehicle_count= 2)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and date_dim.d_dow in (6,0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and date_dim.d_year in (1998,1998+1,1998+2) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store.s_city in ('Rosedale','Bethlehem','Clinton','Clifton','Springfield') 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     group by ss_ticket_number,ss_customer_sk,ss_addr_sk,ca_city) dn,customer,customer_address current_a ddr
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     where dn.ss_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       and customer.c_current_addr_sk = current_addr.ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       and current_addr.ca_city <> bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   order by c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,c_first_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,ca_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   limit 100;
17/04/06 19:06:42 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:42 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:42 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/06 19:06:42 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:42 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:42 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:42 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_1_100_query46_sql_2017-04-06-19-06:  Thu Apr 6 19:06:42 CDT 2017
