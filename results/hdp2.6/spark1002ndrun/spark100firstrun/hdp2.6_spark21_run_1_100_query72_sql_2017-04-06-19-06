START hdp2.6_spark21_run_1_100_query72_sql_2017-04-06-19-06:  Thu Apr 6 19:06:55 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:56 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:56 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  i_item_desc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,w_warehouse_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,d1.d_week_seq
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,count(case when p_promo_sk is null then 1 else 0 end) no_promo
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,count(case when p_promo_sk is not null then 1 else 0 end) promo
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,count(*) total_cnt
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from catalog_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join inventory on (catalog_sales.cs_item_sk = inventory.inv_item_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join warehouse on (warehouse.w_warehouse_sk=inventory.inv_warehouse_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join item on (item.i_item_sk = catalog_sales.cs_item_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join customer_demographics on (catalog_sales.cs_bill_cdemo_sk = customer_demographics.cd_demo_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join household_demographics on (catalog_sales.cs_bill_hdemo_sk = household_demographics.hd_demo_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join date_dim d1 on (catalog_sales.cs_sold_date_sk = d1.d_date_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join date_dim d2 on (inventory.inv_date_sk = d2.d_date_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> join date_dim d3 on (catalog_sales.cs_ship_date_sk = d3.d_date_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> left outer join promotion on (catalog_sales.cs_promo_sk=promotion.p_promo_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> left outer join catalog_returns on (catalog_returns.cr_item_sk = catalog_sales.cs_item_sk and catalog_r eturns.cr_order_number = catalog_sales.cs_order_number)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where d1.d_week_seq = d2.d_week_seq
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and inv_quantity_on_hand < cs_quantity 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and d3.d_date > d1.d_date + 5
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and hd_buy_potential = '1001-5000'
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and d1.d_year = 2001
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and hd_buy_potential = '1001-5000'
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and cd_marital_status = 'M'
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   and d1.d_year = 2001
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> group by i_item_desc,w_warehouse_name,d1.d_week_seq
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/06 19:06:56 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:56 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:56 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/06 19:06:56 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:56 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:56 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:56 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_1_100_query72_sql_2017-04-06-19-06:  Thu Apr 6 19:06:56 CDT 2017
