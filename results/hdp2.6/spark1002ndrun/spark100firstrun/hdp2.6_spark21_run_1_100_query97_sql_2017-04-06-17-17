START hdp2.6_spark21_run_1_100_query97_sql_2017-04-06-17-17:  Thu Apr 6 17:17:01 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 17:17:02 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:02 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:02 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1 else 0 end) store _only
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1 else 0 end) catal og_only
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 else 0 end) s tore_and_catalog
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> ( select ss_customer_sk customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,ss_item_sk item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from store_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   d_month_seq between 1193 and 1193 + 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> group by ss_customer_sk ,ss_item_sk) ssci
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> full outer join
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> ( select cs_bill_customer_sk customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,cs_item_sk item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from catalog_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> JOIN date_dim ON catalog_sales.cs_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   d_month_seq between 1193 and 1193 + 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> group by cs_bill_customer_sk ,cs_item_sk) csci
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> on (ssci.customer_sk=csci.customer_sk and ssci.item_sk = csci.item_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/06 17:17:02 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:02 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:02 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
No current connection

17/04/06 17:17:02 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:02 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:02 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
STOP hdp2.6_spark21_run_1_100_query97_sql_2017-04-06-17-17:  Thu Apr 6 17:17:02 CDT 2017
