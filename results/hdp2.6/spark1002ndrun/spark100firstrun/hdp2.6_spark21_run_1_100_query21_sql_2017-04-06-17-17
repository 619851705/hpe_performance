START hdp2.6_spark21_run_1_100_query21_sql_2017-04-06-17-17:  Thu Apr 6 17:17:39 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 17:17:40 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:40 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:40 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from(select w_warehouse_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>             ,i_item_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>             ,sum(case when (cast(d_date as date) < cast ('1998-04-08' as date))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                 then inv_quantity_on_hand 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                       else 0 end) as inv_before
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>             ,sum(case when (cast(d_date as date) >= cast ('1998-04-08' as date))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                       then inv_quantity_on_hand 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                       else 0 end) as inv_after
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    from inventory
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,warehouse
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,item
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    where i_current_price between 0.99 and 1.49
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and item.i_item_sk          = inventory.inv_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and inventory.inv_warehouse_sk   = warehouse.w_warehouse_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and inventory.inv_date_sk    = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and d_date between '1998-03-09' and '1998-05-07'
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    group by w_warehouse_name, i_item_id) x
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where (case when inv_before > 0 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              then inv_after / inv_before 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              else null
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              end) between 2.0/3.0 and 3.0/2.0
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  order by w_warehouse_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          ,i_item_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  limit 100;
17/04/06 17:17:40 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:40 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:40 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
No current connection

17/04/06 17:17:40 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:40 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:40 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
STOP hdp2.6_spark21_run_1_100_query21_sql_2017-04-06-17-17:  Thu Apr 6 17:17:40 CDT 2017
