START hdp2.6_spark21_run_1_100_query94_sql_2017-04-06-17-16:  Thu Apr 6 17:16:59 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 17:17:00 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:00 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:00 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> SELECT count(distinct ws_order_number) as order_count,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                sum(ws_ext_ship_cost) as total_shipping_cost,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                sum(ws_net_profit) as total_net_profit
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> FROM web_sales ws1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> JOIN customer_address ca ON (ws1.ws_ship_addr_sk = ca.ca_address_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> JOIN web_site s ON (ws1.ws_web_site_sk = s.web_site_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> JOIN date_dim d ON (ws1.ws_ship_date_sk = d.d_date_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> LEFT SEMI JOIN (SELECT ws2.ws_order_number as ws_order_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                                FROM web_sales ws2 JOIN web_sales ws3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                                ON (ws2.ws_order_number = ws3.ws_order_number)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                                WHERE ws2.ws_warehouse_sk <> ws3.ws_warehouse_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> ) ws_wh1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> ON (ws1.ws_order_number = ws_wh1.ws_order_number)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> LEFT OUTER JOIN web_returns wr1 ON (ws1.ws_order_number = wr1.wr_order_number)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> WHERE d.d_date between '1999-05-01' and '1999-07-01' and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                ca.ca_state = 'TX' and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                s.web_company_name = 'pri' and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                wr1.wr_order_number is null
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/06 17:17:00 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:00 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:00 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
No current connection

17/04/06 17:17:00 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:17:00 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:17:00 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
STOP hdp2.6_spark21_run_1_100_query94_sql_2017-04-06-17-16:  Thu Apr 6 17:17:00 CDT 2017
