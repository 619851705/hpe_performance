START hdp2.6_spark21_run_1_100_query79_sql_2017-04-06-17-16:  Thu Apr 6 17:16:42 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 17:16:43 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:16:43 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:16:43 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) (state=,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   c_last_name,c_first_name,substr(s_city,1,30) sub,ss_ticket_number,amt,profit
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>   from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    (select ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,ss_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,store.s_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,sum(ss_coupon_amt) amt
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           ,sum(ss_net_profit) profit
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     from store_sales,date_dim,store,household_demographics
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     where store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store_sales.ss_store_sk = store.s_store_sk  
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and (household_demographics.hd_dep_count = 8 or household_demographics.hd_vehicle_count > 0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and date_dim.d_dow = 1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and date_dim.d_year in (1998,1998+1,1998+2) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     and store.s_number_employees between 200 and 295
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     group by ss_ticket_number,ss_customer_sk,ss_addr_sk,store.s_city) ms,customer
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     where ms.ss_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  order by c_last_name,c_first_name,sub, profit
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/06 17:16:44 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:16:44 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:16:44 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
No current connection

17/04/06 17:16:46 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:16:46 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:16:46 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) (state=,code=0)
STOP hdp2.6_spark21_run_1_100_query79_sql_2017-04-06-17-16:  Thu Apr 6 17:16:48 CDT 2017
