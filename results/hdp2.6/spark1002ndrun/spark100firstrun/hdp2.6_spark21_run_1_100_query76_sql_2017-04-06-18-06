START hdp2.6_spark21_run_1_100_query76_sql_2017-04-06-18-06:  Thu Apr 6 18:06:28 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:06:29 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 18:06:29 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 18:06:29 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:06:32 ERROR HiveConnection: Error opening session
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:376)
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:453)
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:435)
	at org.apache.thrift.transport.TSaslClientTransport.read(TSaslClientTransport.java:37)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hive.service.cli.thrift.TCLIService$Client.recv_OpenSession(TCLIService.java:156)
	at org.apache.hive.service.cli.thrift.TCLIService$Client.OpenSession(TCLIService.java:143)
	at org.apache.hive.jdbc.HiveConnection.openSession(HiveConnection.java:583)
	at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:192)
	at org.apache.hive.jdbc.HiveDriver.connect(HiveDriver.java:105)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:208)
	at org.apache.hive.beeline.DatabaseConnection.connect(DatabaseConnection.java:142)
	at org.apache.hive.beeline.DatabaseConnection.getConnection(DatabaseConnection.java:207)
	at org.apache.hive.beeline.Commands.connect(Commands.java:1149)
	at org.apache.hive.beeline.Commands.connect(Commands.java:1070)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hive.beeline.ReflectiveCommandHandler.execute(ReflectiveCommandHandler.java:52)
	at org.apache.hive.beeline.BeeLine.dispatch(BeeLine.java:970)
	at org.apache.hive.beeline.BeeLine.initArgs(BeeLine.java:707)
	at org.apache.hive.beeline.BeeLine.begin(BeeLine.java:757)
	at org.apache.hive.beeline.BeeLine.mainWithInputRedirection(BeeLine.java:484)
	at org.apache.hive.beeline.BeeLine.main(BeeLine.java:467)
Error: Could not establish connection to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: null (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  channel, col_name, d_year, d_qoy, i_category, COUNT(*) sales_cnt, SUM(ext_sales_price) sales_am t FROM (
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         SELECT 'store' as channel, 'ss_addr_sk' col_name, d_year, d_qoy, i_category, ss_ext_sales_price  ext_sales_price
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          FROM store_sales, item, date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          WHERE ss_addr_sk IS NULL
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            AND store_sales.ss_sold_date_sk=date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            AND store_sales.ss_item_sk=item.i_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         UNION ALL
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         SELECT 'web' as channel, 'ws_web_page_sk' col_name, d_year, d_qoy, i_category, ws_ext_sales_pri ce ext_sales_price
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          FROM web_sales, item, date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          WHERE ws_web_page_sk IS NULL
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            AND web_sales.ws_sold_date_sk=date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            AND web_sales.ws_item_sk=item.i_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         UNION ALL
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         SELECT 'catalog' as channel, 'cs_warehouse_sk' col_name, d_year, d_qoy, i_category, cs_ext_sale s_price ext_sales_price
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          FROM catalog_sales, item, date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          WHERE cs_warehouse_sk IS NULL
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            AND catalog_sales.cs_sold_date_sk=date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            AND catalog_sales.cs_item_sk=item.i_item_sk) foo
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> GROUP BY channel, col_name, d_year, d_qoy, i_category
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> ORDER BY channel, col_name, d_year, d_qoy, i_category
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/06 18:06:32 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 18:06:32 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 18:06:32 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:06:32 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:06:32 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/06 18:06:32 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 18:06:32 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 18:06:32 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:06:32 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:06:32 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_1_100_query76_sql_2017-04-06-18-06:  Thu Apr 6 18:06:32 CDT 2017
