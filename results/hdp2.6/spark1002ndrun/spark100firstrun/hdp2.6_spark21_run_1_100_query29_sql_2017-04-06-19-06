START hdp2.6_spark21_run_1_100_query29_sql_2017-04-06-19-06:  Thu Apr 6 19:06:34 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      i_item_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ,i_item_desc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ,s_store_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ,s_store_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ,sum(ss_quantity)        as store_sales_quantity
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ,sum(sr_return_quantity) as store_returns_quantity
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     ,sum(cs_quantity)        as catalog_sales_quantity
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     store_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,store_returns
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,catalog_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,date_dim             d1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,date_dim             d2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,date_dim             d3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,item
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      d1.d_moy               = 2 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and d1.d_year              = 2000
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and d1.d_date_sk           = ss_sold_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and i_item_sk              = ss_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and s_store_sk             = ss_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and ss_customer_sk         = sr_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and ss_item_sk             = sr_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and ss_ticket_number       = sr_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and sr_returned_date_sk    = d2.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and d2.d_moy               between 2 and  2 + 3 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and d2.d_year              = 2000
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and sr_customer_sk         = cs_bill_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and sr_item_sk             = cs_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and cs_sold_date_sk        = d3.d_date_sk     
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  and d3.d_year              in (2000,2000+1,2000+2)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  group by
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     i_item_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,i_item_desc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,s_store_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,s_store_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  order by
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     i_item_id 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,i_item_desc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,s_store_id
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    ,s_store_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  limit 100;
17/04/06 19:06:35 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/06 19:06:35 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 19:06:35 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 19:06:35 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_1_100_query29_sql_2017-04-06-19-06:  Thu Apr 6 19:06:35 CDT 2017
