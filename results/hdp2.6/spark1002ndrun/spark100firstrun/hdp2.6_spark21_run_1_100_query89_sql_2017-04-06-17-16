START hdp2.6_spark21_run_1_100_query89_sql_2017-04-06-17-16:  Thu Apr 6 17:16:55 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 17:16:55 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:16:55 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:16:55 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from(
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select i_category, i_class, i_brand,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        s_store_name, s_company_name,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        d_moy,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        sum(ss_sales_price) sum_sales,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        avg(sum(ss_sales_price)) over
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          (partition by i_category, i_brand, s_store_name, s_company_name)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          avg_monthly_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from item, store_sales, date_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where store_sales.ss_item_sk = item.i_item_sk and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       store_sales.ss_sold_date_sk = date_dim.d_date_sk and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       store_sales.ss_store_sk = store.s_store_sk and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       d_year in (2000) and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ((i_category in ('Home','Books','Electronics') and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           i_class in ('wallpaper','parenting','musical')
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          )
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       or (i_category in ('Shoes','Jewelry','Men') and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           i_class in ('womens','birdal','pants') 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> group by i_category, i_class, i_brand,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          s_store_name, s_company_name, d_moy) tmp1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where case when (avg_monthly_sales <> 0) then (abs(sum_sales - avg_monthly_sales) / avg_monthly_sales)  else null end > 0.1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> order by sum_sales - avg_monthly_sales, s_store_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/06 17:16:56 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:16:56 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:16:56 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
No current connection

17/04/06 17:16:56 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 17:16:56 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 17:16:56 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Error: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:745)
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

(No active SparkContext.) (state=,code=0)
STOP hdp2.6_spark21_run_1_100_query89_sql_2017-04-06-17-16:  Thu Apr 6 17:16:56 CDT 2017
