START hdp2.6_spark21_run_1_100_query90_sql_2017-04-06-18-45:  Thu Apr 6 18:45:57 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/06 18:45:58 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/06 18:45:58 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/06 18:45:58 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  cast(amc as decimal(15,4))/cast(pmc as decimal(15,4)) am_pm_ratio
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from ( select count(*) amc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        from web_sales, household_demographics , time_dim, web_page
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        where ws_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and ws_ship_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and ws_web_page_sk = web_page.wp_web_page_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and time_dim.t_hour between 6 and 6+1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and household_demographics.hd_dep_count = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and web_page.wp_char_count between 5000 and 5200) at,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ( select count(*) pmc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        from web_sales, household_demographics , time_dim, web_page
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        where ws_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and ws_ship_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and ws_web_page_sk = web_page.wp_web_page_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and time_dim.t_hour between 14 and 14+1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and household_demographics.hd_dep_count = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          and web_page.wp_char_count between 5000 and 5200) pt
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  order by am_pm_ratio
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  limit 100;
Error: org.apache.spark.sql.AnalysisException: Detected cartesian product for INNER join between logical plans
Aggregate [count(1) AS amc#22552L]
+- Project
   +- Join Inner, (ws_web_page_sk#22567 = wp_web_page_sk#22604)
      :- Project [ws_web_page_sk#22567]
      :  +- Join Inner, (ws_sold_time_sk#22556 = t_time_sk#22594)
      :     :- Project [ws_sold_time_sk#22556, ws_web_page_sk#22567]
      :     :  +- Join Inner, (ws_ship_hdemo_sk#22565 = hd_demo_sk#22589)
      :     :     :- Project [ws_sold_time_sk#22556, ws_ship_hdemo_sk#22565, ws_web_page_sk#22567]
      :     :     :  +- Filter ((isnotnull(ws_ship_hdemo_sk#22565) && isnotnull(ws_sold_time_sk#22556)) && isnotnull(ws_web_page_sk#22567))
      :     :     :     +- Relation[ws_sold_time_sk#22556,ws_ship_date_sk#22557,ws_item_sk#22558,ws_bill_customer_sk#22559,ws_bill_cdemo_sk#22560,ws_bill_hdemo_sk#22561,ws_bill_addr_sk#22562,ws_ship_customer_sk#22563,ws_ship_cdemo_sk#22564,ws_ship_hdemo_sk#22565,ws_ship_addr_sk#22566,ws_web_page_sk#22567,ws_web_site_sk#22568,ws_ship_mode_sk#22569,ws_warehouse_sk#22570,ws_promo_sk#22571,ws_order_number#22572,ws_quantity#22573,ws_wholesale_cost#22574,ws_list_price#22575,ws_sales_price#22576,ws_ext_discount_amt#22577,ws_ext_sales_price#22578,ws_ext_wholesale_cost#22579,... 10 more fields] parquet
      :     :     +- Project [hd_demo_sk#22589]
      :     :        +- Filter ((isnotnull(hd_dep_count#22592) && (hd_dep_count#22592 = 8)) && isnotnull(hd_demo_sk#22589))
      :     :           +- InMemoryRelation [hd_demo_sk#22589, hd_income_band_sk#22590, hd_buy_potential#22591, hd_dep_count#22592, hd_vehicle_count#22593], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#22594]
      :        +- Filter ((isnotnull(t_hour#22597) && ((t_hour#22597 >= 6) && (t_hour#22597 <= 7))) && isnotnull(t_time_sk#22594))
      :           +- InMemoryRelation [t_time_sk#22594, t_time_id#22595, t_time#22596, t_hour#22597, t_minute#22598, t_second#22599, t_am_pm#22600, t_shift#22601, t_sub_shift#22602, t_meal_time#22603], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [wp_web_page_sk#22604]
         +- Filter ((isnotnull(wp_char_count#22614) && ((wp_char_count#22614 >= 5000) && (wp_char_count#22614 <= 5200))) && isnotnull(wp_web_page_sk#22604))
            +- InMemoryRelation [wp_web_page_sk#22604, wp_web_page_id#22605, wp_rec_start_date#22606, wp_rec_end_date#22607, wp_creation_date_sk#22608, wp_access_date_sk#22609, wp_autogen_flag#22610, wp_customer_sk#22611, wp_url#22612, wp_type#22613, wp_char_count#22614, wp_link_count#22615, wp_image_count#22616, wp_max_ad_count#22617], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `web_page`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_100.web_page[wp_web_page_sk#3935,wp_web_page_id#3936,wp_rec_start_date#3937,wp_rec_end_date#3938,wp_creation_date_sk#3939,wp_access_date_sk#3940,wp_autogen_flag#3941,wp_customer_sk#3942,wp_url#3943,wp_type#3944,wp_char_count#3945,wp_link_count#3946,wp_image_count#3947,wp_max_ad_count#3948] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<wp_web_page_sk:int,wp_web_page_id:string,wp_rec_start_date:string,wp_rec_end_date:string,w...
and
Aggregate [count(1) AS pmc#22553L]
+- Project
   +- Join Inner, (ws_web_page_sk#22630 = wp_web_page_sk#22667)
      :- Project [ws_web_page_sk#22630]
      :  +- Join Inner, (ws_sold_time_sk#22619 = t_time_sk#22657)
      :     :- Project [ws_sold_time_sk#22619, ws_web_page_sk#22630]
      :     :  +- Join Inner, (ws_ship_hdemo_sk#22628 = hd_demo_sk#22652)
      :     :     :- Project [ws_sold_time_sk#22619, ws_ship_hdemo_sk#22628, ws_web_page_sk#22630]
      :     :     :  +- Filter ((isnotnull(ws_ship_hdemo_sk#22628) && isnotnull(ws_sold_time_sk#22619)) && isnotnull(ws_web_page_sk#22630))
      :     :     :     +- Relation[ws_sold_time_sk#22619,ws_ship_date_sk#22620,ws_item_sk#22621,ws_bill_customer_sk#22622,ws_bill_cdemo_sk#22623,ws_bill_hdemo_sk#22624,ws_bill_addr_sk#22625,ws_ship_customer_sk#22626,ws_ship_cdemo_sk#22627,ws_ship_hdemo_sk#22628,ws_ship_addr_sk#22629,ws_web_page_sk#22630,ws_web_site_sk#22631,ws_ship_mode_sk#22632,ws_warehouse_sk#22633,ws_promo_sk#22634,ws_order_number#22635,ws_quantity#22636,ws_wholesale_cost#22637,ws_list_price#22638,ws_sales_price#22639,ws_ext_discount_amt#22640,ws_ext_sales_price#22641,ws_ext_wholesale_cost#22642,... 10 more fields] parquet
      :     :     +- Project [hd_demo_sk#22652]
      :     :        +- Filter ((isnotnull(hd_dep_count#22655) && (hd_dep_count#22655 = 8)) && isnotnull(hd_demo_sk#22652))
      :     :           +- InMemoryRelation [hd_demo_sk#22652, hd_income_band_sk#22653, hd_buy_potential#22654, hd_dep_count#22655, hd_vehicle_count#22656], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#22657]
      :        +- Filter ((isnotnull(t_hour#22660) && ((t_hour#22660 >= 14) && (t_hour#22660 <= 15))) && isnotnull(t_time_sk#22657))
      :           +- InMemoryRelation [t_time_sk#22657, t_time_id#22658, t_time#22659, t_hour#22660, t_minute#22661, t_second#22662, t_am_pm#22663, t_shift#22664, t_sub_shift#22665, t_meal_time#22666], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [wp_web_page_sk#22667]
         +- Filter ((isnotnull(wp_char_count#22677) && ((wp_char_count#22677 >= 5000) && (wp_char_count#22677 <= 5200))) && isnotnull(wp_web_page_sk#22667))
            +- InMemoryRelation [wp_web_page_sk#22667, wp_web_page_id#22668, wp_rec_start_date#22669, wp_rec_end_date#22670, wp_creation_date_sk#22671, wp_access_date_sk#22672, wp_autogen_flag#22673, wp_customer_sk#22674, wp_url#22675, wp_type#22676, wp_char_count#22677, wp_link_count#22678, wp_image_count#22679, wp_max_ad_count#22680], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `web_page`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_100.web_page[wp_web_page_sk#3935,wp_web_page_id#3936,wp_rec_start_date#3937,wp_rec_end_date#3938,wp_creation_date_sk#3939,wp_access_date_sk#3940,wp_autogen_flag#3941,wp_customer_sk#3942,wp_url#3943,wp_type#3944,wp_char_count#3945,wp_link_count#3946,wp_image_count#3947,wp_max_ad_count#3948] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<wp_web_page_sk:int,wp_web_page_id:string,wp_rec_start_date:string,wp_rec_end_date:string,w...
Join condition is missing or trivial.
Use the CROSS JOIN syntax to allow cartesian products between these relations.; (state=,code=0)

Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
STOP hdp2.6_spark21_run_1_100_query90_sql_2017-04-06-18-45:  Thu Apr 6 18:45:59 CDT 2017
