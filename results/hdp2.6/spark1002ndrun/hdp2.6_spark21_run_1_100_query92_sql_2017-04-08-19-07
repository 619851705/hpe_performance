START hdp2.6_spark21_run_1_100_query92_sql_2017-04-08-19-07:  Sat Apr 8 19:07:19 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/08 19:07:20 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/08 19:07:20 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/08 19:07:20 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> SELECT sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                  else 0 end) as store_only,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                 else 0 end) as catalog_only,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                  else 0 end) as store_and_catalog
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> FROM (SELECT ss.ss_customer_sk as customer_sk,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                              ss.ss_item_sk as item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>              FROM store_sales ss
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>              JOIN date_dim d1 ON (ss.ss_sold_date_sk = d1.d_date_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>              WHERE d1.d_month_seq >= 1206 and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                             d1.d_month_seq <= 1217
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>              GROUP BY ss.ss_customer_sk, ss.ss_item_sk) ssci
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> FULL OUTER JOIN (SELECT cs.cs_bill_customer_sk as customer_sk,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                                    cs.cs_item_sk as item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                    FROM catalog_sales cs
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                    JOIN date_dim d2 ON (cs.cs_sold_date_sk = d2.d_date_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                    WHERE d2.d_month_seq >= 1206 and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                                   d2.d_month_seq <= 1217
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>                                    GROUP BY cs.cs_bill_customer_sk, cs.cs_item_sk) csci
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ON (ssci.customer_sk=csci.customer_sk and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         ssci.item_sk = csci.item_sk);
+-----------------+-----------------+-----------------+--+
|   store_only    |  catalog_only   | store_and_catalog |
+-----------------+-----------------+-----------------+--+
| 53559437        | 28507870        | 6376            |
+-----------------+-----------------+-----------------+--+
1 row selected (9.425 seconds)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
STOP hdp2.6_spark21_run_1_100_query92_sql_2017-04-08-19-07:  Sat Apr 8 19:07:29 CDT 2017
