START hdp2.6_spark21_run_1_100_query88_sql_2017-04-07-19-49:  Fri Apr 7 19:49:23 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/07 19:49:23 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/07 19:49:23 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h8_30_to_9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2)) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s1,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h9_to_9_30 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 9 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s2,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h9_30_to_10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s3,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h10_to_10_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s4,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h10_30_to_11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s5,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h11_to_11_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s6,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h11_30_to_12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s7,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  (select count(*) h12_to_12_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_hour = 12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>      and store.s_store_name = 'ese') s8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> ;
17/04/07 19:49:23 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/07 19:49:23 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/07 19:49:23 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/07 19:49:23 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/07 19:49:23 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/07 19:49:23 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/07 19:49:23 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_1_100_query88_sql_2017-04-07-19-49:  Fri Apr 7 19:49:23 CDT 2017
