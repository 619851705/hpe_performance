START hdp2.6_hivetez_run_orc_1000_2_query70_sql_2017-04-12-07-22:  Wed Apr 12 07:22:14 CDT 2017
beeline -u "jdbc:hive2://h01mgt.hadoop:2181,h01hn01.hadoop:2181,h01hn02.hadoop:2181/tpcds_bin_partitioned_${FILETYPE}_${SF};serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2" -n hive --incremental=true -i settings/${SETTINGS}.settings -f sample-queries-tpcds/$1
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.container.max.java.heap.fraction=0.8;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set hive.log.level=WARN;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.tez.exec.print.summary=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> #set hive.tez.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.enforce.bucketing=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.enforce.sorting=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.tez.container.size=8192; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.am.resource.memory.mb=8192;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.task.resource.memory.mb=8192; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.runtime.io.sort.mb=3277; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.auto.convert.join.noconditionaltask=true; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.auto.convert.join.noconditionaltask.size=2834678415; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.runtime.unordered.output.buffer.size-mb=819; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> #set tez.grouping.min-size=1073741824; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> #set tez.grouping.max-size=2147483648; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.parallel=true; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.parallel.thread.number=16; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.tez.auto.reducer.parallelism=true; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.reducers.bytes.per.reducer=268435456; 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.optimize.reducededuplication.min.reducer = 1 ;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set tez.queue.name=llap;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.dynamic.partition.mode=nonstrict;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.max.dynamic.partitions.pernode=100000;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.max.dynamic.partitions=100000;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.max.created.files=1000000;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.exec.parallel=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set hive.exec.reducers.max=2000;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.stats.autogather=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.optimize.sort.dynamic.partition=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.stats.autogather=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.execution.engine=tez;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.cbo.enable=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.compute.query.using.stats=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.stats.fetch.column.stats=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.stats.fetch.partition.stats=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.vectorized.execution.enabled=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.vectorized.execution.reduce.enabled = true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.vectorized.execution.reduce.groupby.enabled = true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set mapred.job.reduce.input.buffer.percent=0.0;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set mapreduce.input.fileinputformat.split.minsize=1073741824;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set mapreduce.input.fileinputformat.split.maxsize=2147483648;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set mapreduce.input.fileinputformat.split.minsize.per.node=1073741824;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set mapreduce.input.fileinputformat.split.minsize.per.rack=1073741824;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set hive.tez.java.opts=-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+U seNUMA -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.runtime.empty.partitions.info-via-events.enabled=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set tez.runtime.report.partition.stats=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> --set mapred.map.tasks=6;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.limit.pushdown.memory.usage=0.04;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.map.aggr=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.mapjoin.bucket.cache.size=10000;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.mapred.reduce.tasks.speculative.execution=false;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.metastore.cache.pinobjtypes=Table,Database,Type,FieldSchema,Order;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.metastore.client.socket.timeout=60;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.metastore.execute.setugi=true;
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> select  
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>     sum(ss_net_profit) as total_sum
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    ,s_state
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    ,s_county
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    ,grouping__id as lochierarchy
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    , rank() over(partition by grouping__id, case when grouping__id == 2 then s_state e nd order by sum(ss_net_profit)) as rank_within_parent
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> from
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>     store_sales ss join date_dim d1 on d1.d_date_sk = ss.ss_sold_date_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>     join store s on s.s_store_sk  = ss.ss_store_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  where
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>     d1.d_month_seq between 1193 and 1193+11
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  and s.s_state in
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>              ( select s_state
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                from  (select s_state as s_state, sum(ss_net_profit),
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                              rank() over ( partition by s_state order by sum(ss_net_pr ofit) desc) as ranking
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                       from   store_sales, store, date_dim
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                       where  d_month_seq between 1193 and 1193+11
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                             and date_dim.d_date_sk = store_sales.ss_sold_date_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                             and store.s_store_sk  = store_sales.ss_store_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                       group by s_state
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                      ) tmp1 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>                where ranking <= 5
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>              )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  group by s_state,s_county with rollup
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> order by
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    lochierarchy desc
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ,case when lochierarchy = 0 then s_state end
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ,rank_within_parent
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  limit 100;
+-------------------------+----------+-------------------------+---------------+---------------------+--+
|        total_sum        | s_state  |        s_county         | lochierarchy  | rank_within_parent  |
+-------------------------+----------+-------------------------+---------------+---------------------+--+
| -4.412221153946721E11   | NULL     | NULL                    | 3             | 1                   |
| -4.226698123464969E10   | MN       | NULL                    | 1             | 1                   |
| -3.966853509071094E10   | MI       | NULL                    | 1             | 2                   |
| -3.611421927337981E10   | AL       | NULL                    | 1             | 3                   |
| -3.172446688389849E10   | GA       | NULL                    | 1             | 4                   |
| -3.1683153794505455E10  | LA       | NULL                    | 1             | 5                   |
| -2.2919489227454E10     | SD       | NULL                    | 1             | 6                   |
| -2.1987259856868107E10  | TN       | NULL                    | 1             | 7                   |
| -2.1115991829469723E10  | PA       | NULL                    | 1             | 8                   |
| -1.9361807809886444E10  | NM       | NULL                    | 1             | 9                   |
| -1.6726624420565563E10  | FL       | NULL                    | 1             | 10                  |
| -1.6699377368071568E10  | IN       | NULL                    | 1             | 11                  |
| -1.4984419381455694E10  | NC       | NULL                    | 1             | 12                  |
| -1.4971895120788486E10  | NE       | NULL                    | 1             | 13                  |
| -1.4965333112211739E10  | CO       | NULL                    | 1             | 14                  |
| -1.410347095248439E10   | WV       | NULL                    | 1             | 15                  |
| -1.4098819402969234E10  | OH       | NULL                    | 1             | 16                  |
| -1.4094459914198599E10  | WA       | NULL                    | 1             | 17                  |
| -1.4082274584769533E10  | NY       | NULL                    | 1             | 18                  |
| -1.3228978507421223E10  | SC       | NULL                    | 1             | 19                  |
| -1.3196822599079166E10  | TX       | NULL                    | 1             | 20                  |
| -9.71000478095871E9     | MO       | NULL                    | 1             | 21                  |
| -3.517730248875331E9    |          | NULL                    | 1             | 22                  |
| -1.7610983040713594E9   |          |                         | 0             | 28                  |
| -8.79414679378449E8     |          | Barrow County           | 0             | 31                  |
| -8.7721726542552E8      |          | Williamson County       | 0             | 32                  |
| -1.851768890748812E10   | AL       | Walker County           | 0             | 6                   |
| -1.7596530365891697E10  | AL       | Mobile County           | 0             | 10                  |
| -1.4965333112211733E10  | CO       | Mesa County             | 0             | 16                  |
| -1.6726624420565563E10  | FL       | Levy County             | 0             | 11                  |
| -1.8499845762070934E10  | GA       | Barrow County           | 0             | 7                   |
| -1.322462112182759E10   | GA       | Oglethorpe County       | 0             | 23                  |
| -1.6699377368071583E10  | IN       | Marshall County         | 0             | 12                  |
| -1.7600276496490074E10  | LA       | Franklin Parish         | 0             | 9                   |
| -1.4082877298015339E10  | LA       | Jefferson Davis Parish  | 0             | 19                  |
| -1.4986252746008835E10  | MI       | Gogebic County          | 0             | 13                  |
| -1.322557525100767E10   | MI       | Luce County             | 0             | 22                  |
| -1.1456707093694439E10  | MI       | Huron County            | 0             | 26                  |
| -2.3767354854303905E10  | MN       | Pennington County       | 0             | 1                   |
| -1.762323925560693E10   | MN       | Wadena County           | 0             | 8                   |
| -8.763871247388097E8    | MN       |                         | 0             | 33                  |
| -9.710004780958712E9    | MO       | Daviess County          | 0             | 27                  |
| -1.4984419381455711E10  | NC       | Jackson County          | 0             | 14                  |
| -1.4971895120788488E10  | NE       | Gage County             | 0             | 15                  |
| -1.9361807809886456E10  | NM       | San Miguel County       | 0             | 5                   |
| -1.4082274584769539E10  | NY       | Bronx County            | 0             | 20                  |
| -1.4098819402969242E10  | OH       | Richland County         | 0             | 17                  |
| -2.111599182946973E10   | PA       | Dauphin County          | 0             | 4                   |
| -1.322897850742122E10   | SC       | Fairfield County        | 0             | 21                  |
| -2.2039298309368084E10  | SD       | Ziebach County          | 0             | 2                   |
| -8.801909180859331E8    | SD       |                         | 0             | 30                  |
| -2.1987259856868107E10  | TN       | Williamson County       | 0             | 3                   |
| -1.3196822599079174E10  | TX       | Maverick County         | 0             | 25                  |
| -1.40944599141986E10    | WA       | Kittitas County         | 0             | 18                  |
| -1.3221080666881714E10  | WV       | Raleigh County          | 0             | 24                  |
| -8.823902856026801E8    | WV       |                         | 0             | 29                  |
+-------------------------+----------+-------------------------+---------------+---------------------+--+
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
STOP hdp2.6_hivetez_run_orc_1000_2_query70_sql_2017-04-12-07-22:  Wed Apr 12 07:23:11 CDT 2017
