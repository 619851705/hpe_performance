START hdp2.6_spark21_run_1000_1_query87_sql_2017-04-11-08-50:  Tue Apr 11 08:50:25 CDT 2017
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_1000
17/04/11 08:50:25 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/11 08:50:25 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/11 08:50:25 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_1000
Connected to: Spark SQL (version 2.1.0.2.6.0.3-8)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select count(*) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from (select distinct c_last_name as l1, c_first_name as f1, d_date as d1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        from store_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         JOIN customer ON store_sales.ss_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        where 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          d_month_seq between 1193 and 1193+11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ) t1
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       LEFT OUTER JOIN
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ( select distinct c_last_name as l2, c_first_name as f2, d_date as d2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        from catalog_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         JOIN date_dim ON catalog_sales.cs_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         JOIN customer ON catalog_sales.cs_bill_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        where 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          d_month_seq between 1193 and 1193+11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ) t2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ON t1.l1 = t2.l2 and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        t1.f1 = t2.f2 and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        t1.d1 = t2.d2
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       LEFT OUTER JOIN
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       (select distinct c_last_name as l3, c_first_name as f3, d_date as d3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        from web_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         JOIN date_dim ON web_sales.ws_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>         JOIN customer ON web_sales.ws_bill_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        where 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          d_month_seq between 1193 and 1193+11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ) t3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ON t1.l1 = t3.l3 and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        t1.f1 = t3.f3 and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        t1.d1 = t3.d3
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> WHERE
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     l2 is null and
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     l3 is null ;
+-----------------+--+
|    count(1)     |
+-----------------+--+
| 32016933        |
+-----------------+--+
1 row selected (13.688 seconds)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_1000
STOP hdp2.6_spark21_run_1000_1_query87_sql_2017-04-11-08-50:  Tue Apr 11 08:50:39 CDT 2017
