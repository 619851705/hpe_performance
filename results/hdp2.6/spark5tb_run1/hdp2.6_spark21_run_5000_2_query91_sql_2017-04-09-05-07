START hdp2.6_spark21_run_5000_2_query91_sql_2017-04-09-05-07:  Sun Apr 9 05:07:40 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:07:41 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:07:41 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         cc_call_center_id Call_Center,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         cc_name Call_Center_Name,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         cc_manager Manager,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         sum(cr_net_loss) Returns_Loss
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         call_center,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         catalog_returns,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         date_dim,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         customer,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         customer_address,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         customer_demographics,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         household_demographics
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         catalog_returns.cr_call_center_sk       = call_center.cc_call_center_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     catalog_returns.cr_returned_date_sk     = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     catalog_returns.cr_returning_customer_sk= customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     customer_demographics.cd_demo_sk              = customer.c_current_cdemo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     household_demographics.hd_demo_sk              = customer.c_current_hdemo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     customer_address.ca_address_sk           = customer.c_current_addr_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     d_year                  = 1999 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     d_moy                   = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     ( (cd_marital_status       = 'M' and cd_education_status     = 'Unknown')
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         or(cd_marital_status       = 'W' and cd_education_status     = 'Advanced Degree'))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     hd_buy_potential like '0-500%'
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> and     ca_gmt_offset           = -7
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> group by cc_call_center_id,cc_name,cc_manager,cd_marital_status,cd_education_status
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> order by Returns_Loss desc;
17/04/09 05:07:41 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:07:41 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:07:41 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/09 05:07:41 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:07:41 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:07:41 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:41 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_5000_2_query91_sql_2017-04-09-05-07:  Sun Apr 9 05:07:41 CDT 2017
