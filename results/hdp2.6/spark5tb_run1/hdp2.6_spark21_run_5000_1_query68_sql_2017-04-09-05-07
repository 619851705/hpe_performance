START hdp2.6_spark21_run_5000_1_query68_sql_2017-04-09-05-07:  Sun Apr 9 05:07:01 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:07:02 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:07:02 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select  c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,c_first_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ca_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,extended_price
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,extended_tax
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        ,list_price
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  from (select ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              ,ss_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              ,ca_city bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              ,sum(ss_ext_sales_price) extended_price 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              ,sum(ss_ext_list_price) list_price
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              ,sum(ss_ext_tax) extended_tax 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        from store_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            ,date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            ,store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            ,household_demographics
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>            ,customer_address 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        where store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          and store_sales.ss_store_sk = store.s_store_sk  
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and store_sales.ss_addr_sk = customer_address.ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and date_dim.d_dom between 1 and 2 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and (household_demographics.hd_dep_count = 4 or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>              household_demographics.hd_vehicle_count= 2)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and date_dim.d_year in (1998,1998+1,1998+2)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and store.s_city in ('Rosedale','Bethlehem')
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>        group by ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                ,ss_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>                ,ss_addr_sk,ca_city) dn
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,customer
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>       ,customer_address current_addr
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  where dn.ss_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    and customer.c_current_addr_sk = current_addr.ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>    and current_addr.ca_city <> bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  order by c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>          ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>  limit 100;
17/04/09 05:07:02 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:07:02 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:07:02 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/09 05:07:02 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:07:02 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:07:02 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:07:02 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_5000_1_query68_sql_2017-04-09-05-07:  Sun Apr 9 05:07:02 CDT 2017
