START hdp2.6_spark21_run_5000_1_query65_sql_2017-04-09-05-06:  Sun Apr 9 05:06:54 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:06:55 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:06:55 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> select 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     s_store_name,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     i_item_desc,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     sc.revenue,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     i_current_price,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     i_wholesale_cost,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     i_brand
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     store,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     item,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     (select 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss_store_sk, avg(revenue) as ave
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         (select 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         store_sales, date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss_sold_date_sk = d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>             and d_month_seq between 1212 and 1212 + 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     group by ss_store_sk , ss_item_sk) sa
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     group by ss_store_sk) sb,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     (select 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         store_sales, date_dim
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         ss_sold_date_sk = d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>             and d_month_seq between 1212 and 1212 + 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     group by ss_store_sk , ss_item_sk) sc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>     sb.ss_store_sk = sc.ss_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and sc.revenue <= 0.1 * sb.ave
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and s_store_sk = sc.ss_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)>         and i_item_sk = sc.ss_item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> order by s_store_name , i_item_desc
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi (closed)> limit 100;
17/04/09 05:06:55 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:06:55 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:06:55 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO HiveConnection: Transport Used for JDBC connection: null
No current connection

17/04/09 05:06:55 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 05:06:55 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 05:06:55 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO HiveConnection: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 05:06:55 INFO HiveConnection: Transport Used for JDBC connection: null
Error: Could not open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000: java.net.ConnectException: Connection refused (Connection refused) (state=08S01,code=0)
STOP hdp2.6_spark21_run_5000_1_query65_sql_2017-04-09-05-06:  Sun Apr 9 05:06:55 CDT 2017
