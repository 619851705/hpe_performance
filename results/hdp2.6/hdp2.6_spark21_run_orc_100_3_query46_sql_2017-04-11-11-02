START hdp2.6_spark21_run_orc_100_3_query46_sql_2017-04-11-11-02:  Tue Apr 11 11:02:12 CDT 2017
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_orc_100
17/04/11 11:02:13 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/11 11:02:13 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/11 11:02:13 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_orc_100
Connected to: Spark SQL (version 2.1.0.2.6.0.3-8)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,c_first_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,ca_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>        ,amt,profit 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>    (select ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,ss_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,ca_city bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,sum(ss_coupon_amt) amt
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,sum(ss_net_profit) profit
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     from store_sales,date_dim,store,household_demographics,customer_address 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     where store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store_sales.ss_store_sk = store.s_store_sk  
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store_sales.ss_addr_sk = customer_address.ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and (household_demographics.hd_dep_count = 4 or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>          household_demographics.hd_vehicle_count= 2)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and date_dim.d_dow in (6,0)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and date_dim.d_year in (1998,1998+1,1998+2) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     and store.s_city in ('Rosedale','Bethlehem','Clinton','Clifton','Springfield') 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     group by ss_ticket_number,ss_customer_sk,ss_addr_sk,ca_city) dn,customer,customer_address current_addr
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>     where dn.ss_customer_sk = customer.c_customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       and customer.c_current_addr_sk = current_addr.ca_address_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       and current_addr.ca_city <> bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>   order by c_last_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,c_first_name
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,ca_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,bought_city
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           ,ss_ticket_number
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>   limit 100;
+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--+
|   c_last_name   |  c_first_name   |     ca_city     |   bought_city   | ss_ticket_number |       amt       |     profit      |
+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--+
+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--+
No rows selected (30.095 seconds)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_orc_100
STOP hdp2.6_spark21_run_orc_100_3_query46_sql_2017-04-11-11-02:  Tue Apr 11 11:02:46 CDT 2017
