START hdp2.6_spark21_run_100_3_query88_sql_2017-04-11-10-01:  Tue Apr 11 10:01:00 CDT 2017
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
17/04/11 10:01:01 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/11 10:01:01 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/11 10:01:01 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
Connected to: Spark SQL (version 2.1.0.2.6.0.3-8)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h8_30_to_9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2)) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s1,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_to_9_30 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s2,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_30_to_10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s3,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_to_10_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s4,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_30_to_11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s5,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_to_11_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s6,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_30_to_12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s7,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h12_to_12_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ;
Error: org.apache.spark.sql.AnalysisException: Detected cartesian product for INNER join between logical plans
Join Inner
:- Join Inner
:  :- Join Inner
:  :  :- Join Inner
:  :  :  :- Join Inner
:  :  :  :  :- Join Inner
:  :  :  :  :  :- Aggregate [count(1) AS h8_30_to_9#199341L]
:  :  :  :  :  :  +- Project
:  :  :  :  :  :     +- Join Inner, (ss_store_sk#199356 = s_store_sk#199387)
:  :  :  :  :  :        :- Project [ss_store_sk#199356]
:  :  :  :  :  :        :  +- Join Inner, (ss_sold_time_sk#199350 = t_time_sk#199377)
:  :  :  :  :  :        :     :- Project [ss_sold_time_sk#199350, ss_store_sk#199356]
:  :  :  :  :  :        :     :  +- Join Inner, (ss_hdemo_sk#199354 = hd_demo_sk#199372)
:  :  :  :  :  :        :     :     :- Project [ss_sold_time_sk#199350, ss_hdemo_sk#199354, ss_store_sk#199356]
:  :  :  :  :  :        :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199354) && isnotnull(ss_sold_time_sk#199350)) && isnotnull(ss_store_sk#199356))
:  :  :  :  :  :        :     :     :     +- Relation[ss_sold_time_sk#199350,ss_item_sk#199351,ss_customer_sk#199352,ss_cdemo_sk#199353,ss_hdemo_sk#199354,ss_addr_sk#199355,ss_store_sk#199356,ss_promo_sk#199357,ss_ticket_number#199358,ss_quantity#199359,ss_wholesale_cost#199360,ss_list_price#199361,ss_sales_price#199362,ss_ext_discount_amt#199363,ss_ext_sales_price#199364,ss_ext_wholesale_cost#199365,ss_ext_list_price#199366,ss_ext_tax#199367,ss_coupon_amt#199368,ss_net_paid#199369,ss_net_paid_inc_tax#199370,ss_net_profit#199371,ss_sold_date_sk#199349] parquet
:  :  :  :  :  :        :     :     +- Project [hd_demo_sk#199372]
:  :  :  :  :  :        :     :        +- Filter (((((hd_dep_count#199375 = 3) && (hd_vehicle_count#199376 <= 5)) || ((hd_dep_count#199375 = 0) && (hd_vehicle_count#199376 <= 2))) || ((hd_dep_count#199375 = 1) && (hd_vehicle_count#199376 <= 3))) && isnotnull(hd_demo_sk#199372))
:  :  :  :  :  :        :     :           +- InMemoryRelation [hd_demo_sk#199372, hd_income_band_sk#199373, hd_buy_potential#199374, hd_dep_count#199375, hd_vehicle_count#199376], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :  :        :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :  :        :     +- Project [t_time_sk#199377]
:  :  :  :  :  :        :        +- Filter (((isnotnull(t_hour#199380) && isnotnull(t_minute#199381)) && ((t_hour#199380 = 8) && (t_minute#199381 >= 30))) && isnotnull(t_time_sk#199377))
:  :  :  :  :  :        :           +- InMemoryRelation [t_time_sk#199377, t_time_id#199378, t_time#199379, t_hour#199380, t_minute#199381, t_second#199382, t_am_pm#199383, t_shift#199384, t_sub_shift#199385, t_meal_time#199386], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :  :        :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :  :        +- Project [s_store_sk#199387]
:  :  :  :  :  :           +- Filter ((isnotnull(s_store_name#199392) && (s_store_name#199392 = ese)) && isnotnull(s_store_sk#199387))
:  :  :  :  :  :              +- InMemoryRelation [s_store_sk#199387, s_store_id#199388, s_rec_start_date#199389, s_rec_end_date#199390, s_closed_date_sk#199391, s_store_name#199392, s_number_employees#199393, s_floor_space#199394, s_hours#199395, s_manager#199396, s_market_id#199397, s_geography_class#199398, s_market_desc#199399, s_market_manager#199400, s_division_id#199401, s_division_name#199402, s_company_id#199403, s_company_name#199404, s_street_number#199405, s_street_name#199406, s_street_type#199407, s_suite_number#199408, s_city#199409, s_county#199410, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :  :                    +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  :  +- Aggregate [count(1) AS h9_to_9_30#199342L]
:  :  :  :  :     +- Project
:  :  :  :  :        +- Join Inner, (ss_store_sk#199423 = s_store_sk#199454)
:  :  :  :  :           :- Project [ss_store_sk#199423]
:  :  :  :  :           :  +- Join Inner, (ss_sold_time_sk#199417 = t_time_sk#199444)
:  :  :  :  :           :     :- Project [ss_sold_time_sk#199417, ss_store_sk#199423]
:  :  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#199421 = hd_demo_sk#199439)
:  :  :  :  :           :     :     :- Project [ss_sold_time_sk#199417, ss_hdemo_sk#199421, ss_store_sk#199423]
:  :  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199421) && isnotnull(ss_sold_time_sk#199417)) && isnotnull(ss_store_sk#199423))
:  :  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#199417,ss_item_sk#199418,ss_customer_sk#199419,ss_cdemo_sk#199420,ss_hdemo_sk#199421,ss_addr_sk#199422,ss_store_sk#199423,ss_promo_sk#199424,ss_ticket_number#199425,ss_quantity#199426,ss_wholesale_cost#199427,ss_list_price#199428,ss_sales_price#199429,ss_ext_discount_amt#199430,ss_ext_sales_price#199431,ss_ext_wholesale_cost#199432,ss_ext_list_price#199433,ss_ext_tax#199434,ss_coupon_amt#199435,ss_net_paid#199436,ss_net_paid_inc_tax#199437,ss_net_profit#199438,ss_sold_date_sk#199416] parquet
:  :  :  :  :           :     :     +- Project [hd_demo_sk#199439]
:  :  :  :  :           :     :        +- Filter (((((hd_dep_count#199442 = 3) && (hd_vehicle_count#199443 <= 5)) || ((hd_dep_count#199442 = 0) && (hd_vehicle_count#199443 <= 2))) || ((hd_dep_count#199442 = 1) && (hd_vehicle_count#199443 <= 3))) && isnotnull(hd_demo_sk#199439))
:  :  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#199439, hd_income_band_sk#199440, hd_buy_potential#199441, hd_dep_count#199442, hd_vehicle_count#199443], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :           :     +- Project [t_time_sk#199444]
:  :  :  :  :           :        +- Filter (((isnotnull(t_hour#199447) && isnotnull(t_minute#199448)) && ((t_hour#199447 = 9) && (t_minute#199448 < 30))) && isnotnull(t_time_sk#199444))
:  :  :  :  :           :           +- InMemoryRelation [t_time_sk#199444, t_time_id#199445, t_time#199446, t_hour#199447, t_minute#199448, t_second#199449, t_am_pm#199450, t_shift#199451, t_sub_shift#199452, t_meal_time#199453], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :           +- Project [s_store_sk#199454]
:  :  :  :  :              +- Filter ((isnotnull(s_store_name#199459) && (s_store_name#199459 = ese)) && isnotnull(s_store_sk#199454))
:  :  :  :  :                 +- InMemoryRelation [s_store_sk#199454, s_store_id#199455, s_rec_start_date#199456, s_rec_end_date#199457, s_closed_date_sk#199458, s_store_name#199459, s_number_employees#199460, s_floor_space#199461, s_hours#199462, s_manager#199463, s_market_id#199464, s_geography_class#199465, s_market_desc#199466, s_market_manager#199467, s_division_id#199468, s_division_name#199469, s_company_id#199470, s_company_name#199471, s_street_number#199472, s_street_name#199473, s_street_type#199474, s_suite_number#199475, s_city#199476, s_county#199477, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  +- Aggregate [count(1) AS h9_30_to_10#199343L]
:  :  :  :     +- Project
:  :  :  :        +- Join Inner, (ss_store_sk#199490 = s_store_sk#199521)
:  :  :  :           :- Project [ss_store_sk#199490]
:  :  :  :           :  +- Join Inner, (ss_sold_time_sk#199484 = t_time_sk#199511)
:  :  :  :           :     :- Project [ss_sold_time_sk#199484, ss_store_sk#199490]
:  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#199488 = hd_demo_sk#199506)
:  :  :  :           :     :     :- Project [ss_sold_time_sk#199484, ss_hdemo_sk#199488, ss_store_sk#199490]
:  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199488) && isnotnull(ss_sold_time_sk#199484)) && isnotnull(ss_store_sk#199490))
:  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#199484,ss_item_sk#199485,ss_customer_sk#199486,ss_cdemo_sk#199487,ss_hdemo_sk#199488,ss_addr_sk#199489,ss_store_sk#199490,ss_promo_sk#199491,ss_ticket_number#199492,ss_quantity#199493,ss_wholesale_cost#199494,ss_list_price#199495,ss_sales_price#199496,ss_ext_discount_amt#199497,ss_ext_sales_price#199498,ss_ext_wholesale_cost#199499,ss_ext_list_price#199500,ss_ext_tax#199501,ss_coupon_amt#199502,ss_net_paid#199503,ss_net_paid_inc_tax#199504,ss_net_profit#199505,ss_sold_date_sk#199483] parquet
:  :  :  :           :     :     +- Project [hd_demo_sk#199506]
:  :  :  :           :     :        +- Filter (((((hd_dep_count#199509 = 3) && (hd_vehicle_count#199510 <= 5)) || ((hd_dep_count#199509 = 0) && (hd_vehicle_count#199510 <= 2))) || ((hd_dep_count#199509 = 1) && (hd_vehicle_count#199510 <= 3))) && isnotnull(hd_demo_sk#199506))
:  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#199506, hd_income_band_sk#199507, hd_buy_potential#199508, hd_dep_count#199509, hd_vehicle_count#199510], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :           :     +- Project [t_time_sk#199511]
:  :  :  :           :        +- Filter (((isnotnull(t_hour#199514) && isnotnull(t_minute#199515)) && ((t_hour#199514 = 9) && (t_minute#199515 >= 30))) && isnotnull(t_time_sk#199511))
:  :  :  :           :           +- InMemoryRelation [t_time_sk#199511, t_time_id#199512, t_time#199513, t_hour#199514, t_minute#199515, t_second#199516, t_am_pm#199517, t_shift#199518, t_sub_shift#199519, t_meal_time#199520], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :           +- Project [s_store_sk#199521]
:  :  :  :              +- Filter ((isnotnull(s_store_name#199526) && (s_store_name#199526 = ese)) && isnotnull(s_store_sk#199521))
:  :  :  :                 +- InMemoryRelation [s_store_sk#199521, s_store_id#199522, s_rec_start_date#199523, s_rec_end_date#199524, s_closed_date_sk#199525, s_store_name#199526, s_number_employees#199527, s_floor_space#199528, s_hours#199529, s_manager#199530, s_market_id#199531, s_geography_class#199532, s_market_desc#199533, s_market_manager#199534, s_division_id#199535, s_division_name#199536, s_company_id#199537, s_company_name#199538, s_street_number#199539, s_street_name#199540, s_street_type#199541, s_suite_number#199542, s_city#199543, s_county#199544, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  +- Aggregate [count(1) AS h10_to_10_30#199344L]
:  :  :     +- Project
:  :  :        +- Join Inner, (ss_store_sk#199557 = s_store_sk#199588)
:  :  :           :- Project [ss_store_sk#199557]
:  :  :           :  +- Join Inner, (ss_sold_time_sk#199551 = t_time_sk#199578)
:  :  :           :     :- Project [ss_sold_time_sk#199551, ss_store_sk#199557]
:  :  :           :     :  +- Join Inner, (ss_hdemo_sk#199555 = hd_demo_sk#199573)
:  :  :           :     :     :- Project [ss_sold_time_sk#199551, ss_hdemo_sk#199555, ss_store_sk#199557]
:  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199555) && isnotnull(ss_sold_time_sk#199551)) && isnotnull(ss_store_sk#199557))
:  :  :           :     :     :     +- Relation[ss_sold_time_sk#199551,ss_item_sk#199552,ss_customer_sk#199553,ss_cdemo_sk#199554,ss_hdemo_sk#199555,ss_addr_sk#199556,ss_store_sk#199557,ss_promo_sk#199558,ss_ticket_number#199559,ss_quantity#199560,ss_wholesale_cost#199561,ss_list_price#199562,ss_sales_price#199563,ss_ext_discount_amt#199564,ss_ext_sales_price#199565,ss_ext_wholesale_cost#199566,ss_ext_list_price#199567,ss_ext_tax#199568,ss_coupon_amt#199569,ss_net_paid#199570,ss_net_paid_inc_tax#199571,ss_net_profit#199572,ss_sold_date_sk#199550] parquet
:  :  :           :     :     +- Project [hd_demo_sk#199573]
:  :  :           :     :        +- Filter (((((hd_dep_count#199576 = 3) && (hd_vehicle_count#199577 <= 5)) || ((hd_dep_count#199576 = 0) && (hd_vehicle_count#199577 <= 2))) || ((hd_dep_count#199576 = 1) && (hd_vehicle_count#199577 <= 3))) && isnotnull(hd_demo_sk#199573))
:  :  :           :     :           +- InMemoryRelation [hd_demo_sk#199573, hd_income_band_sk#199574, hd_buy_potential#199575, hd_dep_count#199576, hd_vehicle_count#199577], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :           :     +- Project [t_time_sk#199578]
:  :  :           :        +- Filter (((isnotnull(t_hour#199581) && isnotnull(t_minute#199582)) && ((t_hour#199581 = 10) && (t_minute#199582 < 30))) && isnotnull(t_time_sk#199578))
:  :  :           :           +- InMemoryRelation [t_time_sk#199578, t_time_id#199579, t_time#199580, t_hour#199581, t_minute#199582, t_second#199583, t_am_pm#199584, t_shift#199585, t_sub_shift#199586, t_meal_time#199587], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :           +- Project [s_store_sk#199588]
:  :  :              +- Filter ((isnotnull(s_store_name#199593) && (s_store_name#199593 = ese)) && isnotnull(s_store_sk#199588))
:  :  :                 +- InMemoryRelation [s_store_sk#199588, s_store_id#199589, s_rec_start_date#199590, s_rec_end_date#199591, s_closed_date_sk#199592, s_store_name#199593, s_number_employees#199594, s_floor_space#199595, s_hours#199596, s_manager#199597, s_market_id#199598, s_geography_class#199599, s_market_desc#199600, s_market_manager#199601, s_division_id#199602, s_division_name#199603, s_company_id#199604, s_company_name#199605, s_street_number#199606, s_street_name#199607, s_street_type#199608, s_suite_number#199609, s_city#199610, s_county#199611, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  +- Aggregate [count(1) AS h10_30_to_11#199345L]
:  :     +- Project
:  :        +- Join Inner, (ss_store_sk#199624 = s_store_sk#199655)
:  :           :- Project [ss_store_sk#199624]
:  :           :  +- Join Inner, (ss_sold_time_sk#199618 = t_time_sk#199645)
:  :           :     :- Project [ss_sold_time_sk#199618, ss_store_sk#199624]
:  :           :     :  +- Join Inner, (ss_hdemo_sk#199622 = hd_demo_sk#199640)
:  :           :     :     :- Project [ss_sold_time_sk#199618, ss_hdemo_sk#199622, ss_store_sk#199624]
:  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199622) && isnotnull(ss_sold_time_sk#199618)) && isnotnull(ss_store_sk#199624))
:  :           :     :     :     +- Relation[ss_sold_time_sk#199618,ss_item_sk#199619,ss_customer_sk#199620,ss_cdemo_sk#199621,ss_hdemo_sk#199622,ss_addr_sk#199623,ss_store_sk#199624,ss_promo_sk#199625,ss_ticket_number#199626,ss_quantity#199627,ss_wholesale_cost#199628,ss_list_price#199629,ss_sales_price#199630,ss_ext_discount_amt#199631,ss_ext_sales_price#199632,ss_ext_wholesale_cost#199633,ss_ext_list_price#199634,ss_ext_tax#199635,ss_coupon_amt#199636,ss_net_paid#199637,ss_net_paid_inc_tax#199638,ss_net_profit#199639,ss_sold_date_sk#199617] parquet
:  :           :     :     +- Project [hd_demo_sk#199640]
:  :           :     :        +- Filter (((((hd_dep_count#199643 = 3) && (hd_vehicle_count#199644 <= 5)) || ((hd_dep_count#199643 = 0) && (hd_vehicle_count#199644 <= 2))) || ((hd_dep_count#199643 = 1) && (hd_vehicle_count#199644 <= 3))) && isnotnull(hd_demo_sk#199640))
:  :           :     :           +- InMemoryRelation [hd_demo_sk#199640, hd_income_band_sk#199641, hd_buy_potential#199642, hd_dep_count#199643, hd_vehicle_count#199644], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :           :     +- Project [t_time_sk#199645]
:  :           :        +- Filter (((isnotnull(t_hour#199648) && isnotnull(t_minute#199649)) && ((t_hour#199648 = 10) && (t_minute#199649 >= 30))) && isnotnull(t_time_sk#199645))
:  :           :           +- InMemoryRelation [t_time_sk#199645, t_time_id#199646, t_time#199647, t_hour#199648, t_minute#199649, t_second#199650, t_am_pm#199651, t_shift#199652, t_sub_shift#199653, t_meal_time#199654], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :           +- Project [s_store_sk#199655]
:  :              +- Filter ((isnotnull(s_store_name#199660) && (s_store_name#199660 = ese)) && isnotnull(s_store_sk#199655))
:  :                 +- InMemoryRelation [s_store_sk#199655, s_store_id#199656, s_rec_start_date#199657, s_rec_end_date#199658, s_closed_date_sk#199659, s_store_name#199660, s_number_employees#199661, s_floor_space#199662, s_hours#199663, s_manager#199664, s_market_id#199665, s_geography_class#199666, s_market_desc#199667, s_market_manager#199668, s_division_id#199669, s_division_name#199670, s_company_id#199671, s_company_name#199672, s_street_number#199673, s_street_name#199674, s_street_type#199675, s_suite_number#199676, s_city#199677, s_county#199678, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  +- Aggregate [count(1) AS h11_to_11_30#199346L]
:     +- Project
:        +- Join Inner, (ss_store_sk#199691 = s_store_sk#199722)
:           :- Project [ss_store_sk#199691]
:           :  +- Join Inner, (ss_sold_time_sk#199685 = t_time_sk#199712)
:           :     :- Project [ss_sold_time_sk#199685, ss_store_sk#199691]
:           :     :  +- Join Inner, (ss_hdemo_sk#199689 = hd_demo_sk#199707)
:           :     :     :- Project [ss_sold_time_sk#199685, ss_hdemo_sk#199689, ss_store_sk#199691]
:           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199689) && isnotnull(ss_sold_time_sk#199685)) && isnotnull(ss_store_sk#199691))
:           :     :     :     +- Relation[ss_sold_time_sk#199685,ss_item_sk#199686,ss_customer_sk#199687,ss_cdemo_sk#199688,ss_hdemo_sk#199689,ss_addr_sk#199690,ss_store_sk#199691,ss_promo_sk#199692,ss_ticket_number#199693,ss_quantity#199694,ss_wholesale_cost#199695,ss_list_price#199696,ss_sales_price#199697,ss_ext_discount_amt#199698,ss_ext_sales_price#199699,ss_ext_wholesale_cost#199700,ss_ext_list_price#199701,ss_ext_tax#199702,ss_coupon_amt#199703,ss_net_paid#199704,ss_net_paid_inc_tax#199705,ss_net_profit#199706,ss_sold_date_sk#199684] parquet
:           :     :     +- Project [hd_demo_sk#199707]
:           :     :        +- Filter (((((hd_dep_count#199710 = 3) && (hd_vehicle_count#199711 <= 5)) || ((hd_dep_count#199710 = 0) && (hd_vehicle_count#199711 <= 2))) || ((hd_dep_count#199710 = 1) && (hd_vehicle_count#199711 <= 3))) && isnotnull(hd_demo_sk#199707))
:           :     :           +- InMemoryRelation [hd_demo_sk#199707, hd_income_band_sk#199708, hd_buy_potential#199709, hd_dep_count#199710, hd_vehicle_count#199711], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:           :     +- Project [t_time_sk#199712]
:           :        +- Filter (((isnotnull(t_hour#199715) && isnotnull(t_minute#199716)) && ((t_hour#199715 = 11) && (t_minute#199716 < 30))) && isnotnull(t_time_sk#199712))
:           :           +- InMemoryRelation [t_time_sk#199712, t_time_id#199713, t_time#199714, t_hour#199715, t_minute#199716, t_second#199717, t_am_pm#199718, t_shift#199719, t_sub_shift#199720, t_meal_time#199721], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:           +- Project [s_store_sk#199722]
:              +- Filter ((isnotnull(s_store_name#199727) && (s_store_name#199727 = ese)) && isnotnull(s_store_sk#199722))
:                 +- InMemoryRelation [s_store_sk#199722, s_store_id#199723, s_rec_start_date#199724, s_rec_end_date#199725, s_closed_date_sk#199726, s_store_name#199727, s_number_employees#199728, s_floor_space#199729, s_hours#199730, s_manager#199731, s_market_id#199732, s_geography_class#199733, s_market_desc#199734, s_market_manager#199735, s_division_id#199736, s_division_name#199737, s_company_id#199738, s_company_name#199739, s_street_number#199740, s_street_name#199741, s_street_type#199742, s_suite_number#199743, s_city#199744, s_county#199745, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:                       +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
+- Aggregate [count(1) AS h11_30_to_12#199347L]
   +- Project
      +- Join Inner, (ss_store_sk#199758 = s_store_sk#199789)
         :- Project [ss_store_sk#199758]
         :  +- Join Inner, (ss_sold_time_sk#199752 = t_time_sk#199779)
         :     :- Project [ss_sold_time_sk#199752, ss_store_sk#199758]
         :     :  +- Join Inner, (ss_hdemo_sk#199756 = hd_demo_sk#199774)
         :     :     :- Project [ss_sold_time_sk#199752, ss_hdemo_sk#199756, ss_store_sk#199758]
         :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199756) && isnotnull(ss_sold_time_sk#199752)) && isnotnull(ss_store_sk#199758))
         :     :     :     +- Relation[ss_sold_time_sk#199752,ss_item_sk#199753,ss_customer_sk#199754,ss_cdemo_sk#199755,ss_hdemo_sk#199756,ss_addr_sk#199757,ss_store_sk#199758,ss_promo_sk#199759,ss_ticket_number#199760,ss_quantity#199761,ss_wholesale_cost#199762,ss_list_price#199763,ss_sales_price#199764,ss_ext_discount_amt#199765,ss_ext_sales_price#199766,ss_ext_wholesale_cost#199767,ss_ext_list_price#199768,ss_ext_tax#199769,ss_coupon_amt#199770,ss_net_paid#199771,ss_net_paid_inc_tax#199772,ss_net_profit#199773,ss_sold_date_sk#199751] parquet
         :     :     +- Project [hd_demo_sk#199774]
         :     :        +- Filter (((((hd_dep_count#199777 = 3) && (hd_vehicle_count#199778 <= 5)) || ((hd_dep_count#199777 = 0) && (hd_vehicle_count#199778 <= 2))) || ((hd_dep_count#199777 = 1) && (hd_vehicle_count#199778 <= 3))) && isnotnull(hd_demo_sk#199774))
         :     :           +- InMemoryRelation [hd_demo_sk#199774, hd_income_band_sk#199775, hd_buy_potential#199776, hd_dep_count#199777, hd_vehicle_count#199778], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
         :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
         :     +- Project [t_time_sk#199779]
         :        +- Filter (((isnotnull(t_hour#199782) && isnotnull(t_minute#199783)) && ((t_hour#199782 = 11) && (t_minute#199783 >= 30))) && isnotnull(t_time_sk#199779))
         :           +- InMemoryRelation [t_time_sk#199779, t_time_id#199780, t_time#199781, t_hour#199782, t_minute#199783, t_second#199784, t_am_pm#199785, t_shift#199786, t_sub_shift#199787, t_meal_time#199788], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
         :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
         +- Project [s_store_sk#199789]
            +- Filter ((isnotnull(s_store_name#199794) && (s_store_name#199794 = ese)) && isnotnull(s_store_sk#199789))
               +- InMemoryRelation [s_store_sk#199789, s_store_id#199790, s_rec_start_date#199791, s_rec_end_date#199792, s_closed_date_sk#199793, s_store_name#199794, s_number_employees#199795, s_floor_space#199796, s_hours#199797, s_manager#199798, s_market_id#199799, s_geography_class#199800, s_market_desc#199801, s_market_manager#199802, s_division_id#199803, s_division_name#199804, s_company_id#199805, s_company_name#199806, s_street_number#199807, s_street_name#199808, s_street_type#199809, s_suite_number#199810, s_city#199811, s_county#199812, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                     +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
and
Aggregate [count(1) AS h12_to_12_30#199348L]
+- Project
   +- Join Inner, (ss_store_sk#199825 = s_store_sk#199856)
      :- Project [ss_store_sk#199825]
      :  +- Join Inner, (ss_sold_time_sk#199819 = t_time_sk#199846)
      :     :- Project [ss_sold_time_sk#199819, ss_store_sk#199825]
      :     :  +- Join Inner, (ss_hdemo_sk#199823 = hd_demo_sk#199841)
      :     :     :- Project [ss_sold_time_sk#199819, ss_hdemo_sk#199823, ss_store_sk#199825]
      :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#199823) && isnotnull(ss_sold_time_sk#199819)) && isnotnull(ss_store_sk#199825))
      :     :     :     +- Relation[ss_sold_time_sk#199819,ss_item_sk#199820,ss_customer_sk#199821,ss_cdemo_sk#199822,ss_hdemo_sk#199823,ss_addr_sk#199824,ss_store_sk#199825,ss_promo_sk#199826,ss_ticket_number#199827,ss_quantity#199828,ss_wholesale_cost#199829,ss_list_price#199830,ss_sales_price#199831,ss_ext_discount_amt#199832,ss_ext_sales_price#199833,ss_ext_wholesale_cost#199834,ss_ext_list_price#199835,ss_ext_tax#199836,ss_coupon_amt#199837,ss_net_paid#199838,ss_net_paid_inc_tax#199839,ss_net_profit#199840,ss_sold_date_sk#199818] parquet
      :     :     +- Project [hd_demo_sk#199841]
      :     :        +- Filter (((((hd_dep_count#199844 = 3) && (hd_vehicle_count#199845 <= 5)) || ((hd_dep_count#199844 = 0) && (hd_vehicle_count#199845 <= 2))) || ((hd_dep_count#199844 = 1) && (hd_vehicle_count#199845 <= 3))) && isnotnull(hd_demo_sk#199841))
      :     :           +- InMemoryRelation [hd_demo_sk#199841, hd_income_band_sk#199842, hd_buy_potential#199843, hd_dep_count#199844, hd_vehicle_count#199845], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#199846]
      :        +- Filter (((isnotnull(t_hour#199849) && isnotnull(t_minute#199850)) && ((t_hour#199849 = 12) && (t_minute#199850 < 30))) && isnotnull(t_time_sk#199846))
      :           +- InMemoryRelation [t_time_sk#199846, t_time_id#199847, t_time#199848, t_hour#199849, t_minute#199850, t_second#199851, t_am_pm#199852, t_shift#199853, t_sub_shift#199854, t_meal_time#199855], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_100.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [s_store_sk#199856]
         +- Filter ((isnotnull(s_store_name#199861) && (s_store_name#199861 = ese)) && isnotnull(s_store_sk#199856))
            +- InMemoryRelation [s_store_sk#199856, s_store_id#199857, s_rec_start_date#199858, s_rec_end_date#199859, s_closed_date_sk#199860, s_store_name#199861, s_number_employees#199862, s_floor_space#199863, s_hours#199864, s_manager#199865, s_market_id#199866, s_geography_class#199867, s_market_desc#199868, s_market_manager#199869, s_division_id#199870, s_division_name#199871, s_company_id#199872, s_company_name#199873, s_street_number#199874, s_street_name#199875, s_street_type#199876, s_suite_number#199877, s_city#199878, s_county#199879, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_100.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_10..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
Join condition is missing or trivial.
Use the CROSS JOIN syntax to allow cartesian products between these relations.; (state=,code=0)

Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_100
STOP hdp2.6_spark21_run_100_3_query88_sql_2017-04-11-10-01:  Tue Apr 11 10:01:05 CDT 2017
