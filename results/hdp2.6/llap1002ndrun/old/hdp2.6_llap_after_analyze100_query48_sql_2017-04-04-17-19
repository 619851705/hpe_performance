START hdp2.6_llap_after_analyze100_query48_sql_2017-04-04-17-19:  Tue Apr 4 17:19:09 CDT 2017
beeline -u "jdbc:hive2://h01mgt.hadoop:2181,h01hn01.hadoop:2181,h01hn02.hadoop:2181/tpcds_bin_partitioned_orc_$SF;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2" -n hive --incremental=true -i test.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01mgt.hadoop:2181,h01hn01.hadoop:2181,h01hn02.hadoop:2181/tpcds_bin_partitioned_orc_100;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2
Connected to: Apache Hive (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1000.2.6.0.0-598)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script test.settings
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> set hive.tez.exec.print.summary=true;
No rows affected (0.041 seconds)
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> select sum (ss_quantity)
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  from store_sales, store, customer_demographics, customer_address, date_dim
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  where store.s_store_sk = store_sales.ss_store_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  and  store_sales.ss_sold_date_sk = date_dim.d_date_sk and d_year = 1998
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  and  
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  (
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   (
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    customer_demographics.cd_demo_sk = store_sales.ss_cdemo_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    cd_marital_status = 'M'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    cd_education_status = '4 yr Degree'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    ss_sales_price between 100.00 and 150.00  
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  or
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   (
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   customer_demographics.cd_demo_sk = store_sales.ss_cdemo_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    cd_marital_status = 'M'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    cd_education_status = '4 yr Degree'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    ss_sales_price between 50.00 and 100.00   
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  or 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  (
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   customer_demographics.cd_demo_sk = store_sales.ss_cdemo_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    cd_marital_status = 'M'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    cd_education_status = '4 yr Degree'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    and 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>    ss_sales_price between 150.00 and 200.00  
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  (
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   (
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   store_sales.ss_addr_sk = customer_address.ca_address_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ca_country = 'United States'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ca_state in ('KY', 'GA', 'NM')
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and ss_net_profit between 0 and 2000  
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  or
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   (store_sales.ss_addr_sk = customer_address.ca_address_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ca_country = 'United States'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ca_state in ('MT', 'OR', 'IN')
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and ss_net_profit between 150 and 3000 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  or
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   (store_sales.ss_addr_sk = customer_address.ca_address_sk
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ca_country = 'United States'
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   ca_state in ('WI', 'MO', 'WV')
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   and ss_net_profit between 50 and 25000 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>   )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha>  )
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> ;
+----------+--+
|   _c0    |
+----------+--+
| 2240188  |
+----------+--+
1 row selected (4.794 seconds)
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.ha> 
Closing: 0: jdbc:hive2://h01mgt.hadoop:2181,h01hn01.hadoop:2181,h01hn02.hadoop:2181/tpcds_bin_partitioned_orc_100;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-hive2
STOP hdp2.6_llap_after_analyze100_query48_sql_2017-04-04-17-19:  Tue Apr 4 17:19:18 CDT 2017

 South Results Number of Nodes:  9
 Avg CPU Busy:   Peak Cpu Avg:  100.000 Count > 90% Busy:  0
 Avg Disk Busy:   Peak Disk Avg:  0 Count > 90% busy 0
 Avg Disk Reads per sec:   Avg Write per sec: 
 Avg Net TX:    Peak TX Avg: 
 Avg Net RX:    Peak RX Avg: 
 Mem Utilized: 
South CSV
| 100.000 | 0 | | 0 | 0 | | | | | | |
