START hdp2.6_spark21_run_5000_1_query97_sql_2017-04-09-21-33:  Sun Apr 9 21:33:42 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 21:33:42 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 21:33:42 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 21:33:42 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1 else 0 end) store_only
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ,sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1 else 0 end) catalog_only
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ,sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 else 0 end) store_and_ catalog
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ( select ss_customer_sk customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ,ss_item_sk item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from store_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>   d_month_seq between 1193 and 1193 + 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> group by ss_customer_sk ,ss_item_sk) ssci
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> full outer join
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ( select cs_bill_customer_sk customer_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>       ,cs_item_sk item_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from catalog_sales
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> JOIN date_dim ON catalog_sales.cs_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> where
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>   d_month_seq between 1193 and 1193 + 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> group by cs_bill_customer_sk ,cs_item_sk) csci
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> on (ssci.customer_sk=csci.customer_sk and ssci.item_sk = csci.item_sk)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> limit 100;
+-----------------+-----------------+-----------------+--+
|   store_only    |  catalog_only   | store_and_catalog |
+-----------------+-----------------+-----------------+--+
| 2661858781      | 1400826927      | 22211204        |
+-----------------+-----------------+-----------------+--+
1 row selected (107.818 seconds)
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
STOP hdp2.6_spark21_run_5000_1_query97_sql_2017-04-09-21-33:  Sun Apr 9 21:35:30 CDT 2017
