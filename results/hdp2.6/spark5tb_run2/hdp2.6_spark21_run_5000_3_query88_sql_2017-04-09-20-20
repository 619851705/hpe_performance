START hdp2.6_spark21_run_5000_3_query88_sql_2017-04-09-20-20:  Sun Apr 9 20:20:19 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 20:20:19 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 20:20:19 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 20:20:19 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h8_30_to_9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2)) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s1,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_to_9_30 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s2,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_30_to_10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s3,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_to_10_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s4,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_30_to_11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s5,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_to_11_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s6,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_30_to_12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s7,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h12_to_12_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ;
Error: org.apache.spark.sql.AnalysisException: Detected cartesian product for INNER join between logical plans
Join Inner
:- Join Inner
:  :- Join Inner
:  :  :- Join Inner
:  :  :  :- Join Inner
:  :  :  :  :- Join Inner
:  :  :  :  :  :- Aggregate [count(1) AS h8_30_to_9#80346L]
:  :  :  :  :  :  +- Project
:  :  :  :  :  :     +- Join Inner, (ss_store_sk#80361 = s_store_sk#80392)
:  :  :  :  :  :        :- Project [ss_store_sk#80361]
:  :  :  :  :  :        :  +- Join Inner, (ss_sold_time_sk#80355 = t_time_sk#80382)
:  :  :  :  :  :        :     :- Project [ss_sold_time_sk#80355, ss_store_sk#80361]
:  :  :  :  :  :        :     :  +- Join Inner, (ss_hdemo_sk#80359 = hd_demo_sk#80377)
:  :  :  :  :  :        :     :     :- Project [ss_sold_time_sk#80355, ss_hdemo_sk#80359, ss_store_sk#80361]
:  :  :  :  :  :        :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80359) && isnotnull(ss_sold_time_sk#80355)) && isnotnull(ss_store_sk#80361))
:  :  :  :  :  :        :     :     :     +- Relation[ss_sold_time_sk#80355,ss_item_sk#80356,ss_customer_sk#80357,ss_cdemo_sk#80358,ss_hdemo_sk#80359,ss_addr_sk#80360,ss_store_sk#80361,ss_promo_sk#80362,ss_ticket_number#80363,ss_quantity#80364,ss_wholesale_cost#80365,ss_list_price#80366,ss_sales_price#80367,ss_ext_discount_amt#80368,ss_ext_sales_price#80369,ss_ext_wholesale_cost#80370,ss_ext_list_price#80371,ss_ext_tax#80372,ss_coupon_amt#80373,ss_net_paid#80374,ss_net_paid_inc_tax#80375,ss_net_profit#80376,ss_sold_date_sk#80354] parquet
:  :  :  :  :  :        :     :     +- Project [hd_demo_sk#80377]
:  :  :  :  :  :        :     :        +- Filter (((((hd_dep_count#80380 = 3) && (hd_vehicle_count#80381 <= 5)) || ((hd_dep_count#80380 = 0) && (hd_vehicle_count#80381 <= 2))) || ((hd_dep_count#80380 = 1) && (hd_vehicle_count#80381 <= 3))) && isnotnull(hd_demo_sk#80377))
:  :  :  :  :  :        :     :           +- InMemoryRelation [hd_demo_sk#80377, hd_income_band_sk#80378, hd_buy_potential#80379, hd_dep_count#80380, hd_vehicle_count#80381], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :  :        :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :  :        :     +- Project [t_time_sk#80382]
:  :  :  :  :  :        :        +- Filter (((isnotnull(t_hour#80385) && isnotnull(t_minute#80386)) && ((t_hour#80385 = 8) && (t_minute#80386 >= 30))) && isnotnull(t_time_sk#80382))
:  :  :  :  :  :        :           +- InMemoryRelation [t_time_sk#80382, t_time_id#80383, t_time#80384, t_hour#80385, t_minute#80386, t_second#80387, t_am_pm#80388, t_shift#80389, t_sub_shift#80390, t_meal_time#80391], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :  :        :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :  :        +- Project [s_store_sk#80392]
:  :  :  :  :  :           +- Filter ((isnotnull(s_store_name#80397) && (s_store_name#80397 = ese)) && isnotnull(s_store_sk#80392))
:  :  :  :  :  :              +- InMemoryRelation [s_store_sk#80392, s_store_id#80393, s_rec_start_date#80394, s_rec_end_date#80395, s_closed_date_sk#80396, s_store_name#80397, s_number_employees#80398, s_floor_space#80399, s_hours#80400, s_manager#80401, s_market_id#80402, s_geography_class#80403, s_market_desc#80404, s_market_manager#80405, s_division_id#80406, s_division_name#80407, s_company_id#80408, s_company_name#80409, s_street_number#80410, s_street_name#80411, s_street_type#80412, s_suite_number#80413, s_city#80414, s_county#80415, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :  :                    +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  :  +- Aggregate [count(1) AS h9_to_9_30#80347L]
:  :  :  :  :     +- Project
:  :  :  :  :        +- Join Inner, (ss_store_sk#80428 = s_store_sk#80459)
:  :  :  :  :           :- Project [ss_store_sk#80428]
:  :  :  :  :           :  +- Join Inner, (ss_sold_time_sk#80422 = t_time_sk#80449)
:  :  :  :  :           :     :- Project [ss_sold_time_sk#80422, ss_store_sk#80428]
:  :  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#80426 = hd_demo_sk#80444)
:  :  :  :  :           :     :     :- Project [ss_sold_time_sk#80422, ss_hdemo_sk#80426, ss_store_sk#80428]
:  :  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80426) && isnotnull(ss_sold_time_sk#80422)) && isnotnull(ss_store_sk#80428))
:  :  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#80422,ss_item_sk#80423,ss_customer_sk#80424,ss_cdemo_sk#80425,ss_hdemo_sk#80426,ss_addr_sk#80427,ss_store_sk#80428,ss_promo_sk#80429,ss_ticket_number#80430,ss_quantity#80431,ss_wholesale_cost#80432,ss_list_price#80433,ss_sales_price#80434,ss_ext_discount_amt#80435,ss_ext_sales_price#80436,ss_ext_wholesale_cost#80437,ss_ext_list_price#80438,ss_ext_tax#80439,ss_coupon_amt#80440,ss_net_paid#80441,ss_net_paid_inc_tax#80442,ss_net_profit#80443,ss_sold_date_sk#80421] parquet
:  :  :  :  :           :     :     +- Project [hd_demo_sk#80444]
:  :  :  :  :           :     :        +- Filter (((((hd_dep_count#80447 = 3) && (hd_vehicle_count#80448 <= 5)) || ((hd_dep_count#80447 = 0) && (hd_vehicle_count#80448 <= 2))) || ((hd_dep_count#80447 = 1) && (hd_vehicle_count#80448 <= 3))) && isnotnull(hd_demo_sk#80444))
:  :  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#80444, hd_income_band_sk#80445, hd_buy_potential#80446, hd_dep_count#80447, hd_vehicle_count#80448], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :           :     +- Project [t_time_sk#80449]
:  :  :  :  :           :        +- Filter (((isnotnull(t_hour#80452) && isnotnull(t_minute#80453)) && ((t_hour#80452 = 9) && (t_minute#80453 < 30))) && isnotnull(t_time_sk#80449))
:  :  :  :  :           :           +- InMemoryRelation [t_time_sk#80449, t_time_id#80450, t_time#80451, t_hour#80452, t_minute#80453, t_second#80454, t_am_pm#80455, t_shift#80456, t_sub_shift#80457, t_meal_time#80458], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :           +- Project [s_store_sk#80459]
:  :  :  :  :              +- Filter ((isnotnull(s_store_name#80464) && (s_store_name#80464 = ese)) && isnotnull(s_store_sk#80459))
:  :  :  :  :                 +- InMemoryRelation [s_store_sk#80459, s_store_id#80460, s_rec_start_date#80461, s_rec_end_date#80462, s_closed_date_sk#80463, s_store_name#80464, s_number_employees#80465, s_floor_space#80466, s_hours#80467, s_manager#80468, s_market_id#80469, s_geography_class#80470, s_market_desc#80471, s_market_manager#80472, s_division_id#80473, s_division_name#80474, s_company_id#80475, s_company_name#80476, s_street_number#80477, s_street_name#80478, s_street_type#80479, s_suite_number#80480, s_city#80481, s_county#80482, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  +- Aggregate [count(1) AS h9_30_to_10#80348L]
:  :  :  :     +- Project
:  :  :  :        +- Join Inner, (ss_store_sk#80495 = s_store_sk#80526)
:  :  :  :           :- Project [ss_store_sk#80495]
:  :  :  :           :  +- Join Inner, (ss_sold_time_sk#80489 = t_time_sk#80516)
:  :  :  :           :     :- Project [ss_sold_time_sk#80489, ss_store_sk#80495]
:  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#80493 = hd_demo_sk#80511)
:  :  :  :           :     :     :- Project [ss_sold_time_sk#80489, ss_hdemo_sk#80493, ss_store_sk#80495]
:  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80493) && isnotnull(ss_sold_time_sk#80489)) && isnotnull(ss_store_sk#80495))
:  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#80489,ss_item_sk#80490,ss_customer_sk#80491,ss_cdemo_sk#80492,ss_hdemo_sk#80493,ss_addr_sk#80494,ss_store_sk#80495,ss_promo_sk#80496,ss_ticket_number#80497,ss_quantity#80498,ss_wholesale_cost#80499,ss_list_price#80500,ss_sales_price#80501,ss_ext_discount_amt#80502,ss_ext_sales_price#80503,ss_ext_wholesale_cost#80504,ss_ext_list_price#80505,ss_ext_tax#80506,ss_coupon_amt#80507,ss_net_paid#80508,ss_net_paid_inc_tax#80509,ss_net_profit#80510,ss_sold_date_sk#80488] parquet
:  :  :  :           :     :     +- Project [hd_demo_sk#80511]
:  :  :  :           :     :        +- Filter (((((hd_dep_count#80514 = 3) && (hd_vehicle_count#80515 <= 5)) || ((hd_dep_count#80514 = 0) && (hd_vehicle_count#80515 <= 2))) || ((hd_dep_count#80514 = 1) && (hd_vehicle_count#80515 <= 3))) && isnotnull(hd_demo_sk#80511))
:  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#80511, hd_income_band_sk#80512, hd_buy_potential#80513, hd_dep_count#80514, hd_vehicle_count#80515], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :           :     +- Project [t_time_sk#80516]
:  :  :  :           :        +- Filter (((isnotnull(t_hour#80519) && isnotnull(t_minute#80520)) && ((t_hour#80519 = 9) && (t_minute#80520 >= 30))) && isnotnull(t_time_sk#80516))
:  :  :  :           :           +- InMemoryRelation [t_time_sk#80516, t_time_id#80517, t_time#80518, t_hour#80519, t_minute#80520, t_second#80521, t_am_pm#80522, t_shift#80523, t_sub_shift#80524, t_meal_time#80525], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :           +- Project [s_store_sk#80526]
:  :  :  :              +- Filter ((isnotnull(s_store_name#80531) && (s_store_name#80531 = ese)) && isnotnull(s_store_sk#80526))
:  :  :  :                 +- InMemoryRelation [s_store_sk#80526, s_store_id#80527, s_rec_start_date#80528, s_rec_end_date#80529, s_closed_date_sk#80530, s_store_name#80531, s_number_employees#80532, s_floor_space#80533, s_hours#80534, s_manager#80535, s_market_id#80536, s_geography_class#80537, s_market_desc#80538, s_market_manager#80539, s_division_id#80540, s_division_name#80541, s_company_id#80542, s_company_name#80543, s_street_number#80544, s_street_name#80545, s_street_type#80546, s_suite_number#80547, s_city#80548, s_county#80549, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  +- Aggregate [count(1) AS h10_to_10_30#80349L]
:  :  :     +- Project
:  :  :        +- Join Inner, (ss_store_sk#80562 = s_store_sk#80593)
:  :  :           :- Project [ss_store_sk#80562]
:  :  :           :  +- Join Inner, (ss_sold_time_sk#80556 = t_time_sk#80583)
:  :  :           :     :- Project [ss_sold_time_sk#80556, ss_store_sk#80562]
:  :  :           :     :  +- Join Inner, (ss_hdemo_sk#80560 = hd_demo_sk#80578)
:  :  :           :     :     :- Project [ss_sold_time_sk#80556, ss_hdemo_sk#80560, ss_store_sk#80562]
:  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80560) && isnotnull(ss_sold_time_sk#80556)) && isnotnull(ss_store_sk#80562))
:  :  :           :     :     :     +- Relation[ss_sold_time_sk#80556,ss_item_sk#80557,ss_customer_sk#80558,ss_cdemo_sk#80559,ss_hdemo_sk#80560,ss_addr_sk#80561,ss_store_sk#80562,ss_promo_sk#80563,ss_ticket_number#80564,ss_quantity#80565,ss_wholesale_cost#80566,ss_list_price#80567,ss_sales_price#80568,ss_ext_discount_amt#80569,ss_ext_sales_price#80570,ss_ext_wholesale_cost#80571,ss_ext_list_price#80572,ss_ext_tax#80573,ss_coupon_amt#80574,ss_net_paid#80575,ss_net_paid_inc_tax#80576,ss_net_profit#80577,ss_sold_date_sk#80555] parquet
:  :  :           :     :     +- Project [hd_demo_sk#80578]
:  :  :           :     :        +- Filter (((((hd_dep_count#80581 = 3) && (hd_vehicle_count#80582 <= 5)) || ((hd_dep_count#80581 = 0) && (hd_vehicle_count#80582 <= 2))) || ((hd_dep_count#80581 = 1) && (hd_vehicle_count#80582 <= 3))) && isnotnull(hd_demo_sk#80578))
:  :  :           :     :           +- InMemoryRelation [hd_demo_sk#80578, hd_income_band_sk#80579, hd_buy_potential#80580, hd_dep_count#80581, hd_vehicle_count#80582], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :           :     +- Project [t_time_sk#80583]
:  :  :           :        +- Filter (((isnotnull(t_hour#80586) && isnotnull(t_minute#80587)) && ((t_hour#80586 = 10) && (t_minute#80587 < 30))) && isnotnull(t_time_sk#80583))
:  :  :           :           +- InMemoryRelation [t_time_sk#80583, t_time_id#80584, t_time#80585, t_hour#80586, t_minute#80587, t_second#80588, t_am_pm#80589, t_shift#80590, t_sub_shift#80591, t_meal_time#80592], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :           +- Project [s_store_sk#80593]
:  :  :              +- Filter ((isnotnull(s_store_name#80598) && (s_store_name#80598 = ese)) && isnotnull(s_store_sk#80593))
:  :  :                 +- InMemoryRelation [s_store_sk#80593, s_store_id#80594, s_rec_start_date#80595, s_rec_end_date#80596, s_closed_date_sk#80597, s_store_name#80598, s_number_employees#80599, s_floor_space#80600, s_hours#80601, s_manager#80602, s_market_id#80603, s_geography_class#80604, s_market_desc#80605, s_market_manager#80606, s_division_id#80607, s_division_name#80608, s_company_id#80609, s_company_name#80610, s_street_number#80611, s_street_name#80612, s_street_type#80613, s_suite_number#80614, s_city#80615, s_county#80616, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  +- Aggregate [count(1) AS h10_30_to_11#80350L]
:  :     +- Project
:  :        +- Join Inner, (ss_store_sk#80629 = s_store_sk#80660)
:  :           :- Project [ss_store_sk#80629]
:  :           :  +- Join Inner, (ss_sold_time_sk#80623 = t_time_sk#80650)
:  :           :     :- Project [ss_sold_time_sk#80623, ss_store_sk#80629]
:  :           :     :  +- Join Inner, (ss_hdemo_sk#80627 = hd_demo_sk#80645)
:  :           :     :     :- Project [ss_sold_time_sk#80623, ss_hdemo_sk#80627, ss_store_sk#80629]
:  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80627) && isnotnull(ss_sold_time_sk#80623)) && isnotnull(ss_store_sk#80629))
:  :           :     :     :     +- Relation[ss_sold_time_sk#80623,ss_item_sk#80624,ss_customer_sk#80625,ss_cdemo_sk#80626,ss_hdemo_sk#80627,ss_addr_sk#80628,ss_store_sk#80629,ss_promo_sk#80630,ss_ticket_number#80631,ss_quantity#80632,ss_wholesale_cost#80633,ss_list_price#80634,ss_sales_price#80635,ss_ext_discount_amt#80636,ss_ext_sales_price#80637,ss_ext_wholesale_cost#80638,ss_ext_list_price#80639,ss_ext_tax#80640,ss_coupon_amt#80641,ss_net_paid#80642,ss_net_paid_inc_tax#80643,ss_net_profit#80644,ss_sold_date_sk#80622] parquet
:  :           :     :     +- Project [hd_demo_sk#80645]
:  :           :     :        +- Filter (((((hd_dep_count#80648 = 3) && (hd_vehicle_count#80649 <= 5)) || ((hd_dep_count#80648 = 0) && (hd_vehicle_count#80649 <= 2))) || ((hd_dep_count#80648 = 1) && (hd_vehicle_count#80649 <= 3))) && isnotnull(hd_demo_sk#80645))
:  :           :     :           +- InMemoryRelation [hd_demo_sk#80645, hd_income_band_sk#80646, hd_buy_potential#80647, hd_dep_count#80648, hd_vehicle_count#80649], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :           :     +- Project [t_time_sk#80650]
:  :           :        +- Filter (((isnotnull(t_hour#80653) && isnotnull(t_minute#80654)) && ((t_hour#80653 = 10) && (t_minute#80654 >= 30))) && isnotnull(t_time_sk#80650))
:  :           :           +- InMemoryRelation [t_time_sk#80650, t_time_id#80651, t_time#80652, t_hour#80653, t_minute#80654, t_second#80655, t_am_pm#80656, t_shift#80657, t_sub_shift#80658, t_meal_time#80659], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :           +- Project [s_store_sk#80660]
:  :              +- Filter ((isnotnull(s_store_name#80665) && (s_store_name#80665 = ese)) && isnotnull(s_store_sk#80660))
:  :                 +- InMemoryRelation [s_store_sk#80660, s_store_id#80661, s_rec_start_date#80662, s_rec_end_date#80663, s_closed_date_sk#80664, s_store_name#80665, s_number_employees#80666, s_floor_space#80667, s_hours#80668, s_manager#80669, s_market_id#80670, s_geography_class#80671, s_market_desc#80672, s_market_manager#80673, s_division_id#80674, s_division_name#80675, s_company_id#80676, s_company_name#80677, s_street_number#80678, s_street_name#80679, s_street_type#80680, s_suite_number#80681, s_city#80682, s_county#80683, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  +- Aggregate [count(1) AS h11_to_11_30#80351L]
:     +- Project
:        +- Join Inner, (ss_store_sk#80696 = s_store_sk#80727)
:           :- Project [ss_store_sk#80696]
:           :  +- Join Inner, (ss_sold_time_sk#80690 = t_time_sk#80717)
:           :     :- Project [ss_sold_time_sk#80690, ss_store_sk#80696]
:           :     :  +- Join Inner, (ss_hdemo_sk#80694 = hd_demo_sk#80712)
:           :     :     :- Project [ss_sold_time_sk#80690, ss_hdemo_sk#80694, ss_store_sk#80696]
:           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80694) && isnotnull(ss_sold_time_sk#80690)) && isnotnull(ss_store_sk#80696))
:           :     :     :     +- Relation[ss_sold_time_sk#80690,ss_item_sk#80691,ss_customer_sk#80692,ss_cdemo_sk#80693,ss_hdemo_sk#80694,ss_addr_sk#80695,ss_store_sk#80696,ss_promo_sk#80697,ss_ticket_number#80698,ss_quantity#80699,ss_wholesale_cost#80700,ss_list_price#80701,ss_sales_price#80702,ss_ext_discount_amt#80703,ss_ext_sales_price#80704,ss_ext_wholesale_cost#80705,ss_ext_list_price#80706,ss_ext_tax#80707,ss_coupon_amt#80708,ss_net_paid#80709,ss_net_paid_inc_tax#80710,ss_net_profit#80711,ss_sold_date_sk#80689] parquet
:           :     :     +- Project [hd_demo_sk#80712]
:           :     :        +- Filter (((((hd_dep_count#80715 = 3) && (hd_vehicle_count#80716 <= 5)) || ((hd_dep_count#80715 = 0) && (hd_vehicle_count#80716 <= 2))) || ((hd_dep_count#80715 = 1) && (hd_vehicle_count#80716 <= 3))) && isnotnull(hd_demo_sk#80712))
:           :     :           +- InMemoryRelation [hd_demo_sk#80712, hd_income_band_sk#80713, hd_buy_potential#80714, hd_dep_count#80715, hd_vehicle_count#80716], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:           :     +- Project [t_time_sk#80717]
:           :        +- Filter (((isnotnull(t_hour#80720) && isnotnull(t_minute#80721)) && ((t_hour#80720 = 11) && (t_minute#80721 < 30))) && isnotnull(t_time_sk#80717))
:           :           +- InMemoryRelation [t_time_sk#80717, t_time_id#80718, t_time#80719, t_hour#80720, t_minute#80721, t_second#80722, t_am_pm#80723, t_shift#80724, t_sub_shift#80725, t_meal_time#80726], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:           +- Project [s_store_sk#80727]
:              +- Filter ((isnotnull(s_store_name#80732) && (s_store_name#80732 = ese)) && isnotnull(s_store_sk#80727))
:                 +- InMemoryRelation [s_store_sk#80727, s_store_id#80728, s_rec_start_date#80729, s_rec_end_date#80730, s_closed_date_sk#80731, s_store_name#80732, s_number_employees#80733, s_floor_space#80734, s_hours#80735, s_manager#80736, s_market_id#80737, s_geography_class#80738, s_market_desc#80739, s_market_manager#80740, s_division_id#80741, s_division_name#80742, s_company_id#80743, s_company_name#80744, s_street_number#80745, s_street_name#80746, s_street_type#80747, s_suite_number#80748, s_city#80749, s_county#80750, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
+- Aggregate [count(1) AS h11_30_to_12#80352L]
   +- Project
      +- Join Inner, (ss_store_sk#80763 = s_store_sk#80794)
         :- Project [ss_store_sk#80763]
         :  +- Join Inner, (ss_sold_time_sk#80757 = t_time_sk#80784)
         :     :- Project [ss_sold_time_sk#80757, ss_store_sk#80763]
         :     :  +- Join Inner, (ss_hdemo_sk#80761 = hd_demo_sk#80779)
         :     :     :- Project [ss_sold_time_sk#80757, ss_hdemo_sk#80761, ss_store_sk#80763]
         :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80761) && isnotnull(ss_sold_time_sk#80757)) && isnotnull(ss_store_sk#80763))
         :     :     :     +- Relation[ss_sold_time_sk#80757,ss_item_sk#80758,ss_customer_sk#80759,ss_cdemo_sk#80760,ss_hdemo_sk#80761,ss_addr_sk#80762,ss_store_sk#80763,ss_promo_sk#80764,ss_ticket_number#80765,ss_quantity#80766,ss_wholesale_cost#80767,ss_list_price#80768,ss_sales_price#80769,ss_ext_discount_amt#80770,ss_ext_sales_price#80771,ss_ext_wholesale_cost#80772,ss_ext_list_price#80773,ss_ext_tax#80774,ss_coupon_amt#80775,ss_net_paid#80776,ss_net_paid_inc_tax#80777,ss_net_profit#80778,ss_sold_date_sk#80756] parquet
         :     :     +- Project [hd_demo_sk#80779]
         :     :        +- Filter (((((hd_dep_count#80782 = 3) && (hd_vehicle_count#80783 <= 5)) || ((hd_dep_count#80782 = 0) && (hd_vehicle_count#80783 <= 2))) || ((hd_dep_count#80782 = 1) && (hd_vehicle_count#80783 <= 3))) && isnotnull(hd_demo_sk#80779))
         :     :           +- InMemoryRelation [hd_demo_sk#80779, hd_income_band_sk#80780, hd_buy_potential#80781, hd_dep_count#80782, hd_vehicle_count#80783], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
         :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
         :     +- Project [t_time_sk#80784]
         :        +- Filter (((isnotnull(t_hour#80787) && isnotnull(t_minute#80788)) && ((t_hour#80787 = 11) && (t_minute#80788 >= 30))) && isnotnull(t_time_sk#80784))
         :           +- InMemoryRelation [t_time_sk#80784, t_time_id#80785, t_time#80786, t_hour#80787, t_minute#80788, t_second#80789, t_am_pm#80790, t_shift#80791, t_sub_shift#80792, t_meal_time#80793], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
         :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
         +- Project [s_store_sk#80794]
            +- Filter ((isnotnull(s_store_name#80799) && (s_store_name#80799 = ese)) && isnotnull(s_store_sk#80794))
               +- InMemoryRelation [s_store_sk#80794, s_store_id#80795, s_rec_start_date#80796, s_rec_end_date#80797, s_closed_date_sk#80798, s_store_name#80799, s_number_employees#80800, s_floor_space#80801, s_hours#80802, s_manager#80803, s_market_id#80804, s_geography_class#80805, s_market_desc#80806, s_market_manager#80807, s_division_id#80808, s_division_name#80809, s_company_id#80810, s_company_name#80811, s_street_number#80812, s_street_name#80813, s_street_type#80814, s_suite_number#80815, s_city#80816, s_county#80817, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                     +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
and
Aggregate [count(1) AS h12_to_12_30#80353L]
+- Project
   +- Join Inner, (ss_store_sk#80830 = s_store_sk#80861)
      :- Project [ss_store_sk#80830]
      :  +- Join Inner, (ss_sold_time_sk#80824 = t_time_sk#80851)
      :     :- Project [ss_sold_time_sk#80824, ss_store_sk#80830]
      :     :  +- Join Inner, (ss_hdemo_sk#80828 = hd_demo_sk#80846)
      :     :     :- Project [ss_sold_time_sk#80824, ss_hdemo_sk#80828, ss_store_sk#80830]
      :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#80828) && isnotnull(ss_sold_time_sk#80824)) && isnotnull(ss_store_sk#80830))
      :     :     :     +- Relation[ss_sold_time_sk#80824,ss_item_sk#80825,ss_customer_sk#80826,ss_cdemo_sk#80827,ss_hdemo_sk#80828,ss_addr_sk#80829,ss_store_sk#80830,ss_promo_sk#80831,ss_ticket_number#80832,ss_quantity#80833,ss_wholesale_cost#80834,ss_list_price#80835,ss_sales_price#80836,ss_ext_discount_amt#80837,ss_ext_sales_price#80838,ss_ext_wholesale_cost#80839,ss_ext_list_price#80840,ss_ext_tax#80841,ss_coupon_amt#80842,ss_net_paid#80843,ss_net_paid_inc_tax#80844,ss_net_profit#80845,ss_sold_date_sk#80823] parquet
      :     :     +- Project [hd_demo_sk#80846]
      :     :        +- Filter (((((hd_dep_count#80849 = 3) && (hd_vehicle_count#80850 <= 5)) || ((hd_dep_count#80849 = 0) && (hd_vehicle_count#80850 <= 2))) || ((hd_dep_count#80849 = 1) && (hd_vehicle_count#80850 <= 3))) && isnotnull(hd_demo_sk#80846))
      :     :           +- InMemoryRelation [hd_demo_sk#80846, hd_income_band_sk#80847, hd_buy_potential#80848, hd_dep_count#80849, hd_vehicle_count#80850], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#80851]
      :        +- Filter (((isnotnull(t_hour#80854) && isnotnull(t_minute#80855)) && ((t_hour#80854 = 12) && (t_minute#80855 < 30))) && isnotnull(t_time_sk#80851))
      :           +- InMemoryRelation [t_time_sk#80851, t_time_id#80852, t_time#80853, t_hour#80854, t_minute#80855, t_second#80856, t_am_pm#80857, t_shift#80858, t_sub_shift#80859, t_meal_time#80860], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [s_store_sk#80861]
         +- Filter ((isnotnull(s_store_name#80866) && (s_store_name#80866 = ese)) && isnotnull(s_store_sk#80861))
            +- InMemoryRelation [s_store_sk#80861, s_store_id#80862, s_rec_start_date#80863, s_rec_end_date#80864, s_closed_date_sk#80865, s_store_name#80866, s_number_employees#80867, s_floor_space#80868, s_hours#80869, s_manager#80870, s_market_id#80871, s_geography_class#80872, s_market_desc#80873, s_market_manager#80874, s_division_id#80875, s_division_name#80876, s_company_id#80877, s_company_name#80878, s_street_number#80879, s_street_name#80880, s_street_type#80881, s_suite_number#80882, s_city#80883, s_county#80884, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
Join condition is missing or trivial.
Use the CROSS JOIN syntax to allow cartesian products between these relations.; (state=,code=0)

Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
STOP hdp2.6_spark21_run_5000_3_query88_sql_2017-04-09-20-20:  Sun Apr 9 20:20:23 CDT 2017
