START hdp2.6_spark21_run_5000_1_query88_sql_2017-04-09-20-20:  Sun Apr 9 20:20:09 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 20:20:09 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 20:20:09 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 20:20:10 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h8_30_to_9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2)) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s1,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_to_9_30 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s2,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_30_to_10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s3,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_to_10_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s4,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_30_to_11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s5,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_to_11_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s6,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_30_to_12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s7,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h12_to_12_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ;
Error: org.apache.spark.sql.AnalysisException: Detected cartesian product for INNER join between logical plans
Join Inner
:- Join Inner
:  :- Join Inner
:  :  :- Join Inner
:  :  :  :- Join Inner
:  :  :  :  :- Join Inner
:  :  :  :  :  :- Aggregate [count(1) AS h8_30_to_9#74478L]
:  :  :  :  :  :  +- Project
:  :  :  :  :  :     +- Join Inner, (ss_store_sk#74493 = s_store_sk#74524)
:  :  :  :  :  :        :- Project [ss_store_sk#74493]
:  :  :  :  :  :        :  +- Join Inner, (ss_sold_time_sk#74487 = t_time_sk#74514)
:  :  :  :  :  :        :     :- Project [ss_sold_time_sk#74487, ss_store_sk#74493]
:  :  :  :  :  :        :     :  +- Join Inner, (ss_hdemo_sk#74491 = hd_demo_sk#74509)
:  :  :  :  :  :        :     :     :- Project [ss_sold_time_sk#74487, ss_hdemo_sk#74491, ss_store_sk#74493]
:  :  :  :  :  :        :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74491) && isnotnull(ss_sold_time_sk#74487)) && isnotnull(ss_store_sk#74493))
:  :  :  :  :  :        :     :     :     +- Relation[ss_sold_time_sk#74487,ss_item_sk#74488,ss_customer_sk#74489,ss_cdemo_sk#74490,ss_hdemo_sk#74491,ss_addr_sk#74492,ss_store_sk#74493,ss_promo_sk#74494,ss_ticket_number#74495,ss_quantity#74496,ss_wholesale_cost#74497,ss_list_price#74498,ss_sales_price#74499,ss_ext_discount_amt#74500,ss_ext_sales_price#74501,ss_ext_wholesale_cost#74502,ss_ext_list_price#74503,ss_ext_tax#74504,ss_coupon_amt#74505,ss_net_paid#74506,ss_net_paid_inc_tax#74507,ss_net_profit#74508,ss_sold_date_sk#74486] parquet
:  :  :  :  :  :        :     :     +- Project [hd_demo_sk#74509]
:  :  :  :  :  :        :     :        +- Filter (((((hd_dep_count#74512 = 3) && (hd_vehicle_count#74513 <= 5)) || ((hd_dep_count#74512 = 0) && (hd_vehicle_count#74513 <= 2))) || ((hd_dep_count#74512 = 1) && (hd_vehicle_count#74513 <= 3))) && isnotnull(hd_demo_sk#74509))
:  :  :  :  :  :        :     :           +- InMemoryRelation [hd_demo_sk#74509, hd_income_band_sk#74510, hd_buy_potential#74511, hd_dep_count#74512, hd_vehicle_count#74513], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :  :        :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :  :        :     +- Project [t_time_sk#74514]
:  :  :  :  :  :        :        +- Filter (((isnotnull(t_hour#74517) && isnotnull(t_minute#74518)) && ((t_hour#74517 = 8) && (t_minute#74518 >= 30))) && isnotnull(t_time_sk#74514))
:  :  :  :  :  :        :           +- InMemoryRelation [t_time_sk#74514, t_time_id#74515, t_time#74516, t_hour#74517, t_minute#74518, t_second#74519, t_am_pm#74520, t_shift#74521, t_sub_shift#74522, t_meal_time#74523], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :  :        :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :  :        +- Project [s_store_sk#74524]
:  :  :  :  :  :           +- Filter ((isnotnull(s_store_name#74529) && (s_store_name#74529 = ese)) && isnotnull(s_store_sk#74524))
:  :  :  :  :  :              +- InMemoryRelation [s_store_sk#74524, s_store_id#74525, s_rec_start_date#74526, s_rec_end_date#74527, s_closed_date_sk#74528, s_store_name#74529, s_number_employees#74530, s_floor_space#74531, s_hours#74532, s_manager#74533, s_market_id#74534, s_geography_class#74535, s_market_desc#74536, s_market_manager#74537, s_division_id#74538, s_division_name#74539, s_company_id#74540, s_company_name#74541, s_street_number#74542, s_street_name#74543, s_street_type#74544, s_suite_number#74545, s_city#74546, s_county#74547, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :  :                    +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  :  +- Aggregate [count(1) AS h9_to_9_30#74479L]
:  :  :  :  :     +- Project
:  :  :  :  :        +- Join Inner, (ss_store_sk#74560 = s_store_sk#74591)
:  :  :  :  :           :- Project [ss_store_sk#74560]
:  :  :  :  :           :  +- Join Inner, (ss_sold_time_sk#74554 = t_time_sk#74581)
:  :  :  :  :           :     :- Project [ss_sold_time_sk#74554, ss_store_sk#74560]
:  :  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#74558 = hd_demo_sk#74576)
:  :  :  :  :           :     :     :- Project [ss_sold_time_sk#74554, ss_hdemo_sk#74558, ss_store_sk#74560]
:  :  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74558) && isnotnull(ss_sold_time_sk#74554)) && isnotnull(ss_store_sk#74560))
:  :  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#74554,ss_item_sk#74555,ss_customer_sk#74556,ss_cdemo_sk#74557,ss_hdemo_sk#74558,ss_addr_sk#74559,ss_store_sk#74560,ss_promo_sk#74561,ss_ticket_number#74562,ss_quantity#74563,ss_wholesale_cost#74564,ss_list_price#74565,ss_sales_price#74566,ss_ext_discount_amt#74567,ss_ext_sales_price#74568,ss_ext_wholesale_cost#74569,ss_ext_list_price#74570,ss_ext_tax#74571,ss_coupon_amt#74572,ss_net_paid#74573,ss_net_paid_inc_tax#74574,ss_net_profit#74575,ss_sold_date_sk#74553] parquet
:  :  :  :  :           :     :     +- Project [hd_demo_sk#74576]
:  :  :  :  :           :     :        +- Filter (((((hd_dep_count#74579 = 3) && (hd_vehicle_count#74580 <= 5)) || ((hd_dep_count#74579 = 0) && (hd_vehicle_count#74580 <= 2))) || ((hd_dep_count#74579 = 1) && (hd_vehicle_count#74580 <= 3))) && isnotnull(hd_demo_sk#74576))
:  :  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#74576, hd_income_band_sk#74577, hd_buy_potential#74578, hd_dep_count#74579, hd_vehicle_count#74580], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :           :     +- Project [t_time_sk#74581]
:  :  :  :  :           :        +- Filter (((isnotnull(t_hour#74584) && isnotnull(t_minute#74585)) && ((t_hour#74584 = 9) && (t_minute#74585 < 30))) && isnotnull(t_time_sk#74581))
:  :  :  :  :           :           +- InMemoryRelation [t_time_sk#74581, t_time_id#74582, t_time#74583, t_hour#74584, t_minute#74585, t_second#74586, t_am_pm#74587, t_shift#74588, t_sub_shift#74589, t_meal_time#74590], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :           +- Project [s_store_sk#74591]
:  :  :  :  :              +- Filter ((isnotnull(s_store_name#74596) && (s_store_name#74596 = ese)) && isnotnull(s_store_sk#74591))
:  :  :  :  :                 +- InMemoryRelation [s_store_sk#74591, s_store_id#74592, s_rec_start_date#74593, s_rec_end_date#74594, s_closed_date_sk#74595, s_store_name#74596, s_number_employees#74597, s_floor_space#74598, s_hours#74599, s_manager#74600, s_market_id#74601, s_geography_class#74602, s_market_desc#74603, s_market_manager#74604, s_division_id#74605, s_division_name#74606, s_company_id#74607, s_company_name#74608, s_street_number#74609, s_street_name#74610, s_street_type#74611, s_suite_number#74612, s_city#74613, s_county#74614, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  +- Aggregate [count(1) AS h9_30_to_10#74480L]
:  :  :  :     +- Project
:  :  :  :        +- Join Inner, (ss_store_sk#74627 = s_store_sk#74658)
:  :  :  :           :- Project [ss_store_sk#74627]
:  :  :  :           :  +- Join Inner, (ss_sold_time_sk#74621 = t_time_sk#74648)
:  :  :  :           :     :- Project [ss_sold_time_sk#74621, ss_store_sk#74627]
:  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#74625 = hd_demo_sk#74643)
:  :  :  :           :     :     :- Project [ss_sold_time_sk#74621, ss_hdemo_sk#74625, ss_store_sk#74627]
:  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74625) && isnotnull(ss_sold_time_sk#74621)) && isnotnull(ss_store_sk#74627))
:  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#74621,ss_item_sk#74622,ss_customer_sk#74623,ss_cdemo_sk#74624,ss_hdemo_sk#74625,ss_addr_sk#74626,ss_store_sk#74627,ss_promo_sk#74628,ss_ticket_number#74629,ss_quantity#74630,ss_wholesale_cost#74631,ss_list_price#74632,ss_sales_price#74633,ss_ext_discount_amt#74634,ss_ext_sales_price#74635,ss_ext_wholesale_cost#74636,ss_ext_list_price#74637,ss_ext_tax#74638,ss_coupon_amt#74639,ss_net_paid#74640,ss_net_paid_inc_tax#74641,ss_net_profit#74642,ss_sold_date_sk#74620] parquet
:  :  :  :           :     :     +- Project [hd_demo_sk#74643]
:  :  :  :           :     :        +- Filter (((((hd_dep_count#74646 = 3) && (hd_vehicle_count#74647 <= 5)) || ((hd_dep_count#74646 = 0) && (hd_vehicle_count#74647 <= 2))) || ((hd_dep_count#74646 = 1) && (hd_vehicle_count#74647 <= 3))) && isnotnull(hd_demo_sk#74643))
:  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#74643, hd_income_band_sk#74644, hd_buy_potential#74645, hd_dep_count#74646, hd_vehicle_count#74647], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :           :     +- Project [t_time_sk#74648]
:  :  :  :           :        +- Filter (((isnotnull(t_hour#74651) && isnotnull(t_minute#74652)) && ((t_hour#74651 = 9) && (t_minute#74652 >= 30))) && isnotnull(t_time_sk#74648))
:  :  :  :           :           +- InMemoryRelation [t_time_sk#74648, t_time_id#74649, t_time#74650, t_hour#74651, t_minute#74652, t_second#74653, t_am_pm#74654, t_shift#74655, t_sub_shift#74656, t_meal_time#74657], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :           +- Project [s_store_sk#74658]
:  :  :  :              +- Filter ((isnotnull(s_store_name#74663) && (s_store_name#74663 = ese)) && isnotnull(s_store_sk#74658))
:  :  :  :                 +- InMemoryRelation [s_store_sk#74658, s_store_id#74659, s_rec_start_date#74660, s_rec_end_date#74661, s_closed_date_sk#74662, s_store_name#74663, s_number_employees#74664, s_floor_space#74665, s_hours#74666, s_manager#74667, s_market_id#74668, s_geography_class#74669, s_market_desc#74670, s_market_manager#74671, s_division_id#74672, s_division_name#74673, s_company_id#74674, s_company_name#74675, s_street_number#74676, s_street_name#74677, s_street_type#74678, s_suite_number#74679, s_city#74680, s_county#74681, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  +- Aggregate [count(1) AS h10_to_10_30#74481L]
:  :  :     +- Project
:  :  :        +- Join Inner, (ss_store_sk#74694 = s_store_sk#74725)
:  :  :           :- Project [ss_store_sk#74694]
:  :  :           :  +- Join Inner, (ss_sold_time_sk#74688 = t_time_sk#74715)
:  :  :           :     :- Project [ss_sold_time_sk#74688, ss_store_sk#74694]
:  :  :           :     :  +- Join Inner, (ss_hdemo_sk#74692 = hd_demo_sk#74710)
:  :  :           :     :     :- Project [ss_sold_time_sk#74688, ss_hdemo_sk#74692, ss_store_sk#74694]
:  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74692) && isnotnull(ss_sold_time_sk#74688)) && isnotnull(ss_store_sk#74694))
:  :  :           :     :     :     +- Relation[ss_sold_time_sk#74688,ss_item_sk#74689,ss_customer_sk#74690,ss_cdemo_sk#74691,ss_hdemo_sk#74692,ss_addr_sk#74693,ss_store_sk#74694,ss_promo_sk#74695,ss_ticket_number#74696,ss_quantity#74697,ss_wholesale_cost#74698,ss_list_price#74699,ss_sales_price#74700,ss_ext_discount_amt#74701,ss_ext_sales_price#74702,ss_ext_wholesale_cost#74703,ss_ext_list_price#74704,ss_ext_tax#74705,ss_coupon_amt#74706,ss_net_paid#74707,ss_net_paid_inc_tax#74708,ss_net_profit#74709,ss_sold_date_sk#74687] parquet
:  :  :           :     :     +- Project [hd_demo_sk#74710]
:  :  :           :     :        +- Filter (((((hd_dep_count#74713 = 3) && (hd_vehicle_count#74714 <= 5)) || ((hd_dep_count#74713 = 0) && (hd_vehicle_count#74714 <= 2))) || ((hd_dep_count#74713 = 1) && (hd_vehicle_count#74714 <= 3))) && isnotnull(hd_demo_sk#74710))
:  :  :           :     :           +- InMemoryRelation [hd_demo_sk#74710, hd_income_band_sk#74711, hd_buy_potential#74712, hd_dep_count#74713, hd_vehicle_count#74714], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :           :     +- Project [t_time_sk#74715]
:  :  :           :        +- Filter (((isnotnull(t_hour#74718) && isnotnull(t_minute#74719)) && ((t_hour#74718 = 10) && (t_minute#74719 < 30))) && isnotnull(t_time_sk#74715))
:  :  :           :           +- InMemoryRelation [t_time_sk#74715, t_time_id#74716, t_time#74717, t_hour#74718, t_minute#74719, t_second#74720, t_am_pm#74721, t_shift#74722, t_sub_shift#74723, t_meal_time#74724], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :           +- Project [s_store_sk#74725]
:  :  :              +- Filter ((isnotnull(s_store_name#74730) && (s_store_name#74730 = ese)) && isnotnull(s_store_sk#74725))
:  :  :                 +- InMemoryRelation [s_store_sk#74725, s_store_id#74726, s_rec_start_date#74727, s_rec_end_date#74728, s_closed_date_sk#74729, s_store_name#74730, s_number_employees#74731, s_floor_space#74732, s_hours#74733, s_manager#74734, s_market_id#74735, s_geography_class#74736, s_market_desc#74737, s_market_manager#74738, s_division_id#74739, s_division_name#74740, s_company_id#74741, s_company_name#74742, s_street_number#74743, s_street_name#74744, s_street_type#74745, s_suite_number#74746, s_city#74747, s_county#74748, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  +- Aggregate [count(1) AS h10_30_to_11#74482L]
:  :     +- Project
:  :        +- Join Inner, (ss_store_sk#74761 = s_store_sk#74792)
:  :           :- Project [ss_store_sk#74761]
:  :           :  +- Join Inner, (ss_sold_time_sk#74755 = t_time_sk#74782)
:  :           :     :- Project [ss_sold_time_sk#74755, ss_store_sk#74761]
:  :           :     :  +- Join Inner, (ss_hdemo_sk#74759 = hd_demo_sk#74777)
:  :           :     :     :- Project [ss_sold_time_sk#74755, ss_hdemo_sk#74759, ss_store_sk#74761]
:  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74759) && isnotnull(ss_sold_time_sk#74755)) && isnotnull(ss_store_sk#74761))
:  :           :     :     :     +- Relation[ss_sold_time_sk#74755,ss_item_sk#74756,ss_customer_sk#74757,ss_cdemo_sk#74758,ss_hdemo_sk#74759,ss_addr_sk#74760,ss_store_sk#74761,ss_promo_sk#74762,ss_ticket_number#74763,ss_quantity#74764,ss_wholesale_cost#74765,ss_list_price#74766,ss_sales_price#74767,ss_ext_discount_amt#74768,ss_ext_sales_price#74769,ss_ext_wholesale_cost#74770,ss_ext_list_price#74771,ss_ext_tax#74772,ss_coupon_amt#74773,ss_net_paid#74774,ss_net_paid_inc_tax#74775,ss_net_profit#74776,ss_sold_date_sk#74754] parquet
:  :           :     :     +- Project [hd_demo_sk#74777]
:  :           :     :        +- Filter (((((hd_dep_count#74780 = 3) && (hd_vehicle_count#74781 <= 5)) || ((hd_dep_count#74780 = 0) && (hd_vehicle_count#74781 <= 2))) || ((hd_dep_count#74780 = 1) && (hd_vehicle_count#74781 <= 3))) && isnotnull(hd_demo_sk#74777))
:  :           :     :           +- InMemoryRelation [hd_demo_sk#74777, hd_income_band_sk#74778, hd_buy_potential#74779, hd_dep_count#74780, hd_vehicle_count#74781], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :           :     +- Project [t_time_sk#74782]
:  :           :        +- Filter (((isnotnull(t_hour#74785) && isnotnull(t_minute#74786)) && ((t_hour#74785 = 10) && (t_minute#74786 >= 30))) && isnotnull(t_time_sk#74782))
:  :           :           +- InMemoryRelation [t_time_sk#74782, t_time_id#74783, t_time#74784, t_hour#74785, t_minute#74786, t_second#74787, t_am_pm#74788, t_shift#74789, t_sub_shift#74790, t_meal_time#74791], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :           +- Project [s_store_sk#74792]
:  :              +- Filter ((isnotnull(s_store_name#74797) && (s_store_name#74797 = ese)) && isnotnull(s_store_sk#74792))
:  :                 +- InMemoryRelation [s_store_sk#74792, s_store_id#74793, s_rec_start_date#74794, s_rec_end_date#74795, s_closed_date_sk#74796, s_store_name#74797, s_number_employees#74798, s_floor_space#74799, s_hours#74800, s_manager#74801, s_market_id#74802, s_geography_class#74803, s_market_desc#74804, s_market_manager#74805, s_division_id#74806, s_division_name#74807, s_company_id#74808, s_company_name#74809, s_street_number#74810, s_street_name#74811, s_street_type#74812, s_suite_number#74813, s_city#74814, s_county#74815, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  +- Aggregate [count(1) AS h11_to_11_30#74483L]
:     +- Project
:        +- Join Inner, (ss_store_sk#74828 = s_store_sk#74859)
:           :- Project [ss_store_sk#74828]
:           :  +- Join Inner, (ss_sold_time_sk#74822 = t_time_sk#74849)
:           :     :- Project [ss_sold_time_sk#74822, ss_store_sk#74828]
:           :     :  +- Join Inner, (ss_hdemo_sk#74826 = hd_demo_sk#74844)
:           :     :     :- Project [ss_sold_time_sk#74822, ss_hdemo_sk#74826, ss_store_sk#74828]
:           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74826) && isnotnull(ss_sold_time_sk#74822)) && isnotnull(ss_store_sk#74828))
:           :     :     :     +- Relation[ss_sold_time_sk#74822,ss_item_sk#74823,ss_customer_sk#74824,ss_cdemo_sk#74825,ss_hdemo_sk#74826,ss_addr_sk#74827,ss_store_sk#74828,ss_promo_sk#74829,ss_ticket_number#74830,ss_quantity#74831,ss_wholesale_cost#74832,ss_list_price#74833,ss_sales_price#74834,ss_ext_discount_amt#74835,ss_ext_sales_price#74836,ss_ext_wholesale_cost#74837,ss_ext_list_price#74838,ss_ext_tax#74839,ss_coupon_amt#74840,ss_net_paid#74841,ss_net_paid_inc_tax#74842,ss_net_profit#74843,ss_sold_date_sk#74821] parquet
:           :     :     +- Project [hd_demo_sk#74844]
:           :     :        +- Filter (((((hd_dep_count#74847 = 3) && (hd_vehicle_count#74848 <= 5)) || ((hd_dep_count#74847 = 0) && (hd_vehicle_count#74848 <= 2))) || ((hd_dep_count#74847 = 1) && (hd_vehicle_count#74848 <= 3))) && isnotnull(hd_demo_sk#74844))
:           :     :           +- InMemoryRelation [hd_demo_sk#74844, hd_income_band_sk#74845, hd_buy_potential#74846, hd_dep_count#74847, hd_vehicle_count#74848], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:           :     +- Project [t_time_sk#74849]
:           :        +- Filter (((isnotnull(t_hour#74852) && isnotnull(t_minute#74853)) && ((t_hour#74852 = 11) && (t_minute#74853 < 30))) && isnotnull(t_time_sk#74849))
:           :           +- InMemoryRelation [t_time_sk#74849, t_time_id#74850, t_time#74851, t_hour#74852, t_minute#74853, t_second#74854, t_am_pm#74855, t_shift#74856, t_sub_shift#74857, t_meal_time#74858], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:           +- Project [s_store_sk#74859]
:              +- Filter ((isnotnull(s_store_name#74864) && (s_store_name#74864 = ese)) && isnotnull(s_store_sk#74859))
:                 +- InMemoryRelation [s_store_sk#74859, s_store_id#74860, s_rec_start_date#74861, s_rec_end_date#74862, s_closed_date_sk#74863, s_store_name#74864, s_number_employees#74865, s_floor_space#74866, s_hours#74867, s_manager#74868, s_market_id#74869, s_geography_class#74870, s_market_desc#74871, s_market_manager#74872, s_division_id#74873, s_division_name#74874, s_company_id#74875, s_company_name#74876, s_street_number#74877, s_street_name#74878, s_street_type#74879, s_suite_number#74880, s_city#74881, s_county#74882, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
+- Aggregate [count(1) AS h11_30_to_12#74484L]
   +- Project
      +- Join Inner, (ss_store_sk#74895 = s_store_sk#74926)
         :- Project [ss_store_sk#74895]
         :  +- Join Inner, (ss_sold_time_sk#74889 = t_time_sk#74916)
         :     :- Project [ss_sold_time_sk#74889, ss_store_sk#74895]
         :     :  +- Join Inner, (ss_hdemo_sk#74893 = hd_demo_sk#74911)
         :     :     :- Project [ss_sold_time_sk#74889, ss_hdemo_sk#74893, ss_store_sk#74895]
         :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74893) && isnotnull(ss_sold_time_sk#74889)) && isnotnull(ss_store_sk#74895))
         :     :     :     +- Relation[ss_sold_time_sk#74889,ss_item_sk#74890,ss_customer_sk#74891,ss_cdemo_sk#74892,ss_hdemo_sk#74893,ss_addr_sk#74894,ss_store_sk#74895,ss_promo_sk#74896,ss_ticket_number#74897,ss_quantity#74898,ss_wholesale_cost#74899,ss_list_price#74900,ss_sales_price#74901,ss_ext_discount_amt#74902,ss_ext_sales_price#74903,ss_ext_wholesale_cost#74904,ss_ext_list_price#74905,ss_ext_tax#74906,ss_coupon_amt#74907,ss_net_paid#74908,ss_net_paid_inc_tax#74909,ss_net_profit#74910,ss_sold_date_sk#74888] parquet
         :     :     +- Project [hd_demo_sk#74911]
         :     :        +- Filter (((((hd_dep_count#74914 = 3) && (hd_vehicle_count#74915 <= 5)) || ((hd_dep_count#74914 = 0) && (hd_vehicle_count#74915 <= 2))) || ((hd_dep_count#74914 = 1) && (hd_vehicle_count#74915 <= 3))) && isnotnull(hd_demo_sk#74911))
         :     :           +- InMemoryRelation [hd_demo_sk#74911, hd_income_band_sk#74912, hd_buy_potential#74913, hd_dep_count#74914, hd_vehicle_count#74915], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
         :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
         :     +- Project [t_time_sk#74916]
         :        +- Filter (((isnotnull(t_hour#74919) && isnotnull(t_minute#74920)) && ((t_hour#74919 = 11) && (t_minute#74920 >= 30))) && isnotnull(t_time_sk#74916))
         :           +- InMemoryRelation [t_time_sk#74916, t_time_id#74917, t_time#74918, t_hour#74919, t_minute#74920, t_second#74921, t_am_pm#74922, t_shift#74923, t_sub_shift#74924, t_meal_time#74925], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
         :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
         +- Project [s_store_sk#74926]
            +- Filter ((isnotnull(s_store_name#74931) && (s_store_name#74931 = ese)) && isnotnull(s_store_sk#74926))
               +- InMemoryRelation [s_store_sk#74926, s_store_id#74927, s_rec_start_date#74928, s_rec_end_date#74929, s_closed_date_sk#74930, s_store_name#74931, s_number_employees#74932, s_floor_space#74933, s_hours#74934, s_manager#74935, s_market_id#74936, s_geography_class#74937, s_market_desc#74938, s_market_manager#74939, s_division_id#74940, s_division_name#74941, s_company_id#74942, s_company_name#74943, s_street_number#74944, s_street_name#74945, s_street_type#74946, s_suite_number#74947, s_city#74948, s_county#74949, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                     +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
and
Aggregate [count(1) AS h12_to_12_30#74485L]
+- Project
   +- Join Inner, (ss_store_sk#74962 = s_store_sk#74993)
      :- Project [ss_store_sk#74962]
      :  +- Join Inner, (ss_sold_time_sk#74956 = t_time_sk#74983)
      :     :- Project [ss_sold_time_sk#74956, ss_store_sk#74962]
      :     :  +- Join Inner, (ss_hdemo_sk#74960 = hd_demo_sk#74978)
      :     :     :- Project [ss_sold_time_sk#74956, ss_hdemo_sk#74960, ss_store_sk#74962]
      :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#74960) && isnotnull(ss_sold_time_sk#74956)) && isnotnull(ss_store_sk#74962))
      :     :     :     +- Relation[ss_sold_time_sk#74956,ss_item_sk#74957,ss_customer_sk#74958,ss_cdemo_sk#74959,ss_hdemo_sk#74960,ss_addr_sk#74961,ss_store_sk#74962,ss_promo_sk#74963,ss_ticket_number#74964,ss_quantity#74965,ss_wholesale_cost#74966,ss_list_price#74967,ss_sales_price#74968,ss_ext_discount_amt#74969,ss_ext_sales_price#74970,ss_ext_wholesale_cost#74971,ss_ext_list_price#74972,ss_ext_tax#74973,ss_coupon_amt#74974,ss_net_paid#74975,ss_net_paid_inc_tax#74976,ss_net_profit#74977,ss_sold_date_sk#74955] parquet
      :     :     +- Project [hd_demo_sk#74978]
      :     :        +- Filter (((((hd_dep_count#74981 = 3) && (hd_vehicle_count#74982 <= 5)) || ((hd_dep_count#74981 = 0) && (hd_vehicle_count#74982 <= 2))) || ((hd_dep_count#74981 = 1) && (hd_vehicle_count#74982 <= 3))) && isnotnull(hd_demo_sk#74978))
      :     :           +- InMemoryRelation [hd_demo_sk#74978, hd_income_band_sk#74979, hd_buy_potential#74980, hd_dep_count#74981, hd_vehicle_count#74982], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#74983]
      :        +- Filter (((isnotnull(t_hour#74986) && isnotnull(t_minute#74987)) && ((t_hour#74986 = 12) && (t_minute#74987 < 30))) && isnotnull(t_time_sk#74983))
      :           +- InMemoryRelation [t_time_sk#74983, t_time_id#74984, t_time#74985, t_hour#74986, t_minute#74987, t_second#74988, t_am_pm#74989, t_shift#74990, t_sub_shift#74991, t_meal_time#74992], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [s_store_sk#74993]
         +- Filter ((isnotnull(s_store_name#74998) && (s_store_name#74998 = ese)) && isnotnull(s_store_sk#74993))
            +- InMemoryRelation [s_store_sk#74993, s_store_id#74994, s_rec_start_date#74995, s_rec_end_date#74996, s_closed_date_sk#74997, s_store_name#74998, s_number_employees#74999, s_floor_space#75000, s_hours#75001, s_manager#75002, s_market_id#75003, s_geography_class#75004, s_market_desc#75005, s_market_manager#75006, s_division_id#75007, s_division_name#75008, s_company_id#75009, s_company_name#75010, s_street_number#75011, s_street_name#75012, s_street_type#75013, s_suite_number#75014, s_city#75015, s_county#75016, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
Join condition is missing or trivial.
Use the CROSS JOIN syntax to allow cartesian products between these relations.; (state=,code=0)

Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
STOP hdp2.6_spark21_run_5000_1_query88_sql_2017-04-09-20-20:  Sun Apr 9 20:20:14 CDT 2017
