START hdp2.6_spark21_run_5000_2_query88_sql_2017-04-09-20-20:  Sun Apr 9 20:20:14 CDT 2017
 /usr/hdp/current/spark2-client/bin/beeline -u "jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_$SF" -n hive --incremental=true  -i settings/spark.settings -f sample-queries-tpcds/$1
Connecting to jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
17/04/09 20:20:14 INFO Utils: Supplied authorities: h01hn02.hadoop:10016
17/04/09 20:20:14 INFO Utils: Resolved authority: h01hn02.hadoop:10016
17/04/09 20:20:14 INFO HiveConnection: Will try to open client transport with JDBC Uri: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
Connected to: Spark SQL (version 2.1.0.2.6.0.0-598)
Driver: Hive JDBC (version 1.2.1.spark2.hdp)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script settings/spark.settings
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> select  *
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> from
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h8_30_to_9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk   
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2)) 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s1,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_to_9_30 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s2,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h9_30_to_10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 9
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s3,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_to_10_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s4,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h10_30_to_11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 10 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s5,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_to_11_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk 
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s6,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h11_30_to_12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 11
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute >= 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s7,
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  (select count(*) h12_to_12_30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  from store_sales, household_demographics , time_dim, store
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>  where store_sales.ss_sold_time_sk = time_dim.t_time_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store_sales.ss_store_sk = store.s_store_sk
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_hour = 12
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and time_dim.t_minute < 30
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and ((household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 0 and household_demographics.hd_vehicle_count<=0+2) or
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>           (household_demographics.hd_dep_count = 1 and household_demographics.hd_vehicle_count<=1+2))
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi>      and store.s_store_name = 'ese') s8
0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bi> ;
Error: org.apache.spark.sql.AnalysisException: Detected cartesian product for INNER join between logical plans
Join Inner
:- Join Inner
:  :- Join Inner
:  :  :- Join Inner
:  :  :  :- Join Inner
:  :  :  :  :- Join Inner
:  :  :  :  :  :- Aggregate [count(1) AS h8_30_to_9#77412L]
:  :  :  :  :  :  +- Project
:  :  :  :  :  :     +- Join Inner, (ss_store_sk#77427 = s_store_sk#77458)
:  :  :  :  :  :        :- Project [ss_store_sk#77427]
:  :  :  :  :  :        :  +- Join Inner, (ss_sold_time_sk#77421 = t_time_sk#77448)
:  :  :  :  :  :        :     :- Project [ss_sold_time_sk#77421, ss_store_sk#77427]
:  :  :  :  :  :        :     :  +- Join Inner, (ss_hdemo_sk#77425 = hd_demo_sk#77443)
:  :  :  :  :  :        :     :     :- Project [ss_sold_time_sk#77421, ss_hdemo_sk#77425, ss_store_sk#77427]
:  :  :  :  :  :        :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77425) && isnotnull(ss_sold_time_sk#77421)) && isnotnull(ss_store_sk#77427))
:  :  :  :  :  :        :     :     :     +- Relation[ss_sold_time_sk#77421,ss_item_sk#77422,ss_customer_sk#77423,ss_cdemo_sk#77424,ss_hdemo_sk#77425,ss_addr_sk#77426,ss_store_sk#77427,ss_promo_sk#77428,ss_ticket_number#77429,ss_quantity#77430,ss_wholesale_cost#77431,ss_list_price#77432,ss_sales_price#77433,ss_ext_discount_amt#77434,ss_ext_sales_price#77435,ss_ext_wholesale_cost#77436,ss_ext_list_price#77437,ss_ext_tax#77438,ss_coupon_amt#77439,ss_net_paid#77440,ss_net_paid_inc_tax#77441,ss_net_profit#77442,ss_sold_date_sk#77420] parquet
:  :  :  :  :  :        :     :     +- Project [hd_demo_sk#77443]
:  :  :  :  :  :        :     :        +- Filter (((((hd_dep_count#77446 = 3) && (hd_vehicle_count#77447 <= 5)) || ((hd_dep_count#77446 = 0) && (hd_vehicle_count#77447 <= 2))) || ((hd_dep_count#77446 = 1) && (hd_vehicle_count#77447 <= 3))) && isnotnull(hd_demo_sk#77443))
:  :  :  :  :  :        :     :           +- InMemoryRelation [hd_demo_sk#77443, hd_income_band_sk#77444, hd_buy_potential#77445, hd_dep_count#77446, hd_vehicle_count#77447], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :  :        :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :  :        :     +- Project [t_time_sk#77448]
:  :  :  :  :  :        :        +- Filter (((isnotnull(t_hour#77451) && isnotnull(t_minute#77452)) && ((t_hour#77451 = 8) && (t_minute#77452 >= 30))) && isnotnull(t_time_sk#77448))
:  :  :  :  :  :        :           +- InMemoryRelation [t_time_sk#77448, t_time_id#77449, t_time#77450, t_hour#77451, t_minute#77452, t_second#77453, t_am_pm#77454, t_shift#77455, t_sub_shift#77456, t_meal_time#77457], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :  :        :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :  :        +- Project [s_store_sk#77458]
:  :  :  :  :  :           +- Filter ((isnotnull(s_store_name#77463) && (s_store_name#77463 = ese)) && isnotnull(s_store_sk#77458))
:  :  :  :  :  :              +- InMemoryRelation [s_store_sk#77458, s_store_id#77459, s_rec_start_date#77460, s_rec_end_date#77461, s_closed_date_sk#77462, s_store_name#77463, s_number_employees#77464, s_floor_space#77465, s_hours#77466, s_manager#77467, s_market_id#77468, s_geography_class#77469, s_market_desc#77470, s_market_manager#77471, s_division_id#77472, s_division_name#77473, s_company_id#77474, s_company_name#77475, s_street_number#77476, s_street_name#77477, s_street_type#77478, s_suite_number#77479, s_city#77480, s_county#77481, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :  :                    +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  :  +- Aggregate [count(1) AS h9_to_9_30#77413L]
:  :  :  :  :     +- Project
:  :  :  :  :        +- Join Inner, (ss_store_sk#77494 = s_store_sk#77525)
:  :  :  :  :           :- Project [ss_store_sk#77494]
:  :  :  :  :           :  +- Join Inner, (ss_sold_time_sk#77488 = t_time_sk#77515)
:  :  :  :  :           :     :- Project [ss_sold_time_sk#77488, ss_store_sk#77494]
:  :  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#77492 = hd_demo_sk#77510)
:  :  :  :  :           :     :     :- Project [ss_sold_time_sk#77488, ss_hdemo_sk#77492, ss_store_sk#77494]
:  :  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77492) && isnotnull(ss_sold_time_sk#77488)) && isnotnull(ss_store_sk#77494))
:  :  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#77488,ss_item_sk#77489,ss_customer_sk#77490,ss_cdemo_sk#77491,ss_hdemo_sk#77492,ss_addr_sk#77493,ss_store_sk#77494,ss_promo_sk#77495,ss_ticket_number#77496,ss_quantity#77497,ss_wholesale_cost#77498,ss_list_price#77499,ss_sales_price#77500,ss_ext_discount_amt#77501,ss_ext_sales_price#77502,ss_ext_wholesale_cost#77503,ss_ext_list_price#77504,ss_ext_tax#77505,ss_coupon_amt#77506,ss_net_paid#77507,ss_net_paid_inc_tax#77508,ss_net_profit#77509,ss_sold_date_sk#77487] parquet
:  :  :  :  :           :     :     +- Project [hd_demo_sk#77510]
:  :  :  :  :           :     :        +- Filter (((((hd_dep_count#77513 = 3) && (hd_vehicle_count#77514 <= 5)) || ((hd_dep_count#77513 = 0) && (hd_vehicle_count#77514 <= 2))) || ((hd_dep_count#77513 = 1) && (hd_vehicle_count#77514 <= 3))) && isnotnull(hd_demo_sk#77510))
:  :  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#77510, hd_income_band_sk#77511, hd_buy_potential#77512, hd_dep_count#77513, hd_vehicle_count#77514], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :  :           :     +- Project [t_time_sk#77515]
:  :  :  :  :           :        +- Filter (((isnotnull(t_hour#77518) && isnotnull(t_minute#77519)) && ((t_hour#77518 = 9) && (t_minute#77519 < 30))) && isnotnull(t_time_sk#77515))
:  :  :  :  :           :           +- InMemoryRelation [t_time_sk#77515, t_time_id#77516, t_time#77517, t_hour#77518, t_minute#77519, t_second#77520, t_am_pm#77521, t_shift#77522, t_sub_shift#77523, t_meal_time#77524], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :  :           +- Project [s_store_sk#77525]
:  :  :  :  :              +- Filter ((isnotnull(s_store_name#77530) && (s_store_name#77530 = ese)) && isnotnull(s_store_sk#77525))
:  :  :  :  :                 +- InMemoryRelation [s_store_sk#77525, s_store_id#77526, s_rec_start_date#77527, s_rec_end_date#77528, s_closed_date_sk#77529, s_store_name#77530, s_number_employees#77531, s_floor_space#77532, s_hours#77533, s_manager#77534, s_market_id#77535, s_geography_class#77536, s_market_desc#77537, s_market_manager#77538, s_division_id#77539, s_division_name#77540, s_company_id#77541, s_company_name#77542, s_street_number#77543, s_street_name#77544, s_street_type#77545, s_suite_number#77546, s_city#77547, s_county#77548, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  :  +- Aggregate [count(1) AS h9_30_to_10#77414L]
:  :  :  :     +- Project
:  :  :  :        +- Join Inner, (ss_store_sk#77561 = s_store_sk#77592)
:  :  :  :           :- Project [ss_store_sk#77561]
:  :  :  :           :  +- Join Inner, (ss_sold_time_sk#77555 = t_time_sk#77582)
:  :  :  :           :     :- Project [ss_sold_time_sk#77555, ss_store_sk#77561]
:  :  :  :           :     :  +- Join Inner, (ss_hdemo_sk#77559 = hd_demo_sk#77577)
:  :  :  :           :     :     :- Project [ss_sold_time_sk#77555, ss_hdemo_sk#77559, ss_store_sk#77561]
:  :  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77559) && isnotnull(ss_sold_time_sk#77555)) && isnotnull(ss_store_sk#77561))
:  :  :  :           :     :     :     +- Relation[ss_sold_time_sk#77555,ss_item_sk#77556,ss_customer_sk#77557,ss_cdemo_sk#77558,ss_hdemo_sk#77559,ss_addr_sk#77560,ss_store_sk#77561,ss_promo_sk#77562,ss_ticket_number#77563,ss_quantity#77564,ss_wholesale_cost#77565,ss_list_price#77566,ss_sales_price#77567,ss_ext_discount_amt#77568,ss_ext_sales_price#77569,ss_ext_wholesale_cost#77570,ss_ext_list_price#77571,ss_ext_tax#77572,ss_coupon_amt#77573,ss_net_paid#77574,ss_net_paid_inc_tax#77575,ss_net_profit#77576,ss_sold_date_sk#77554] parquet
:  :  :  :           :     :     +- Project [hd_demo_sk#77577]
:  :  :  :           :     :        +- Filter (((((hd_dep_count#77580 = 3) && (hd_vehicle_count#77581 <= 5)) || ((hd_dep_count#77580 = 0) && (hd_vehicle_count#77581 <= 2))) || ((hd_dep_count#77580 = 1) && (hd_vehicle_count#77581 <= 3))) && isnotnull(hd_demo_sk#77577))
:  :  :  :           :     :           +- InMemoryRelation [hd_demo_sk#77577, hd_income_band_sk#77578, hd_buy_potential#77579, hd_dep_count#77580, hd_vehicle_count#77581], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :  :           :     +- Project [t_time_sk#77582]
:  :  :  :           :        +- Filter (((isnotnull(t_hour#77585) && isnotnull(t_minute#77586)) && ((t_hour#77585 = 9) && (t_minute#77586 >= 30))) && isnotnull(t_time_sk#77582))
:  :  :  :           :           +- InMemoryRelation [t_time_sk#77582, t_time_id#77583, t_time#77584, t_hour#77585, t_minute#77586, t_second#77587, t_am_pm#77588, t_shift#77589, t_sub_shift#77590, t_meal_time#77591], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :  :           +- Project [s_store_sk#77592]
:  :  :  :              +- Filter ((isnotnull(s_store_name#77597) && (s_store_name#77597 = ese)) && isnotnull(s_store_sk#77592))
:  :  :  :                 +- InMemoryRelation [s_store_sk#77592, s_store_id#77593, s_rec_start_date#77594, s_rec_end_date#77595, s_closed_date_sk#77596, s_store_name#77597, s_number_employees#77598, s_floor_space#77599, s_hours#77600, s_manager#77601, s_market_id#77602, s_geography_class#77603, s_market_desc#77604, s_market_manager#77605, s_division_id#77606, s_division_name#77607, s_company_id#77608, s_company_name#77609, s_street_number#77610, s_street_name#77611, s_street_type#77612, s_suite_number#77613, s_city#77614, s_county#77615, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  :  +- Aggregate [count(1) AS h10_to_10_30#77415L]
:  :  :     +- Project
:  :  :        +- Join Inner, (ss_store_sk#77628 = s_store_sk#77659)
:  :  :           :- Project [ss_store_sk#77628]
:  :  :           :  +- Join Inner, (ss_sold_time_sk#77622 = t_time_sk#77649)
:  :  :           :     :- Project [ss_sold_time_sk#77622, ss_store_sk#77628]
:  :  :           :     :  +- Join Inner, (ss_hdemo_sk#77626 = hd_demo_sk#77644)
:  :  :           :     :     :- Project [ss_sold_time_sk#77622, ss_hdemo_sk#77626, ss_store_sk#77628]
:  :  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77626) && isnotnull(ss_sold_time_sk#77622)) && isnotnull(ss_store_sk#77628))
:  :  :           :     :     :     +- Relation[ss_sold_time_sk#77622,ss_item_sk#77623,ss_customer_sk#77624,ss_cdemo_sk#77625,ss_hdemo_sk#77626,ss_addr_sk#77627,ss_store_sk#77628,ss_promo_sk#77629,ss_ticket_number#77630,ss_quantity#77631,ss_wholesale_cost#77632,ss_list_price#77633,ss_sales_price#77634,ss_ext_discount_amt#77635,ss_ext_sales_price#77636,ss_ext_wholesale_cost#77637,ss_ext_list_price#77638,ss_ext_tax#77639,ss_coupon_amt#77640,ss_net_paid#77641,ss_net_paid_inc_tax#77642,ss_net_profit#77643,ss_sold_date_sk#77621] parquet
:  :  :           :     :     +- Project [hd_demo_sk#77644]
:  :  :           :     :        +- Filter (((((hd_dep_count#77647 = 3) && (hd_vehicle_count#77648 <= 5)) || ((hd_dep_count#77647 = 0) && (hd_vehicle_count#77648 <= 2))) || ((hd_dep_count#77647 = 1) && (hd_vehicle_count#77648 <= 3))) && isnotnull(hd_demo_sk#77644))
:  :  :           :     :           +- InMemoryRelation [hd_demo_sk#77644, hd_income_band_sk#77645, hd_buy_potential#77646, hd_dep_count#77647, hd_vehicle_count#77648], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :  :           :     +- Project [t_time_sk#77649]
:  :  :           :        +- Filter (((isnotnull(t_hour#77652) && isnotnull(t_minute#77653)) && ((t_hour#77652 = 10) && (t_minute#77653 < 30))) && isnotnull(t_time_sk#77649))
:  :  :           :           +- InMemoryRelation [t_time_sk#77649, t_time_id#77650, t_time#77651, t_hour#77652, t_minute#77653, t_second#77654, t_am_pm#77655, t_shift#77656, t_sub_shift#77657, t_meal_time#77658], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :  :           +- Project [s_store_sk#77659]
:  :  :              +- Filter ((isnotnull(s_store_name#77664) && (s_store_name#77664 = ese)) && isnotnull(s_store_sk#77659))
:  :  :                 +- InMemoryRelation [s_store_sk#77659, s_store_id#77660, s_rec_start_date#77661, s_rec_end_date#77662, s_closed_date_sk#77663, s_store_name#77664, s_number_employees#77665, s_floor_space#77666, s_hours#77667, s_manager#77668, s_market_id#77669, s_geography_class#77670, s_market_desc#77671, s_market_manager#77672, s_division_id#77673, s_division_name#77674, s_company_id#77675, s_company_name#77676, s_street_number#77677, s_street_name#77678, s_street_type#77679, s_suite_number#77680, s_city#77681, s_county#77682, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  :  +- Aggregate [count(1) AS h10_30_to_11#77416L]
:  :     +- Project
:  :        +- Join Inner, (ss_store_sk#77695 = s_store_sk#77726)
:  :           :- Project [ss_store_sk#77695]
:  :           :  +- Join Inner, (ss_sold_time_sk#77689 = t_time_sk#77716)
:  :           :     :- Project [ss_sold_time_sk#77689, ss_store_sk#77695]
:  :           :     :  +- Join Inner, (ss_hdemo_sk#77693 = hd_demo_sk#77711)
:  :           :     :     :- Project [ss_sold_time_sk#77689, ss_hdemo_sk#77693, ss_store_sk#77695]
:  :           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77693) && isnotnull(ss_sold_time_sk#77689)) && isnotnull(ss_store_sk#77695))
:  :           :     :     :     +- Relation[ss_sold_time_sk#77689,ss_item_sk#77690,ss_customer_sk#77691,ss_cdemo_sk#77692,ss_hdemo_sk#77693,ss_addr_sk#77694,ss_store_sk#77695,ss_promo_sk#77696,ss_ticket_number#77697,ss_quantity#77698,ss_wholesale_cost#77699,ss_list_price#77700,ss_sales_price#77701,ss_ext_discount_amt#77702,ss_ext_sales_price#77703,ss_ext_wholesale_cost#77704,ss_ext_list_price#77705,ss_ext_tax#77706,ss_coupon_amt#77707,ss_net_paid#77708,ss_net_paid_inc_tax#77709,ss_net_profit#77710,ss_sold_date_sk#77688] parquet
:  :           :     :     +- Project [hd_demo_sk#77711]
:  :           :     :        +- Filter (((((hd_dep_count#77714 = 3) && (hd_vehicle_count#77715 <= 5)) || ((hd_dep_count#77714 = 0) && (hd_vehicle_count#77715 <= 2))) || ((hd_dep_count#77714 = 1) && (hd_vehicle_count#77715 <= 3))) && isnotnull(hd_demo_sk#77711))
:  :           :     :           +- InMemoryRelation [hd_demo_sk#77711, hd_income_band_sk#77712, hd_buy_potential#77713, hd_dep_count#77714, hd_vehicle_count#77715], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:  :           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:  :           :     +- Project [t_time_sk#77716]
:  :           :        +- Filter (((isnotnull(t_hour#77719) && isnotnull(t_minute#77720)) && ((t_hour#77719 = 10) && (t_minute#77720 >= 30))) && isnotnull(t_time_sk#77716))
:  :           :           +- InMemoryRelation [t_time_sk#77716, t_time_id#77717, t_time#77718, t_hour#77719, t_minute#77720, t_second#77721, t_am_pm#77722, t_shift#77723, t_sub_shift#77724, t_meal_time#77725], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:  :           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:  :           +- Project [s_store_sk#77726]
:  :              +- Filter ((isnotnull(s_store_name#77731) && (s_store_name#77731 = ese)) && isnotnull(s_store_sk#77726))
:  :                 +- InMemoryRelation [s_store_sk#77726, s_store_id#77727, s_rec_start_date#77728, s_rec_end_date#77729, s_closed_date_sk#77730, s_store_name#77731, s_number_employees#77732, s_floor_space#77733, s_hours#77734, s_manager#77735, s_market_id#77736, s_geography_class#77737, s_market_desc#77738, s_market_manager#77739, s_division_id#77740, s_division_name#77741, s_company_id#77742, s_company_name#77743, s_street_number#77744, s_street_name#77745, s_street_type#77746, s_suite_number#77747, s_city#77748, s_county#77749, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:  :                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
:  +- Aggregate [count(1) AS h11_to_11_30#77417L]
:     +- Project
:        +- Join Inner, (ss_store_sk#77762 = s_store_sk#77793)
:           :- Project [ss_store_sk#77762]
:           :  +- Join Inner, (ss_sold_time_sk#77756 = t_time_sk#77783)
:           :     :- Project [ss_sold_time_sk#77756, ss_store_sk#77762]
:           :     :  +- Join Inner, (ss_hdemo_sk#77760 = hd_demo_sk#77778)
:           :     :     :- Project [ss_sold_time_sk#77756, ss_hdemo_sk#77760, ss_store_sk#77762]
:           :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77760) && isnotnull(ss_sold_time_sk#77756)) && isnotnull(ss_store_sk#77762))
:           :     :     :     +- Relation[ss_sold_time_sk#77756,ss_item_sk#77757,ss_customer_sk#77758,ss_cdemo_sk#77759,ss_hdemo_sk#77760,ss_addr_sk#77761,ss_store_sk#77762,ss_promo_sk#77763,ss_ticket_number#77764,ss_quantity#77765,ss_wholesale_cost#77766,ss_list_price#77767,ss_sales_price#77768,ss_ext_discount_amt#77769,ss_ext_sales_price#77770,ss_ext_wholesale_cost#77771,ss_ext_list_price#77772,ss_ext_tax#77773,ss_coupon_amt#77774,ss_net_paid#77775,ss_net_paid_inc_tax#77776,ss_net_profit#77777,ss_sold_date_sk#77755] parquet
:           :     :     +- Project [hd_demo_sk#77778]
:           :     :        +- Filter (((((hd_dep_count#77781 = 3) && (hd_vehicle_count#77782 <= 5)) || ((hd_dep_count#77781 = 0) && (hd_vehicle_count#77782 <= 2))) || ((hd_dep_count#77781 = 1) && (hd_vehicle_count#77782 <= 3))) && isnotnull(hd_demo_sk#77778))
:           :     :           +- InMemoryRelation [hd_demo_sk#77778, hd_income_band_sk#77779, hd_buy_potential#77780, hd_dep_count#77781, hd_vehicle_count#77782], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
:           :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
:           :     +- Project [t_time_sk#77783]
:           :        +- Filter (((isnotnull(t_hour#77786) && isnotnull(t_minute#77787)) && ((t_hour#77786 = 11) && (t_minute#77787 < 30))) && isnotnull(t_time_sk#77783))
:           :           +- InMemoryRelation [t_time_sk#77783, t_time_id#77784, t_time#77785, t_hour#77786, t_minute#77787, t_second#77788, t_am_pm#77789, t_shift#77790, t_sub_shift#77791, t_meal_time#77792], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
:           :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
:           +- Project [s_store_sk#77793]
:              +- Filter ((isnotnull(s_store_name#77798) && (s_store_name#77798 = ese)) && isnotnull(s_store_sk#77793))
:                 +- InMemoryRelation [s_store_sk#77793, s_store_id#77794, s_rec_start_date#77795, s_rec_end_date#77796, s_closed_date_sk#77797, s_store_name#77798, s_number_employees#77799, s_floor_space#77800, s_hours#77801, s_manager#77802, s_market_id#77803, s_geography_class#77804, s_market_desc#77805, s_market_manager#77806, s_division_id#77807, s_division_name#77808, s_company_id#77809, s_company_name#77810, s_street_number#77811, s_street_name#77812, s_street_type#77813, s_suite_number#77814, s_city#77815, s_county#77816, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
:                       +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
+- Aggregate [count(1) AS h11_30_to_12#77418L]
   +- Project
      +- Join Inner, (ss_store_sk#77829 = s_store_sk#77860)
         :- Project [ss_store_sk#77829]
         :  +- Join Inner, (ss_sold_time_sk#77823 = t_time_sk#77850)
         :     :- Project [ss_sold_time_sk#77823, ss_store_sk#77829]
         :     :  +- Join Inner, (ss_hdemo_sk#77827 = hd_demo_sk#77845)
         :     :     :- Project [ss_sold_time_sk#77823, ss_hdemo_sk#77827, ss_store_sk#77829]
         :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77827) && isnotnull(ss_sold_time_sk#77823)) && isnotnull(ss_store_sk#77829))
         :     :     :     +- Relation[ss_sold_time_sk#77823,ss_item_sk#77824,ss_customer_sk#77825,ss_cdemo_sk#77826,ss_hdemo_sk#77827,ss_addr_sk#77828,ss_store_sk#77829,ss_promo_sk#77830,ss_ticket_number#77831,ss_quantity#77832,ss_wholesale_cost#77833,ss_list_price#77834,ss_sales_price#77835,ss_ext_discount_amt#77836,ss_ext_sales_price#77837,ss_ext_wholesale_cost#77838,ss_ext_list_price#77839,ss_ext_tax#77840,ss_coupon_amt#77841,ss_net_paid#77842,ss_net_paid_inc_tax#77843,ss_net_profit#77844,ss_sold_date_sk#77822] parquet
         :     :     +- Project [hd_demo_sk#77845]
         :     :        +- Filter (((((hd_dep_count#77848 = 3) && (hd_vehicle_count#77849 <= 5)) || ((hd_dep_count#77848 = 0) && (hd_vehicle_count#77849 <= 2))) || ((hd_dep_count#77848 = 1) && (hd_vehicle_count#77849 <= 3))) && isnotnull(hd_demo_sk#77845))
         :     :           +- InMemoryRelation [hd_demo_sk#77845, hd_income_band_sk#77846, hd_buy_potential#77847, hd_dep_count#77848, hd_vehicle_count#77849], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
         :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
         :     +- Project [t_time_sk#77850]
         :        +- Filter (((isnotnull(t_hour#77853) && isnotnull(t_minute#77854)) && ((t_hour#77853 = 11) && (t_minute#77854 >= 30))) && isnotnull(t_time_sk#77850))
         :           +- InMemoryRelation [t_time_sk#77850, t_time_id#77851, t_time#77852, t_hour#77853, t_minute#77854, t_second#77855, t_am_pm#77856, t_shift#77857, t_sub_shift#77858, t_meal_time#77859], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
         :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
         +- Project [s_store_sk#77860]
            +- Filter ((isnotnull(s_store_name#77865) && (s_store_name#77865 = ese)) && isnotnull(s_store_sk#77860))
               +- InMemoryRelation [s_store_sk#77860, s_store_id#77861, s_rec_start_date#77862, s_rec_end_date#77863, s_closed_date_sk#77864, s_store_name#77865, s_number_employees#77866, s_floor_space#77867, s_hours#77868, s_manager#77869, s_market_id#77870, s_geography_class#77871, s_market_desc#77872, s_market_manager#77873, s_division_id#77874, s_division_name#77875, s_company_id#77876, s_company_name#77877, s_street_number#77878, s_street_name#77879, s_street_type#77880, s_suite_number#77881, s_city#77882, s_county#77883, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                     +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
and
Aggregate [count(1) AS h12_to_12_30#77419L]
+- Project
   +- Join Inner, (ss_store_sk#77896 = s_store_sk#77927)
      :- Project [ss_store_sk#77896]
      :  +- Join Inner, (ss_sold_time_sk#77890 = t_time_sk#77917)
      :     :- Project [ss_sold_time_sk#77890, ss_store_sk#77896]
      :     :  +- Join Inner, (ss_hdemo_sk#77894 = hd_demo_sk#77912)
      :     :     :- Project [ss_sold_time_sk#77890, ss_hdemo_sk#77894, ss_store_sk#77896]
      :     :     :  +- Filter ((isnotnull(ss_hdemo_sk#77894) && isnotnull(ss_sold_time_sk#77890)) && isnotnull(ss_store_sk#77896))
      :     :     :     +- Relation[ss_sold_time_sk#77890,ss_item_sk#77891,ss_customer_sk#77892,ss_cdemo_sk#77893,ss_hdemo_sk#77894,ss_addr_sk#77895,ss_store_sk#77896,ss_promo_sk#77897,ss_ticket_number#77898,ss_quantity#77899,ss_wholesale_cost#77900,ss_list_price#77901,ss_sales_price#77902,ss_ext_discount_amt#77903,ss_ext_sales_price#77904,ss_ext_wholesale_cost#77905,ss_ext_list_price#77906,ss_ext_tax#77907,ss_coupon_amt#77908,ss_net_paid#77909,ss_net_paid_inc_tax#77910,ss_net_profit#77911,ss_sold_date_sk#77889] parquet
      :     :     +- Project [hd_demo_sk#77912]
      :     :        +- Filter (((((hd_dep_count#77915 = 3) && (hd_vehicle_count#77916 <= 5)) || ((hd_dep_count#77915 = 0) && (hd_vehicle_count#77916 <= 2))) || ((hd_dep_count#77915 = 1) && (hd_vehicle_count#77916 <= 3))) && isnotnull(hd_demo_sk#77912))
      :     :           +- InMemoryRelation [hd_demo_sk#77912, hd_income_band_sk#77913, hd_buy_potential#77914, hd_dep_count#77915, hd_vehicle_count#77916], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `household_demographics`
      :     :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.household_demographics[hd_demo_sk#1622,hd_income_band_sk#1623,hd_buy_potential#1624,hd_dep_count#1625,hd_vehicle_count#1626] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<hd_demo_sk:int,hd_income_band_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_c...
      :     +- Project [t_time_sk#77917]
      :        +- Filter (((isnotnull(t_hour#77920) && isnotnull(t_minute#77921)) && ((t_hour#77920 = 12) && (t_minute#77921 < 30))) && isnotnull(t_time_sk#77917))
      :           +- InMemoryRelation [t_time_sk#77917, t_time_id#77918, t_time#77919, t_hour#77920, t_minute#77921, t_second#77922, t_am_pm#77923, t_shift#77924, t_sub_shift#77925, t_meal_time#77926], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `time_dim`
      :                 +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.time_dim[t_time_sk#516,t_time_id#517,t_time#518,t_hour#519,t_minute#520,t_second#521,t_am_pm#522,t_shift#523,t_sub_shift#524,t_meal_time#525] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<t_time_sk:int,t_time_id:string,t_time:int,t_hour:int,t_minute:int,t_second:int,t_am_pm:str...
      +- Project [s_store_sk#77927]
         +- Filter ((isnotnull(s_store_name#77932) && (s_store_name#77932 = ese)) && isnotnull(s_store_sk#77927))
            +- InMemoryRelation [s_store_sk#77927, s_store_id#77928, s_rec_start_date#77929, s_rec_end_date#77930, s_closed_date_sk#77931, s_store_name#77932, s_number_employees#77933, s_floor_space#77934, s_hours#77935, s_manager#77936, s_market_id#77937, s_geography_class#77938, s_market_desc#77939, s_market_manager#77940, s_division_id#77941, s_division_name#77942, s_company_id#77943, s_company_name#77944, s_street_number#77945, s_street_name#77946, s_street_type#77947, s_suite_number#77948, s_city#77949, s_county#77950, ... 5 more fields], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas), `store`
                  +- *FileScan parquet tpcds_bin_partitioned_parquet_5000.store[s_store_sk#1968,s_store_id#1969,s_rec_start_date#1970,s_rec_end_date#1971,s_closed_date_sk#1972,s_store_name#1973,s_number_employees#1974,s_floor_space#1975,s_hours#1976,s_manager#1977,s_market_id#1978,s_geography_class#1979,s_market_desc#1980,s_market_manager#1981,s_division_id#1982,s_division_name#1983,s_company_id#1984,s_company_name#1985,s_street_number#1986,s_street_name#1987,s_street_type#1988,s_suite_number#1989,s_city#1990,s_county#1991,... 5 more fields] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://h01hn01.hadoop:8020/apps/hive/warehouse/tpcds_bin_partitioned_parquet_50..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_rec_start_date:string,s_rec_end_date:string,s_closed_da...
Join condition is missing or trivial.
Use the CROSS JOIN syntax to allow cartesian products between these relations.; (state=,code=0)

Closing: 0: jdbc:hive2://h01hn02.hadoop:10016/tpcds_bin_partitioned_parquet_5000
STOP hdp2.6_spark21_run_5000_2_query88_sql_2017-04-09-20-20:  Sun Apr 9 20:20:19 CDT 2017
