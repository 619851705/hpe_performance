START hdp2.5_llap_10000_query97_sql_2017-01-04-17-29:  Wed Jan 4 17:30:01 CST 2017
beeline --outputformat=csv2 -u jdbc:hiv2:// -i sample-queries-tpcds/testbench.settings-4g-container-tez --database tpcds_bin_partitioned_orc_10000 -f sample-queries-tpcds/query97.sql
Connecting to jdbc:hive2://h01hn02:10500/tpcds_bin_partitioned_orc_10000
Connected to: Apache Hive (version 2.1.0.2.5.1.0-43)
Driver: Hive JDBC (version 1.2.1000.2.5.1.0-43)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Running init script sample-queries-tpch/testbench.settings-4g-container
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> --set ambari.hive.db.schema.name=hive;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set fs.file.impl.disable.cache=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set fs.hdfs.impl.disable.cache=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.auto.convert.join.noconditionaltask=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.auto.convert.join=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> --set hive.auto.convert.sortmerge.join.noconditionaltask=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.auto.convert.sortmerge.join=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.abortedtxn.threshold=1000;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.check.interval=300;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.delta.num.threshold=10;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.delta.pct.threshold=0.1f;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.initiator.on=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.worker.threads=0;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compactor.worker.timeout=86400;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.compute.query.using.stats=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.enforce.bucketing=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.enforce.sorting=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.enforce.sortmergebucketmapjoin=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.execution.engine=mr;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.limit.pushdown.memory.usage=0.04;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.map.aggr=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.mapjoin.bucket.cache.size=10000;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.mapred.reduce.tasks.speculative.execution=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.metastore.cache.pinobjtypes=Table,Database,Type,FieldSchema,Order;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.metastore.client.socket.timeout=60;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.metastore.execute.setugi=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.metastore.warehouse.dir=/apps/hive/warehouse;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.optimize.bucketmapjoin.sortedmerge=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.optimize.bucketmapjoin=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.optimize.index.filter=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> --set hive.optimize.mapjoin.mapreduce=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.optimize.reducededuplication.min.reducer=4;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.optimize.reducededuplication=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.orc.splits.include.file.footer=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.security.authorization.enabled=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAut horizationProvider;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> --set hive.semantic.analyzer.factory.impl=org.apache.hivealog.cli.HCatSemanticAnalyzerFactory;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.server2.enable.doAs=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.server2.tez.default.queues=default;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.server2.tez.initialize.default.sessions=false;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.server2.tez.sessions.per.default.queue=1;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.stats.autogather=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.txn.max.open.batch=1000;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.txn.timeout=300;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.vectorized.execution.enabled=true;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.vectorized.groupby.checkinterval=1024;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.vectorized.groupby.flush.percent=1;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.vectorized.groupby.maxentries=1024;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> 
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- These values need to be tuned appropriately to your cluster. These examples are for reference.
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.tez.container.size=4096;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.tez.java.opts=-Xmx3800m;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> -- set hive.auto.convert.join.noconditionaltask.size=1252698795;
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> 
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> select sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1 else 0 end) store_only
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti>       ,sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1 else 0 end) catalog_only
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti>       ,sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 else 0 end) store_and_catal og
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> from 
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> ( select ss_customer_sk customer_sk
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti>       ,ss_item_sk item_sk
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> from store_sales
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> where
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti>   d_month_seq between 1193 and 1193 + 11
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> group by ss_customer_sk ,ss_item_sk) ssci
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> full outer join
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> ( select cs_bill_customer_sk customer_sk
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti>       ,cs_item_sk item_sk
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> from catalog_sales
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> JOIN date_dim ON catalog_sales.cs_sold_date_sk = date_dim.d_date_sk
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> where
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti>   d_month_seq between 1193 and 1193 + 11
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> group by cs_bill_customer_sk ,cs_item_sk) csci
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> on (ssci.customer_sk=csci.customer_sk and ssci.item_sk = csci.item_sk)
0: jdbc:hive2://h01hn02:10500/tpcds_bin_parti> limit 100;
INFO  : Compiling command(queryId=hive_20170104173002_bcbdba4b-f8a4-46e7-8ef3-74942d6062f5): select sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1 else 0 end) store_only
      ,sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1 else 0 end) catalog_only
      ,sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 else 0 end) store_and_catalog
from 
( select ss_customer_sk customer_sk
      ,ss_item_sk item_sk
from store_sales
JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk
where
  d_month_seq between 1193 and 1193 + 11
group by ss_customer_sk ,ss_item_sk) ssci
full outer join
( select cs_bill_customer_sk customer_sk
      ,cs_item_sk item_sk
from catalog_sales
JOIN date_dim ON catalog_sales.cs_sold_date_sk = date_dim.d_date_sk
where
  d_month_seq between 1193 and 1193 + 11
group by cs_bill_customer_sk ,cs_item_sk) csci
on (ssci.customer_sk=csci.customer_sk and ssci.item_sk = csci.item_sk)
limit 100
INFO  : Semantic Analysis Completed
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:store_only, type:bigint, comment:null), FieldSchema(name:catalog_only, type:bigint, comment:null), FieldSchema(name:store_and_catalog, type:bigint, comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hive_20170104173002_bcbdba4b-f8a4-46e7-8ef3-74942d6062f5); Time taken: 1.187 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hive_20170104173002_bcbdba4b-f8a4-46e7-8ef3-74942d6062f5): select sum(case when ssci.customer_sk is not null and csci.customer_sk is null then 1 else 0 end) store_only
      ,sum(case when ssci.customer_sk is null and csci.customer_sk is not null then 1 else 0 end) catalog_only
      ,sum(case when ssci.customer_sk is not null and csci.customer_sk is not null then 1 else 0 end) store_and_catalog
from 
( select ss_customer_sk customer_sk
      ,ss_item_sk item_sk
from store_sales
JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk
where
  d_month_seq between 1193 and 1193 + 11
group by ss_customer_sk ,ss_item_sk) ssci
full outer join
( select cs_bill_customer_sk customer_sk
      ,cs_item_sk item_sk
from catalog_sales
JOIN date_dim ON catalog_sales.cs_sold_date_sk = date_dim.d_date_sk
where
  d_month_seq between 1193 and 1193 + 11
group by cs_bill_customer_sk ,cs_item_sk) csci
on (ssci.customer_sk=csci.customer_sk and ssci.item_sk = csci.item_sk)
limit 100
INFO  : Query ID = hive_20170104173002_bcbdba4b-f8a4-46e7-8ef3-74942d6062f5
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Session is already open
INFO  : Dag name: select sum(case when ssci.customer_sk ...100(Stage-1)
INFO  : Setting tez.task.scale.memory.reserve-fraction to 0.30000001192092896
INFO  : Setting tez.task.scale.memory.reserve-fraction to 0.30000001192092896
INFO  : 

ERROR : Status: Failed
ERROR : Vertex failed, vertexName=Map 8, vertexId=vertex_1483569684333_0025_1_00, diagnostics=[Vertex vertex_1483569684333_0025_1_00 [Map 8] killed/failed due to:INIT_FAILURE, Fail to create InputInitializerManager, org.apache.tez.dag.api.TezReflectionException: Unable to instantiate class with 1 arguments: org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:70)
	at org.apache.tez.common.ReflectionUtils.createClazzInstance(ReflectionUtils.java:89)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:151)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.createInitializer(RootInputInitializerManager.java:148)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInputInitializers(RootInputInitializerManager.java:121)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.setupInputInitializerManager(VertexImpl.java:3986)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.access$3100(VertexImpl.java:204)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.handleInitEvent(VertexImpl.java:2818)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2765)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2747)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.tez.state.StateMachineTez.doTransition(StateMachineTez.java:59)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:1888)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:203)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2242)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2228)
	at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:68)
	... 25 more
Caused by: java.lang.IllegalStateException: org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProviderneeds at least 1 location to function
	at com.google.common.base.Preconditions.checkState(Preconditions.java:149)
	at org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider.<init>(HostAffinitySplitLocationProvider.java:51)
	at org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:52)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:121)
	... 30 more
]
ERROR : Vertex failed, vertexName=Map 5, vertexId=vertex_1483569684333_0025_1_01, diagnostics=[Vertex vertex_1483569684333_0025_1_01 [Map 5] killed/failed due to:INIT_FAILURE, Fail to create InputInitializerManager, org.apache.tez.dag.api.TezReflectionException: Unable to instantiate class with 1 arguments: org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:70)
	at org.apache.tez.common.ReflectionUtils.createClazzInstance(ReflectionUtils.java:89)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:151)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.createInitializer(RootInputInitializerManager.java:148)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInputInitializers(RootInputInitializerManager.java:121)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.setupInputInitializerManager(VertexImpl.java:3986)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.access$3100(VertexImpl.java:204)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.handleInitEvent(VertexImpl.java:2818)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2765)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2747)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.tez.state.StateMachineTez.doTransition(StateMachineTez.java:59)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:1888)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:203)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2242)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2228)
	at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:68)
	... 25 more
Caused by: java.lang.IllegalStateException: org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProviderneeds at least 1 location to function
	at com.google.common.base.Preconditions.checkState(Preconditions.java:149)
	at org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider.<init>(HostAffinitySplitLocationProvider.java:51)
	at org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:52)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:121)
	... 30 more
]
ERROR : Vertex killed, vertexName=Reducer 4, vertexId=vertex_1483569684333_0025_1_07, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_07 [Reducer 4] killed/failed due to:OTHER_VERTEX_FAILURE]
ERROR : Vertex killed, vertexName=Reducer 3, vertexId=vertex_1483569684333_0025_1_06, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_06 [Reducer 3] killed/failed due to:OTHER_VERTEX_FAILURE]
ERROR : Vertex killed, vertexName=Reducer 2, vertexId=vertex_1483569684333_0025_1_05, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_05 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]
ERROR : Vertex killed, vertexName=Map 1, vertexId=vertex_1483569684333_0025_1_04, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_04 [Map 1] killed/failed due to:OTHER_VERTEX_FAILURE]
ERROR : Vertex killed, vertexName=Reducer 7, vertexId=vertex_1483569684333_0025_1_03, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_03 [Reducer 7] killed/failed due to:OTHER_VERTEX_FAILURE]
ERROR : Vertex killed, vertexName=Map 6, vertexId=vertex_1483569684333_0025_1_02, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_02 [Map 6] killed/failed due to:OTHER_VERTEX_FAILURE]
ERROR : DAG did not succeed due to VERTEX_FAILURE. failedVertices:2 killedVertices:6
INFO  : org.apache.tez.common.counters.DAGCounter:
INFO  :    AM_CPU_MILLISECONDS: 210
INFO  :    AM_GC_TIME_MILLIS: 0
ERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 8, vertexId=vertex_1483569684333_0025_1_00, diagnostics=[Vertex vertex_1483569684333_0025_1_00 [Map 8] killed/failed due to:INIT_FAILURE, Fail to create InputInitializerManager, org.apache.tez.dag.api.TezReflectionException: Unable to instantiate class with 1 arguments: org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:70)
	at org.apache.tez.common.ReflectionUtils.createClazzInstance(ReflectionUtils.java:89)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:151)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.createInitializer(RootInputInitializerManager.java:148)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInputInitializers(RootInputInitializerManager.java:121)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.setupInputInitializerManager(VertexImpl.java:3986)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.access$3100(VertexImpl.java:204)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.handleInitEvent(VertexImpl.java:2818)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2765)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2747)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.tez.state.StateMachineTez.doTransition(StateMachineTez.java:59)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:1888)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:203)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2242)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2228)
	at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:68)
	... 25 more
Caused by: java.lang.IllegalStateException: org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProviderneeds at least 1 location to function
	at com.google.common.base.Preconditions.checkState(Preconditions.java:149)
	at org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider.<init>(HostAffinitySplitLocationProvider.java:51)
	at org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:52)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:121)
	... 30 more
]Vertex failed, vertexName=Map 5, vertexId=vertex_1483569684333_0025_1_01, diagnostics=[Vertex vertex_1483569684333_0025_1_01 [Map 5] killed/failed due to:INIT_FAILURE, Fail to create InputInitializerManager, org.apache.tez.dag.api.TezReflectionException: Unable to instantiate class with 1 arguments: org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:70)
	at org.apache.tez.common.ReflectionUtils.createClazzInstance(ReflectionUtils.java:89)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:151)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.createInitializer(RootInputInitializerManager.java:148)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInputInitializers(RootInputInitializerManager.java:121)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.setupInputInitializerManager(VertexImpl.java:3986)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.access$3100(VertexImpl.java:204)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.handleInitEvent(VertexImpl.java:2818)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2765)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2747)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.tez.state.StateMachineTez.doTransition(StateMachineTez.java:59)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:1888)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:203)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2242)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2228)
	at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:68)
	... 25 more
Caused by: java.lang.IllegalStateException: org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProviderneeds at least 1 location to function
	at com.google.common.base.Preconditions.checkState(Preconditions.java:149)
	at org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider.<init>(HostAffinitySplitLocationProvider.java:51)
	at org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:52)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:121)
	... 30 more
]Vertex killed, vertexName=Reducer 4, vertexId=vertex_1483569684333_0025_1_07, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_07 [Reducer 4] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Reducer 3, vertexId=vertex_1483569684333_0025_1_06, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_06 [Reducer 3] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1483569684333_0025_1_05, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_05 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Map 1, vertexId=vertex_1483569684333_0025_1_04, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_04 [Map 1] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Reducer 7, vertexId=vertex_1483569684333_0025_1_03, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_03 [Reducer 7] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Map 6, vertexId=vertex_1483569684333_0025_1_02, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_02 [Map 6] killed/failed due to:OTHER_VERTEX_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:2 killedVertices:6
INFO  : Completed executing command(queryId=hive_20170104173002_bcbdba4b-f8a4-46e7-8ef3-74942d6062f5); Time taken: 0.909 seconds
Error: Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 8, vertexId=vertex_1483569684333_0025_1_00, diagnostics=[Vertex vertex_1483569684333_0025_1_00 [Map 8] killed/failed due to:INIT_FAILURE, Fail to create InputInitializerManager, org.apache.tez.dag.api.TezReflectionException: Unable to instantiate class with 1 arguments: org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:70)
	at org.apache.tez.common.ReflectionUtils.createClazzInstance(ReflectionUtils.java:89)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:151)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.createInitializer(RootInputInitializerManager.java:148)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInputInitializers(RootInputInitializerManager.java:121)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.setupInputInitializerManager(VertexImpl.java:3986)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.access$3100(VertexImpl.java:204)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.handleInitEvent(VertexImpl.java:2818)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2765)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2747)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.tez.state.StateMachineTez.doTransition(StateMachineTez.java:59)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:1888)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:203)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2242)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2228)
	at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:68)
	... 25 more
Caused by: java.lang.IllegalStateException: org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProviderneeds at least 1 location to function
	at com.google.common.base.Preconditions.checkState(Preconditions.java:149)
	at org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider.<init>(HostAffinitySplitLocationProvider.java:51)
	at org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:52)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:121)
	... 30 more
]Vertex failed, vertexName=Map 5, vertexId=vertex_1483569684333_0025_1_01, diagnostics=[Vertex vertex_1483569684333_0025_1_01 [Map 5] killed/failed due to:INIT_FAILURE, Fail to create InputInitializerManager, org.apache.tez.dag.api.TezReflectionException: Unable to instantiate class with 1 arguments: org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:70)
	at org.apache.tez.common.ReflectionUtils.createClazzInstance(ReflectionUtils.java:89)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:151)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$1.run(RootInputInitializerManager.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.createInitializer(RootInputInitializerManager.java:148)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager.runInputInitializers(RootInputInitializerManager.java:121)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.setupInputInitializerManager(VertexImpl.java:3986)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.access$3100(VertexImpl.java:204)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.handleInitEvent(VertexImpl.java:2818)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2765)
	at org.apache.tez.dag.app.dag.impl.VertexImpl$InitTransition.transition(VertexImpl.java:2747)
	at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.tez.state.StateMachineTez.doTransition(StateMachineTez.java:59)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:1888)
	at org.apache.tez.dag.app.dag.impl.VertexImpl.handle(VertexImpl.java:203)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2242)
	at org.apache.tez.dag.app.DAGAppMaster$VertexEventDispatcher.handle(DAGAppMaster.java:2228)
	at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.tez.common.ReflectionUtils.getNewInstance(ReflectionUtils.java:68)
	... 25 more
Caused by: java.lang.IllegalStateException: org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProviderneeds at least 1 location to function
	at com.google.common.base.Preconditions.checkState(Preconditions.java:149)
	at org.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider.<init>(HostAffinitySplitLocationProvider.java:51)
	at org.apache.hadoop.hive.ql.exec.tez.Utils.getSplitLocationProvider(Utils.java:52)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.<init>(HiveSplitGenerator.java:121)
	... 30 more
]Vertex killed, vertexName=Reducer 4, vertexId=vertex_1483569684333_0025_1_07, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_07 [Reducer 4] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Reducer 3, vertexId=vertex_1483569684333_0025_1_06, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_06 [Reducer 3] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1483569684333_0025_1_05, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_05 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Map 1, vertexId=vertex_1483569684333_0025_1_04, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_04 [Map 1] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Reducer 7, vertexId=vertex_1483569684333_0025_1_03, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_03 [Reducer 7] killed/failed due to:OTHER_VERTEX_FAILURE]Vertex killed, vertexName=Map 6, vertexId=vertex_1483569684333_0025_1_02, diagnostics=[Vertex received Kill in NEW state., Vertex vertex_1483569684333_0025_1_02 [Map 6] killed/failed due to:OTHER_VERTEX_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:2 killedVertices:6 (state=08S01,code=2)

Closing: 0: jdbc:hive2://h01hn02:10500/tpcds_bin_partitioned_orc_10000
STOP hdp2.5_llap_10000_query97_sql_2017-01-04-17-29:  Wed Jan 4 17:30:05 CST 2017

 South Results Number of Nodes:  9
 Avg CPU Busy:   Peak Cpu Avg:  100.000 Count > 90% Busy:  0
 Avg Disk Busy:   Peak Disk Avg:  0 Count > 90% busy 0
 Avg Disk Reads per sec:   Avg Write per sec: 
 Avg Net TX:    Peak TX Avg: 
 Avg Net RX:    Peak RX Avg: 
 Mem Utilized: 
South CSV
| 100.000 | 0 | | 0 | 0 | | | | | | |
